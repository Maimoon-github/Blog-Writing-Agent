{
  "topic": "AI_overview",
  "queries": [
    "what is the current global situation concerning AI in today's world?",
    "AI global situation",
    "AI regulation"
  ],
  "search_results": [
    {
      "title": "The current state of AI, according to Stanford's AI Index | World ...",
      "url": "https://www.weforum.org/stories/2024/04/stanford-university-ai-index-report/",
      "snippet": "Stanford University has released its seventh AI Index report. It covers trends such as technical advancements in AI and public perceptions of the technology. In an effort to alleviate concerns around AI governance, the World Economic Forum has spearheaded the AI Governance Alliance.",
      "position": 1,
      "query": "what is the current global situation concerning AI in today's world?",
      "timestamp": "2026-02-17T01:49:01.252570"
    },
    {
      "title": "The Real Threat Of AI: WEF Global Risks Report 2025 - Forbes",
      "url": "https://www.forbes.com/sites/jasonsnyder/2025/01/19/beyond-the-illusionthe-real-threat-of-ai-wef-global-risks-report-2025/",
      "snippet": "The World Economic Forum Global Risks Report 2025 highlights the dual nature of technological acceleration—offering profound opportunities and unprecedented risks.",
      "position": 2,
      "query": "what is the current global situation concerning AI in today's world?",
      "timestamp": "2026-02-17T01:49:01.252570"
    },
    {
      "title": "The State of AI: Global Survey 2025 | McKinsey",
      "url": "https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai",
      "snippet": "In this 2025 edition of the annual McKinsey Global Survey on AI , we look at the current trends that are driving real value from artificial intelligence.",
      "position": 3,
      "query": "what is the current global situation concerning AI in today's world?",
      "timestamp": "2026-02-17T01:49:01.252570"
    },
    {
      "title": "The State of AI: Global Survey 2025 | McKinsey",
      "url": "https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai",
      "snippet": "Nov 5, 2025 · In this 2025 edition of the annual McKinsey Global Survey on AI , we look at the current trends that are driving real value from artificial intelligence.",
      "position": 1,
      "query": "AI global situation",
      "timestamp": "2026-02-17T01:51:04.146103"
    },
    {
      "title": "Global Artificial Intelligence Report (2025) - IDCA",
      "url": "https://www.idc-a.org/insights/0bKr4NJQdK5sYcAQaGZD",
      "snippet": "Artificial Intelligence ( AI ) in all forms is increasingly driving the development of the Digital Economy, which now encompasses about $16 trillion of global GDP in nominal terms, according to IDCA’s Digital Economy Report 2025.",
      "position": 2,
      "query": "AI global situation",
      "timestamp": "2026-02-17T01:51:04.146103"
    },
    {
      "title": "Artificial Intelligence Q3 2025 Global Report | Insights ...",
      "url": "https://www.ropesgray.com/en/insights/alerts/2025/11/artificial-intelligence-q3-2025-global-report",
      "snippet": "AI Deal Activity Surges: The pace of private capital investment in AI -focused companies is likely to remain elevated, as venture-backed startups make progress in commercializing innovative use cases and investors remain eager to capitalize on strong projected growth in the sector and optimism regarding AI ’s transformative power.",
      "position": 3,
      "query": "AI global situation",
      "timestamp": "2026-02-17T01:51:04.146103"
    },
    {
      "title": "AI regulation",
      "url": "https://en.wikipedia.org/wiki/AI_regulation",
      "snippet": "Regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI). The regulatory and policy landscape for AI is an emerging issue in jurisdictions worldwide, including for international organizations without direct enforcement power like the IEEE or the OECD.Since 2016, numerous AI ethics guidelines have been published in order to maintain social control over the technology. Furthermore, organizations deploying AI have a central role to play in creating and implementing trustworthy AI, adhering to established principles, and taking accountability for mitigating risks. The European Union adopted in 2024 a common legal framework for AI with the AI Act.",
      "position": 1,
      "query": "AI regulation",
      "timestamp": "2026-02-17T01:51:11.007703"
    },
    {
      "title": "Regulation of artificial intelligence - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence",
      "snippet": "Regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI).",
      "position": 2,
      "query": "AI regulation",
      "timestamp": "2026-02-17T01:51:11.007703"
    },
    {
      "title": "AI Regulations in 2025: US, EU, UK, Japan, China & More - Anecdotes AI",
      "url": "https://www.anecdotes.ai/learn/ai-regulations-in-2025-us-eu-uk-japan-china-and-more",
      "snippet": "28-Jan-2026 · AI regulations refer to the legal frameworks and guidelines established to oversee the development and deployment of artificial intelligence ...",
      "position": 3,
      "query": "AI regulation",
      "timestamp": "2026-02-17T01:51:11.007703"
    }
  ],
  "extracted_content": [
    {
      "url": "https://www.weforum.org/stories/2024/04/stanford-university-ai-index-report/",
      "title": "The current state of AI, according to Stanford's AI Index | World ...",
      "content": "",
      "word_count": 0,
      "extraction_method": "failed",
      "metadata": {},
      "timestamp": "2026-02-17T01:49:02.658422",
      "error": "HTTP 403"
    },
    {
      "url": "https://www.forbes.com/sites/jasonsnyder/2025/01/19/beyond-the-illusionthe-real-threat-of-ai-wef-global-risks-report-2025/",
      "title": "The Real Threat Of AI: WEF Global Risks Report 2025 - Forbes",
      "content": "",
      "word_count": 0,
      "extraction_method": "failed",
      "metadata": {},
      "timestamp": "2026-02-17T01:49:04.255861",
      "error": "HTTP 403"
    },
    {
      "url": "https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai",
      "title": "The State of AI: Global Survey 2025 | McKinsey",
      "content": "",
      "word_count": 0,
      "extraction_method": "failed",
      "metadata": {},
      "timestamp": "2026-02-17T01:51:01.351041",
      "error": "HTTPSConnectionPool(host='www.mckinsey.com', port=443): Max retries exceeded with url: /capabilities/quantumblack/our-insights/the-state-of-ai (Caused by ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))"
    },
    {
      "url": "https://www.idc-a.org/insights/0bKr4NJQdK5sYcAQaGZD",
      "title": "Global Artificial Intelligence Report (2025) | IDCA",
      "content": "AI's prominence became well-established in the world's tech industry in 2024 and has already continued with the same trajectory in 2025. According to IDCA's comprehensive Q1 2025 industry survey, research shows that 87 percent of companies identify AI as a top priority in their business plans, 76 percent of organizations now use AI, 69 percent of organizations use generative AI in at least one business function, and 53 percent use AI to harness Big Data effectively. Furthermore, IDCA polls and surveys among industry professionals and global leaders show that 72 percent of respondents named AI the leading \"game changer\" in building Digital Economies today. Artificial Intelligence (AI) in all forms is increasingly driving the development of the Digital Economy, which now encompasses about $16 trillion of global GDP in nominal terms, according to IDCA’s Digital Economy Report 2025. Growth projections for specific revenue for AI companies and initiatives cover a wide range, but several scenarios point to a global market of $1 trillion or more by 2030. Syncing these projections shows that AI is creating at least a 10-to-1 leverage of its use in developing the global digital economy. AI has become an innovation engine, reshaping industries and redefining economic possibilities. From revolutionizing healthcare diagnostics to automating complex manufacturing workflows, AI is accelerating productivity across the board. AI’s convergence with the Internet of Things (IoT), blockchain, and quantum computing fosters robust ecosystems that enable breakthroughs across industries. Companies must adopt AI technologies and position themselves as innovators within this transformative ecosystem. The integration of AI at scale has become a prerequisite for sustaining competitive advantage. AI’s development is progressing into Agentic AI platforms and services, which act as agents for users in various specific tasks. The search for an Artificial General Intelligence (AGI) continues as well. Beyond those frontiers lies the world of quantum computing and AI, which is projected to gain commercial traction within a decade. There are ethical concerns about AI’s development and use, as well as concerns about energy use and emissions levels. The energy use concerns are challenges in providing enough power, nation-by-nation, to meet anticipated demands and sustainably use that power.",
      "word_count": 356,
      "extraction_method": "readability",
      "metadata": {
        "search_position": 2,
        "search_query": "AI global situation",
        "original_title": "Global Artificial Intelligence Report (2025) - IDCA",
        "snippet": "Artificial Intelligence ( AI ) in all forms is increasingly driving the development of the Digital Economy, which now encompasses about $16 trillion of global GDP in nominal terms, according to IDCA’s Digital Economy Report 2025."
      },
      "timestamp": "2026-02-17T01:51:05.719208",
      "error": null
    },
    {
      "url": "https://www.ropesgray.com/en/insights/alerts/2025/11/artificial-intelligence-q3-2025-global-report",
      "title": "Artificial Intelligence Q3 2025 Global Report | Insights ...",
      "content": "",
      "word_count": 0,
      "extraction_method": "failed",
      "metadata": {},
      "timestamp": "2026-02-17T01:51:08.834811",
      "error": "HTTP 403"
    },
    {
      "url": "https://en.wikipedia.org/wiki/AI_regulation",
      "title": "Regulation of artificial intelligence - Wikipedia",
      "content": "Guidelines and laws to regulate AI Regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI). The regulatory and policy landscape for AI is an emerging issue in jurisdictions worldwide, including for international organizations without direct enforcement power like the IEEE or the OECD . [ 1 ] Since 2016, numerous AI ethics guidelines have been published in order to maintain social control over the technology. [ 2 ] Furthermore, organizations deploying AI have a central role to play in creating and implementing trustworthy AI , adhering to established principles, and taking accountability for mitigating risks. [ 3 ] The European Union adopted in 2024 a common legal framework for AI with the AI Act . [ 4 ] According to Stanford University 's 2025 AI Index, legislative mentions of AI rose 21.3% across 75 countries since 2023, marking a ninefold increase since 2016. The U.S. federal agencies introduced 59 AI-related regulations in 2024—more than double the number in 2023. [ 5 ] [ 6 ] In 2024, nearly 700 AI-related bills were introduced across 45 states, up from 191 in 2023. [ 7 ] There is currently no broad consensus on the degree or mechanics of AI regulation. Several prominent figures in the field, including Elon Musk , Sam Altman , Dario Amodei , and Demis Hassabis have publicly called for immediate regulation of AI. [ 8 ] [ 9 ] [ 10 ] [ 11 ] In 2023, following ChatGPT-4 's creation, Elon Musk and others signed an open letter urging a moratorium on the training of more powerful AI systems. [ 12 ] Others, such as Mark Zuckerberg and Marc Andreessen , have warned about the risk of preemptive regulation stifling innovation. [ 13 ] [ 14 ] In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". [ 5 ] Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity. [ 15 ] In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\". [ 16 ] [ 17 ] In 2023 the United Kingdom started a series of international summits on AI with the AI Safety Summit . It was followed by the AI Seoul Summit in 2024, and the AI Action Summit in Paris in 2025. [ 18 ] The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI. [ 19 ] Public administration and policy considerations generally focus on the technical and economic implications and on trustworthy and human-centered AI systems, [ 20 ] regulation of artificial superintelligence , [ 21 ] the risks and biases of machine-learning algorithms, the explainability of model outputs, [ 22 ] and the tension between open source AI and unchecked AI use. [ 23 ] [ 24 ] [ 25 ] There have been both hard law and soft law proposals to regulate AI. [ 26 ] Some legal scholars have noted that hard law approaches to AI regulation have substantial challenges. [ 27 ] [ 28 ] Among the challenges, AI technology is rapidly evolving leading to a \"pacing problem\" where traditional laws and regulations often cannot keep up with emerging applications and their associated risks and benefits. [ 27 ] [ 28 ] Similarly, the diversity of AI applications challenges existing regulatory agencies, which often have limited jurisdictional scope. [ 27 ] As an alternative, some legal scholars argue that soft law approaches to AI regulation are promising, as they offer greater flexibility to adapt to emerging technologies and the evolving nature of AI applications. [ 27 ] [ 28 ] However, soft law approaches often lack substantial enforcement potential. [ 27 ] [ 29 ] Cason Schmit, Megan Doerr, and Jennifer Wagner proposed the creation of a quasi-governmental regulator by leveraging intellectual property rights (i.e., copyleft licensing) in certain AI objects (i.e., AI models and training datasets) and delegating enforcement rights to a designated enforcement entity. [ 30 ] They argue that AI can be licensed under terms that require adherence to specified ethical practices and codes of conduct. (e.g., soft law principles). [ 30 ] Some policy proposals seek to regulate advanced “frontier” AI systems by restricting or licensing the publication of models, while other approaches emphasize regulating how AI is deployed in specific settings. In an article for IEEE Spectrum , technologist John deVadoss argued that model-centric measures—such as licensing training runs or restricting the release of model weights—are difficult to enforce once software artifacts are copied and redistributed, and that restrictions on publishing model code or weights could face constitutional challenges in the United States. He instead advocated a risk-tiered, “use-based” regime in which obligations scale with deployment context (for example, disclosure and acceptable-use policies for general consumer interaction; risk assessment and human oversight for decision support; and rigorous testing, monitoring, and incident reporting for safety-critical uses), with enforcement focused on practical “chokepoints” such as app stores, cloud platforms, and payment systems. [ 31 ] The European Union’s Artificial Intelligence Act similarly follows a risk-based framework that assigns different obligations to providers and users according to an AI system’s risk level, and it includes transparency requirements for generative AI alongside additional oversight for high-impact general-purpose models. [ 32 ] Prominent youth organizations focused on AI, namely Encode AI, have also issued comprehensive agendas calling for more stringent AI regulations and public-private partnerships . [ 33 ] [ 34 ] AI regulation could derive from basic principles. A 2020 Berkman Klein Center for Internet & Society meta-review of existing sets of principles, such as the Asilomar Principles and the Beijing Principles, identified eight such basic principles: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and respect for human values. [ 35 ] AI law and regulations have been divided into three main topics, namely governance of autonomous intelligence systems, responsibility and accountability for the systems, and privacy and safety issues. [ 36 ] A public administration approach sees a relationship between AI law and regulation, the ethics of AI , and 'AI society', defined as workforce substitution and transformation, social acceptance and trust in AI, and the transformation of human to machine interaction. [ 37 ] The development of public sector strategies for management and regulation of AI is deemed necessary at the local, national, [ 38 ] and international levels [ 39 ] and in a variety of fields, from public service management [ 40 ] and accountability [ 41 ] to law enforcement, [ 39 ] [ 42 ] healthcare (especially the concept of a Human Guarantee), [ 43 ] [ 44 ] [ 45 ] [ 46 ] [ 47 ] the financial sector, [ 38 ] [ 48 ] robotics, [ 49 ] [ 50 ] autonomous vehicles, [ 49 ] the military [ 51 ] and national security, [ 52 ] and international law. [ 53 ] [ 54 ] Henry Kissinger , Eric Schmidt , and Daniel Huttenlocher published a joint statement in November 2021 entitled \"Being Human in an Age of AI\", calling for a government commission to regulate AI. [ 55 ] In 2025, the UK and US governments declined to sign an international agreement on AI at the AI Action Summit in Paris. The agreement was described as proposing an open, inclusive and ethical approach to AI development, including environmental protection measures. US Vice President JD Vance argued that the agreement would be detrimental to the growth of the AI industry. The UK government added that the agreement \"didn't provide enough practical clarity on global governance, nor sufficiently address harder questions around national security\". [ 56 ] As a response to the AI control problem [ edit ] Regulation of AI can be seen as positive social means to manage the AI control problem (the need to ensure long-term beneficial AI), with other social responses such as doing nothing or banning being seen as impractical, and approaches such as enhancing human capabilities through transhumanism techniques like brain-computer interfaces being seen as potentially complementary. [ 57 ] [ 58 ] Regulation of research into artificial general intelligence (AGI) focuses on the role of review boards, from university or corporation to international levels, and on encouraging research into AI safety , [ 58 ] together with the possibility of differential intellectual progress (prioritizing protective strategies over risky strategies in AI development) or conducting international mass surveillance to perform AGI arms control. [ 57 ] For instance, the 'AGI Nanny' is a proposed strategy, potentially under the control of humanity, for preventing the creation of a dangerous superintelligence as well as for addressing other major threats to human well-being, such as subversion of the global financial system , until a true superintelligence can be safely created. It entails the creation of a smarter-than-human, but not superintelligent, AGI system connected to a large surveillance network, with the goal of monitoring humanity and protecting it from danger. [ 57 ] Regulation of conscious, ethically aware AGIs focuses on how to integrate them with existing human society and can be divided into considerations of their legal standing and of their moral rights. [ 57 ] Regulation of AI has been seen as restrictive, with a risk of preventing the development of AGI. [ 49 ] Organizations polled largely agree that companies developing foundation models will be responsible for associated risks (rather than those using it), and that global governance is required to address risks from generative AI . [ 59 ] The development of a global governance board to regulate AI development was suggested at least as early as 2017. [ 60 ] In December 2018, Canada and France announced plans for a G7-backed International Panel on Artificial Intelligence, modeled on the International Panel on Climate Change , to study the global effects of AI on people and economies and to steer AI development. [ 61 ] In 2019, the Panel was renamed the Global Partnership on AI. [ 62 ] [ 63 ] The Global Partnership on Artificial Intelligence (GPAI) was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology, as outlined in the OECD Principles on Artificial Intelligence (2019). [ 64 ] The 15 founding members of the Global Partnership on Artificial Intelligence are Australia, Canada, the European Union, France, Germany, India, Italy, Japan, the Republic of Korea, Mexico, New Zealand, Singapore, Slovenia, the United States and the UK. In 2023, the GPAI has 29 members. [ 65 ] The GPAI Secretariat is hosted by the OECD in Paris, France. GPAI's mandate covers four themes, two of which are supported by the International Centre of Expertise in Montréal for the Advancement of Artificial Intelligence, namely, responsible AI and data governance. A corresponding centre of excellence in Paris will support the other two themes on the future of work, and on innovation and commercialization. GPAI also investigated how AI can be leveraged to respond to the COVID-19 pandemic. [ 64 ] The OECD AI Principles [ 66 ] were adopted in May 2019, and the G20 AI Principles in June 2019. [ 63 ] [ 67 ] [ 68 ] In September 2019 the World Economic Forum issued ten 'AI Government Procurement Guidelines'. [ 69 ] In February 2020, the European Union published its draft strategy paper for promoting and regulating AI. [ 39 ] At the United Nations (UN), several entities have begun to promote and discuss aspects of AI regulation and policy, including the UNICRI Centre for AI and Robotics . [ 52 ] In partnership with INTERPOL, UNICRI's Centre issued the report AI and Robotics for Law Enforcement in April 2019 [ 70 ] and the follow-up report Towards Responsible AI Innovation in May 2020. [ 42 ] At UNESCO 's Scientific 40th session in November 2019, the organization commenced a two-year process to achieve a \"global standard-setting instrument on ethics of artificial intelligence\". In pursuit of this goal, UNESCO forums and conferences on AI were held to gather stakeholder views. A draft text of a Recommendation on the Ethics of AI of the UNESCO Ad Hoc Expert Group was issued in September 2020 and included a call for legislative gaps to be filled. [ 71 ] UNESCO tabled the international instrument on the ethics of AI for adoption at its General Conference in November 2021; [ 64 ] this was subsequently adopted. [ 72 ] While the UN is making progress with the global management of AI, its institutional and legal capability to manage the AGI existential risk is more limited. [ 73 ] Recent research has indicated that countries will also begin to use artificial intelligence as a tool for national cyberdefense. AI is a new factor in the cyber arms industry, as it can be used for defense purposes. Therefore, academics urge that nations should establish regulations for the use of AI, similar to how there are regulations for other military industries. [ 74 ] In recent years, academic researchers have made more efforts to promote multilateral dialogue and policy development, advocating for the adoption of international frameworks that govern the deployment of AI in military and cybersecurity contexts, with a strong emphasis on human rights and international humanitarian law. [ 75 ] Initiatives such as the Munich Convention on AI, Data and Human Rights, which brought together scholars from various academic institutions, have called for a binding international agreement to protect human rights in the age of AI. [ 76 ] A key element of such initiatives is identifying common ground between different regional approaches, such as those of the African Union and the Council of Europe. [ 77 ] On 30 October 2023, the Group of Seven ( G7 ) nations adopted a set of eleven guiding principles relating to the design, development and deployment of advanced artificial intelligence systems. These principles form part of the Hiroshima Process, a framework aimed at ensuring that AI technologies are implemented responsibly across global markets. Alongside these principles, a voluntary Code of Conduct for AI developers was introduced to encourage transparency, accountability, and risk-mitigation in emerging AI models and platforms. [ 78 ] The announcement was welcomed internationally, notably by Ursula von der Leyen , who stated that the initiative reflects the direction of the AI Directive, which was in its final stage of negotiation at the time. New guidelines also aim to establish a coordinated global effort towards the responsible development and use of advanced AI systems. While non-binding, the G7 governments encourage organizations to voluntarily adopt the guidelines, which emphasize a risk-based approach across the AI lifecycle—from pre-deployment risk assessment to post-deployment incident reporting and mitigation. [ 79 ] The AIP&CoC also highlight the importance of AI system security, internal adversarial testing ('red teaming'), public transparency about capabilities and limitations, and governance procedures that include privacy safeguards and content authentication tools. The guidelines additionally promote AI innovation directed at solving global challenges such as climate change and public health, and call for advancing international technical standards. [ 79 ] Looking ahead, the G7 intends to further refine their principles and Code of Conduct in collaboration with other organizations like the OECD , GPAI , and broader stakeholders. Areas of broader development include clearer AI terminology (e.g., \"advanced AI systems\"), the setting of risk benchmarks, and mechanisms for cross-border information sharing on potential AI risks. Despite general alignment on AI safety, analysts have noted that differing regulatory philosophies—such as the EU's prescriptive AI Act versus the U.S.'s sector-specific approach—may challenge global regulatory harmonization. [ 80 ] Regional and national regulation [ edit ] Timeline of strategies, action plans and policy papers setting defining national, regional and international approaches to AI [ 81 ] The regulatory and policy landscape for AI is an emerging issue in regional and national jurisdictions globally, for example in the European Union [ 82 ] and Russia. [ 83 ] Since early 2016, many national, regional and international authorities have begun adopting strategies, actions plans and policy papers on AI. [ 84 ] [ 85 ] These documents cover a wide range of topics such as regulation and governance, as well as industrial strategy, research, talent and infrastructure. [ 20 ] [ 86 ] Different countries have approached the problem in different ways. Regarding the three largest economies, it has been said that \"the United States is following a market-driven approach, China is advancing a state-driven approach, and the EU is pursuing a rights-driven approach.\" [ 87 ] The African Union has increasingly been active in the field. Most importantly, the African Commission on Human and Peoples' Rights published a study on AI and human rights and advocated for an African Framework Convention on AI and Human Rights. [ 88 ] This initiative builds on earlier debates within the AU, particularly discussions on autonomous lethal weapons, which African representatives had previously raised in international forums. [ 75 ] A distinctive feature of the proposed African Framework is its strong emphasis on collective rights, as enshrined in the African Charter on Human and Peoples' Rights . This approach is situated within the broader debate on aligning AI governance with African values, including ethical traditions such as Ubuntu (\"humanity to others\"). [ 89 ] [ 90 ] [ 91 ] In October 2023, the Australian Computer Society , Business Council of Australia , Australian Chamber of Commerce and Industry , Ai Group (aka Australian Industry Group) , Council of Small Business Organisations Australia, and Tech Council of Australia jointly published an open letter calling for a national approach to AI strategy. [ 92 ] The letter backs the federal government establishing a whole-of-government AI taskforce. [ 92 ] Additionally, in August 2024, the Australian government set a Voluntary AI Safety Standard, which was followed by a Proposals Paper later in September of that year, outlining potential guardrails for high-risk AI that could become mandatory. These guardrails include areas such as model testing, transparency, human oversight, and record-keeping, all of which may be enforced through new legislation. As noted, however, Australia has not yet passed AI-specific laws, but existing statutes such as the Privacy Act 1988 , Corporations Act 2001 , and Online Safety Act 2021 all have applications which apply to AI use. [ 93 ] In September 2024, a bill also was introduced which granted the Australian Communications and Media Authority powers to regulate AI-generated misinformation. Several agencies, including the ACMA , ACCC , and Office of the Australian Information Commissioner , are all expected to play roles in future AI regulation. [ 93 ] On September 30, 2021, the Brazilian Chamber of Deputies (Câmara dos Deputados) approved the Brazilian Legal Framework for Artificial Intelligence (Marco Legal da Inteligência Artificial). This legislation aimed to regulate AI development and usage while promoting research and innovation in ethical AI solutions that prioritize culture, justice, fairness, and accountability. [ 94 ] The 10-article bill established several key objectives: developing ethical principles for AI, promoting sustained research investment, and removing barriers to innovation. Article 4 specifically emphasized preventing discriminatory AI solutions, ensuring plurality, and protecting human rights. When the bill was first released to the public, it faced substantial criticism, alarming the government for critical provisions. The underlying issue is that this bill failed to thoroughly and carefully address accountability, transparency, and inclusivity principles. Article VI establishes subjective liability, meaning any individual that is damaged by an AI system and is wishing to receive compensation must specify the stakeholder and prove that there was a mistake in the machine's life cycle. Scholars emphasize that it is out of legal order to assign an individual responsible for proving algorithmic errors given the high degree of autonomy, unpredictability, and complexity of AI systems. [ 95 ] This also drew attention to the currently occurring issues with face recognition systems in Brazil leading to unjust arrests by the police, which would then imply that when this bill is adopted, individuals would have to prove and justify these machine errors. The main controversy of this draft bill was directed to three proposed principles. First, the non-discrimination principle, [ 96 ] suggests that AI must be developed and used in a way that merely mitigates the possibility of abusive and discriminatory practices. Secondly, the pursuit of neutrality principle lists recommendations for stakeholders to mitigate biases; however, with no obligation to achieve this goal. Lastly, the transparency principle states that a system's transparency is only necessary when there is a high risk of violating fundamental rights. As easily observed, the Brazilian Legal Framework for Artificial Intelligence lacks binding and obligatory clauses and is rather filled with relaxed guidelines. In fact, experts emphasize that this bill may even make accountability for AI discriminatory biases even harder to achieve. Compared to the EU's proposal of extensive risk-based regulations, the Brazilian Bill has 10 articles proposing vague and generic recommendations. The Brazilian AI Bill lacks the diverse perspectives that characterized earlier Brazilian internet legislation. When Brazil drafted the Marco Civil da Internet (Brazilian Internet Bill of Rights) in the 2000s, it used a multistakeholder approach that brought together various groups—including government, civil society, academia, and industry—to participate in dialogue, decision-making, and implementation. This collaborative process helps capture different viewpoints and trade-offs among stakeholders with varying interests, ultimately improving transparency and effectiveness in AI regulation. [ 95 ] In May 2023, a new bill was passed, superseding the 2021 bill. It calls for risk assessments of AI systems before deployment and distinguishes \"high risk\" and \"excessive risk\" systems. The latter are characterized by their potential to expose or exploit vulnerabilities and will be subject to regulation by the Executive Branch. [ 97 ] The Pan-Canadian Artificial Intelligence Strategy (2017) is supported by federal funding of Can $125 million with the objectives of increasing the number of outstanding AI researchers and skilled graduates in Canada, establishing nodes of scientific excellence at the three major AI centres, developing 'global thought leadership' on the economic, ethical, policy and legal implications of AI advances and supporting a national research community working on AI. [ 64 ] The Canada CIFAR AI Chairs Program is the cornerstone of the strategy. It benefits from funding of Can$86.5 million over five years to attract and retain world-renowned AI researchers. [ 64 ] The federal government appointed an Advisory Council on AI in May 2019 with a focus on examining how to build on Canada's strengths to ensure that AI advancements reflect Canadian values, such as human rights, transparency and openness. The Advisory Council on AI has established a working group on extracting commercial value from Canadian-owned AI and data analytics. [ 64 ] In 2020, the federal government and Government of Quebec announced the opening of the International Centre of Expertise in Montréal for the Advancement of Artificial Intelligence, which will advance the cause of responsible development of AI. [ 64 ] In June 2022, the government of Canada started a second phase of the Pan-Canadian Artificial Intelligence Strategy. [ 98 ] In November 2022, Canada has introduced the Digital Charter Implementation Act (Bill C-27), which proposes three acts that have been described as a holistic package of legislation for trust and privacy: the Consumer Privacy Protection Act, the Personal Information and Data Protection Tribunal Act, and the Artificial Intelligence & Data Act (AIDA). [ 99 ] [ 100 ] In September 2023, the Canadian Government introduced a Voluntary Code of Conduct for the Responsible Development and Management of Advanced Generative AI Systems. The code, based initially on public consultations, seeks to provide interim guidance to Canadian companies on responsible AI practices. Ultimately, its intended to serve as a stopgap until formal legislation, such as the Artificial Intelligence and Data Act (AIDA), is enacted. [ 101 ] [ 102 ] Moreover, in November 2024, the Canadian government additionally announced the creation of the Canadian Artificial Intelligence Safety Institute (CAISI) as part of a 2.4 billion CAD federal AI investment package. This includes 2 billion CAD to support a new AI Sovereign Computing Strategy and the AI Computing Access Fund, which aims to bolster Canada's advanced computing infrastructure. Further funding includes 700 million CAD for domestic AI development, 1 billion CAD for public supercomputing infrastructure, and 300 million CAD to assist companies in accessing new AI resources. [ 102 ] The regulation of AI in China is mainly governed by the State Council of the People's Republic of China 's July 8, 2017 \"A Next Generation Artificial Intelligence Development Plan\" (State Council Document No. 35), in which the Central Committee of the Chinese Communist Party and the State Council of the PRC urged the governing bodies of China to promote the development of AI up to 2030. Regulation of the issues of ethical and legal support for the development of AI is accelerating, and policy ensures state control of Chinese companies and over valuable data, including storage of data on Chinese users within the country and the mandatory use of People's Republic of China's national standards for AI, including over big data, cloud computing, and industrial software. [ 103 ] [ 104 ] [ 105 ] In 2021, China published ethical guidelines for the use of AI in China which state that researchers must ensure that AI abides by shared human values, is always under human control, and is not endangering public safety. [ 106 ] In 2023, China introduced Interim Measures for the Management of Generative AI Services . [ 107 ] On August 15, 2023, China's first generative AI measures officially came into force, becoming one of the first comprehensive national regulatory frameworks for generative AI. The measures apply to all providers offering generative AI services to the Chinese public, including foreign entities, ultimately setting the rules related to data protection, transparency, and algorithmic accountability. [ 108 ] [ 109 ] In parallel, earlier regulations such as the Chinese government's Deep Synthesis Provisions (effective January 2023) and the Algorithm Recommendation Provisions (effective March 2022) continue to shape China's governance of AI-driven systems, including requirements for watermarking and algorithm filing with the Cyberspace Administration of China (CAC). [ 110 ] Additionally, In October 2023, China also implemented a set of Ethics Review Measures for science and technology, mandating certain ethical assessments of AI projects which were deemed socially sensitive or capable of negatively influencing public opinion. [ 108 ] As of mid-2024, over 1,400 AI algorithms had been already registered under the CAC 's algorithm filing regime, which includes disclosure requirements and penalties for noncompliance. [ 108 ] This layered approach reflects a broader policy process shaped by not only central directives but also academic input, civil society concerns, and public discourse. [ 110 ] Later procedures set out detailed mandatory AI content labeling rules. In 2025, Chinese regulators issued the Measures for Labeling of AI-Generated Synthetic Content. These procedures standardize the use of on-screen disclosure labels and embedded provenance metadata for AI-generated text, images, audio, video, and virtual scenes. Additionally, they introduce a mandatory requirement for online service providers to disclose their name or code and content reference number in the embedded metadata, encourage the use of digital watermarking , require online content platforms to detect or infer AI-generated material and add conspicuous consumer disclosures, and mandate that providers describe their labeling methods in online terms of service. [ 111 ] Although Colombia has not issued specific AI laws, this does not mean there is a lack of frameworks or initiatives to govern it. In fact, there are numerous instruments issued for that purpose, including national policies, ethical frameworks, roadmaps, rulings, and guidelines. In addition, there are other existing regulations applicable to AI systems, such as data protection, intellectual property, consumer laws, and civil liability rules. One of the first specific instruments issued was the CONPES 3920 of 2019, the National Policy on Exploitation of Data (Big Data). The main purpose of this policy was to leverage data in Colombia by creating the conditions to handle it as an asset to generate social and economic value. [ 112 ] Another milestone occurred in 2021, when the National Government published the Ethical Framework for AI in Colombia. It was a soft law guide for public entities, offering recommendations to consider in the management of AI-related projects. [ 113 ] An additional framework for AI was adopted by Colombia in 2022: the Recommendation on the Ethics of Artificial Intelligence by UNESCO. [ 113 ] It includes values and principles applicable in the public and private sectors in all stages of the AI system life cycle. [ 113 ] A regional political commitment on AI was made in 2023, involving Latin American and Caribbean countries. It was called the Declaration of Santiago, whose main purpose is to promote ethical AI in the region. [ 114 ] 2024 was a prolific year in governing AI in Colombia. A roadmap for an ethical and sustainable AI adoption was launched by the National Government. [ 115 ] The Superintendence of Industry and Commerce issued a guide on the processing of personal data in AI systems. [ 116 ] The Judiciary Council published a guideline for the use of AI in the judicial sector. [ 117 ] In the global context, the OECD principles were updated, [ 118 ] the Global Digital Compact by the United Nations was published, [ 119 ] and the UN adopted Resolution A/78/L.49 on safe, trustworthy, and reliable AI systems for sustainable development. [ 120 ] In 2025, a new national policy on AI was issued by the National Government, contained in CONPES 4144. [ 121 ] The ruling T-067/25 by the Constitutional Court provided some rules for access to public information and transparency of algorithms. [ 122 ] Until Congress issues AI regulations, these soft-law documents can guide the design, development, and use of AI systems in Colombia. The Council of Europe (CoE) is an international organization that promotes human rights, democracy and the rule of law. It comprises 46 member states, including all 29 Signatories of the European Union's 2018 Declaration of Cooperation on Artificial Intelligence. The CoE has created a common legal space in which the members have a legal obligation to guarantee rights as set out in the European Convention on Human Rights . Specifically in relation to AI, \"The Council of Europe's aim is to identify intersecting areas between AI and our standards on human rights, democracy and rule of law, and to develop relevant standard setting or capacity-building solutions\". The large number of relevant documents identified by the CoE include guidelines, charters, papers, reports and strategies. [ 123 ] The authoring bodies of these AI regulation documents are not confined to one sector of society and include organizations, companies, bodies and nation-states. [ 71 ] In 2019, the Council of Europe initiated a process to assess the need for legally binding regulation of AI, focusing specifically on its implications for human rights and democratic values. Negotiations on a treaty began in September 2022, involving the 46 member states of the Council of Europe, as well as Argentina, Australia, Canada, Costa Rica, the Holy See, Israel, Japan, Mexico, Peru, the United States of America, and Uruguay, as well as the European Union. On 17 May 2024, the \" Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law \" was adopted. It was opened for signature on 5 September 2024. Although developed by a European organisation, the treaty is open for accession by states from other parts of the world. The first ten signatories were: Andorra, Georgia, Iceland, Norway, Moldova, San Marino, the United Kingdom, Israel, the United States, and the European Union. [ 124 ] [ 125 ] The Czech Republic adopted a National AI Strategy in 2019 and updated it in 2024 with the National AI Strategy of the Czech Republic 2030. [ 126 ] The updated strategy includes a provision to ensure effective legislation, to create codes of ethics for developers and users, to establish supervisory bodies and to promote the ethical use of AI. [ 127 ] The EU is one of the largest jurisdictions in the world and plays an active role in the global regulation of digital technology through the GDPR , [ 128 ] Digital Services Act , and the Digital Markets Act . [ 129 ] [ 130 ] For AI in particular, the Artificial intelligence Act is regarded in 2023 as the most far-reaching regulation of AI worldwide. [ 131 ] [ 132 ] Most European Union (EU) countries have their own national strategies towards regulating AI, but these are largely convergent. [ 71 ] The European Union is guided by a European Strategy on Artificial Intelligence, [ 133 ] supported by a High-Level Expert Group on Artificial Intelligence. [ 134 ] [ 135 ] In April 2019, the European Commission published its Ethics Guidelines for Trustworthy Artificial Intelligence (AI) , [ 136 ] following this with its Policy and investment recommendations for trustworthy Artificial Intelligence in June 2019. [ 137 ] The EU Commission's High Level Expert Group on Artificial Intelligence carries out work on Trustworthy AI, and the commission has issued reports on the Safety and Liability Aspects of AI and on the Ethics of Automated Vehicles. In 2020. the EU Commission sought views on a proposal for AI specific legislation, and that process is ongoing. [ 71 ] On February 2, 2020, the European Commission published its White Paper on Artificial Intelligence – A European approach to excellence and trust . [ 138 ] [ 139 ] The White Paper consists of two main building blocks, an 'ecosystem of excellence' and a 'ecosystem of trust'. The 'ecosystem of trust' outlines the EU's approach for a regulatory framework for AI. In its proposed approach, the Commission distinguishes AI applications based on whether they are 'high-risk' or not. Only high-risk AI applications should be in the scope of a future EU regulatory framework. An AI application is considered high-risk if it operates in a risky sector (such as healthcare, transport or energy) and is \"used in such a manner that significant risks are likely to arise\". For high-risk AI applications, the requirements are mainly about the : \"training data\", \"data and record-keeping\", \"information to be provided\", \"robustness and accuracy\", and \"human oversight\". There are also requirements specific to certain usages such as remote biometric identification. AI applications that do not qualify as 'high-risk' could be governed by a voluntary labeling scheme. As regards compliance and enforcement, the Commission considers prior conformity assessments which could include 'procedures for testing, inspection or certification' and/or 'checks of the algorithms and of the data sets used in the development phase'. A European governance structure on AI in the form of a framework for cooperation of national competent authorities could facilitate the implementation of the regulatory framework. [ 140 ] A January 2021 draft was leaked online on April 14, 2021, [ 141 ] before the Commission presented their official \"Proposal for a Regulation laying down harmonised rules on artificial intelligence\" a week later. [ 142 ] Shortly after, the Artificial Intelligence Act (also known as the AI Act) was formally proposed on this basis. [ 143 ] This proposal includes a refinement of the 2020 risk-based approach with, this time, 4 risk categories: \"minimal\", \"limited\", \"high\" and \"unacceptable\". [ 144 ] The proposal has been severely critiqued in the public debate. Academics have expressed concerns about various unclear elements in the proposal – such as the broad definition of what constitutes AI – and feared unintended legal implications, especially for vulnerable groups such as patients and migrants. [ 145 ] [ 146 ] The risk category \"general-purpose AI\" was added to the AI Act to account for versatile models like ChatGPT , which did not fit the application-based regulation framework. [ 147 ] Unlike for other risk categories, general-purpose AI models can be regulated based on their capabilities, not just their uses. Weaker general-purpose AI models are subject transparency requirements, while those considered to pose \"systemic risks\" (notably those trained using computational capabilities exceeding 10 25 FLOPS ) must also undergo a thorough evaluation process. [ 148 ] A subsequent version of the AI Act was finally adopted in May 2024. [ 149 ] The AI Act will be progressively enforced. [ 150 ] Recognition of emotions and real-time remote biometric identification will be prohibited, with some exemptions, such as for law enforcement. [ 151 ] The European Union's AI Act has created a regulatory framework with significant global implications. This legislation introduces a risk-based approach to categorizing AI systems, focusing on high-risk applications like healthcare, education, and public safety. [ 152 ] It requires organizations to ensure transparency, data governance, and human oversight in their AI solutions. While this aims to foster ethical AI use, the stringent requirements could increase overhead and compliance costs, delaying certain AI designs and deployments. [ 153 ] [ 154 ] [ 155 ] Observers have expressed concerns about the multiplication of legislative proposals under the von der Leyen Commission . The speed of the legislative initiatives is partially led by political ambitions of the EU and could put at risk the digital rights of the European citizens, including rights to privacy, [ 156 ] especially in the face of uncertain guarantees of data protection through cyber security. [ 135 ] Among the stated guiding principles in the variety of legislative proposals in the area of AI under the von der Leyen Commission are the objectives of strategic autonomy [ 157 ] and the concept of digital sovereignty. [ 158 ] On May 29, 2024, the European Court of Auditors published a report stating that EU measures were not well coordinated with those of EU countries; that the monitoring of investments was not systematic; and that stronger governance was needed. [ 159 ] The EU's Artificial Intelligence Act (Regulation (EU) 2024/1689) entered into force on 1 August 2024, creating a risk-based legal framework for AI systems, including special provisions for general-purpose AI models enforceable by 2 August 2025. [ 160 ] Finland has appointed a working group to evaluate what national legislation is required by the EU Artificial intelligence Act , and to prepare a legislative proposal on its national implementation. The working group began its evaluation on April 29, 2024, and is expected to conclude by June 30, 2026. [ 161 ] In November 2020, [ 162 ] DIN , DKE and the German Federal Ministry for Economic Affairs and Energy published the first edition of the \"German Standardization Roadmap for Artificial Intelligence\" (NRM KI) and presented it to the public at the Digital Summit of the Federal Government of Germany. [ 163 ] NRM KI describes requirements to future regulations and standards in the context of AI. The implementation of the recommendations for action is intended to help to strengthen the German economy and science in the international competition in the field of artificial intelligence and create innovation-friendly conditions for this emerging technology . The first edition is a 200-page long document written by 300 experts. The second edition of the NRM KI was published to coincide with the German government's Digital Summit on December 9, 2022. [ 164 ] DIN coordinated more than 570 participating experts from a wide range of fields from science, industry, civil society and the public sector. The second edition is a 450-page long document. On the one hand, NRM KI covers the focus topics in terms of applications (e.g. medicine, mobility, energy & environment, financial services, industrial automation) and fundamental issues (e.g. AI classification, security, certifiability, socio-technical systems, ethics). [ 164 ] On the other hand, it provides an overview of the central terms in the field of AI and its environment across a wide range of interest groups and information sources. In total, the document covers 116 standardisation needs and provides six central recommendations for action. [ 165 ] On October 30, 2022, pursuant to government resolution 212 of August 2021, the Israeli Ministry of Innovation, Science and Technology released its \"Principles of Policy, Regulation and Ethics in AI\" white paper for public consultation. [ 166 ] By December 2023, the Ministry of Innovation and the Ministry of Justice published a joint AI regulation and ethics policy paper, outlining several AI ethical principles and a set of recommendations including opting for sector-based regulation, a risk-based approach, preference for \"soft\" regulatory tools such as AI sandboxes [ 167 ] and maintaining consistency with existing global regulatory approaches to AI. [ 168 ] In December 2023, Israel unveiled its first comprehensive national AI policy, which was jointly developed through a collaboration between ministerial and stakeholder consultation. In general, the new policy outlines ethical principles aligned with current OECD guidelines and recommends a sector-based, risk-driven regulatory framework, which focuses on areas like transparency and accountability. [ 169 ] The policy proposes the creation of a national AI Policy Coordination Center to support regulators, and further developing the tools necessary for responsible AI deployment. In addition, alongside 56 other nations, to domestic policy development, Israel signed the world's first binding international treaty on artificial intelligence in March 2024. The specific treaty, led by the Council of Europe , has obliged signatories to ensure current AI systems uphold democratic values, human rights, and the rule of law. [ 170 ] In October 2023, the Italian privacy authority approved a regulation that provides three principles for therapeutic decisions taken by automated systems: transparency of decision-making processes, human supervision of automated decisions and algorithmic non-discrimination. [ 171 ] In March 2024, the President of the Italian Data Protection Authority reaffirmed their agency's readiness to implement the European Union's newly introduced Artificial Intelligence Act , praising the framework of institutional competence and independence. [ 172 ] Italy has continued to develop guidance on AI applications through existing legal frameworks, including recent innovations in areas such as facial recognition for law enforcement, AI in healthcare, deepfakes , and smart assistants . [ 173 ] The Italian government's National AI Strategy (2022–2024) emphasizes responsible innovation and outlines goals for talent development, public and private sector adoption, and regulatory clarity, particularly in coordination with EU-level initiatives. [ 172 ] While Italy has not enacted standalone AI legislation, courts and regulators have begun interpreting existing laws to address transparency, non-discrimination, and human oversight in algorithmic decision-making. In Morocco, a new legislative proposal has been put forward by a coalition of political parties in Parliament to establish the National Agency for Artificial Intelligence (AI). This agency is intended to regulate AI technologies, enhance collaboration with international entities in the field, and increase public awareness of both the possibilities and risks associated with AI. [ 174 ] In recent years, Morocco has made efforts to advance its use of artificial intelligence in the legal sector, particularly through AI tools that assist with judicial prediction and document analysis, helping to streamline case law research and support legal practitioners with more complex tasks. Alongside these efforts to establish a national AI agency, AI is being gradually introduced into legislative and judicial processes in Morocco, with ongoing discussions emphasizing the benefits as well as the potential risks of these technologies. [ 175 ] Generally speaking Morocco's broader digital policy includes robust data governance measures including the 2009 Personal Data Protection Law and the 2020 Cybersecurity Law, which establish requirements in areas such as privacy, breach notification, and data localization. [ 175 ] As of 2024, additional decrees have also expanded cybersecurity standards for cloud infrastructure and data audits within the nation. And while general data localization is not mandated, sensitive government and critical infrastructure data must be stored domestically. Oversight is led by the National Commission for the Protection of Personal Data (CNDP) and the General Directorate of Information Systems Security (DGSSI), though public enforcement actions in the country remain limited. [ 175 ] As of July 2023 [update] , no AI-specific legislation exists, but AI usage is regulated by existing laws, including the Privacy Act , the Human Rights Act , the Fair Trading Act and the Harmful Digital Communications Act . [ 176 ] In 2020, the New Zealand Government sponsored a World Economic Forum pilot project titled \"Reimagining Regulation for the Age of AI\", aimed at creating regulatory frameworks around AI. [ 177 ] The same year, the Privacy Act was updated to regulate the use of New Zealanders' personal information in AI. [ 178 ] In 2023, the Privacy Commissioner released guidance on using AI in accordance with information privacy principles. [ 179 ] In February 2024, the Attorney-General and Technology Minister announced the formation of a Parliamentary cross-party AI caucus , and that framework for the Government's use of AI was being developed. She also announced that no extra regulation was planned at that stage. [ 180 ] In 2023, a bill was filed in the Philippine House of Representatives which proposed the establishment of the Artificial Intelligence Development Authority (AIDA) which would oversee the development and research of artificial intelligence. AIDA was also proposed to be a watchdog against crimes using AI. [ 181 ] The Commission on Elections has also considered in 2024 the ban of using AI and deepfake for campaigning. They look to implement regulations that would apply as early as for the 2025 general elections. [ 182 ] In 2018, the Spanish Ministry of Science, Innovation and Universities approved an R&D Strategy on Artificial Intelligence. [ 183 ] With the formation of the second government of Pedro Sánchez in January 2020, the areas related to new technologies that, since 2018, were in the Ministry of Economy , were strengthened. Thus, in 2020 the Secretariat of State for Digitalization and Artificial Intelligence (SEDIA) was created. [ 184 ] From this higher body, following the recommendations made by the R&D Strategy on Artificial Intelligence of 2018, [ 185 ] the National Artificial Intelligence Strategy (2020) was developed, which already provided for actions concerning the governance of artificial intelligence and the ethical standards that should govern its use. This project was also included within the Recovery, Transformation and Resilience Plan (2021). During 2021, [ 184 ] the Government revealed that these ideas would be developed through a new government agency, and the General State Budget for 2022 authorized its creation and allocated five million euros for its development. [ 186 ] The Council of Ministers , at its meeting on 13 September 2022, began the process for the election of the AESIA headquarters. [ 187 ] [ 188 ] 16 Spanish provinces presented candidatures, with the Government opting for A Coruña , which proposed the La Terraza building. [ 189 ] On 22 August 2023, the Government approved the internal regulations of the Agency. [ 190 ] With this, Spain became the first European country with an agency dedicated to the supervision of AI, anticipating the entry into force of the future European Regulation on Artificial Intelligence, [ 191 ] which establishes the need for Member States to have with a supervisory authority in this matter. The agency officially launched its operations on 19 June 2024. [ 192 ] In April 2025, it became the reinforcing body for Spain's new law against unlabeled AI-generated content. [ 193 ] Switzerland currently has no specific AI legislation, but on 12 February 2025, the Federal Council announced plans to ratify the Council of Europe 's AI Convention and incorporate it into Swiss law. A draft bill and implementation plan are to be prepared by the end of 2026. The approach includes sector-specific regulation, limited cross-sector rules, such as data protection, and non-binding measures such as industry agreements. The goals are to support innovation, protect fundamental rights, and build public trust in AI. [ 194 ] The UK supported the application and development of AI in business via the Digital Economy Strategy 2015–2018 [ 195 ] introduced at the beginning of 2015 by Innovate UK as part of the UK Digital Strategy. [ 195 ] In the public sector, the Department for Digital, Culture, Media and Sport advised on data ethics and the Alan Turing Institute provided guidance on responsible design and implementation of AI systems. [ 196 ] [ 197 ] In terms of cyber security, in 2020 the National Cyber Security Centre has issued guidance on 'Intelligent Security Tools'. [ 52 ] [ 198 ] The following year, the UK published its 10-year National AI Strategy, [ 199 ] which describes actions to assess long-term AI risks, including AGI-related catastrophic risks. [ 200 ] In March 2023, the UK released the white paper A pro-innovation approach to AI regulation . [ 201 ] This white paper presents general AI principles, but leaves significant flexibility to existing regulators in how they adapt these principles to specific areas such as transport or financial markets. [ 202 ] In November 2023, the UK hosted the first AI safety summit , with the prime minister Rishi Sunak aiming to position the UK as a leader in AI safety regulation. [ 203 ] [ 204 ] During the summit, the UK created an AI Safety Institute , as an evolution of the Frontier AI Taskforce led by Ian Hogarth . The institute was notably assigned the responsibility of advancing the safety evaluations of the world's most advanced AI models, also called frontier AI models . [ 205 ] The UK government indicated its reluctance to legislate early, arguing that it may reduce the sector's growth and that laws might be rendered obsolete by further technological progress. [ 206 ] Discussions on regulation of AI in the United States have included topics such as the timeliness of regulating AI, the nature of the federal regulatory framework to govern and promote AI, including what agency should lead, the regulatory and governing powers of that agency, and how to update regulations in the face of rapidly changing technology, as well as the roles of state governments and courts. [ 207 ] On 12 December 2025, President Trump signed an executive order preventing states from creating their own AI restrictions, thereby forcing all states to follow the \"single national framework\". [ 208 ] “This is an executive order that orders aspects of your administration to take decisive action to ensure that AI can operate within a single national framework in this country, as opposed to being subject to state level regulation that could potentially cripple the industry”, White House aide Will Scharf said in the Oval Office, commenting on the executive order. Walter Donway, writing for a publication of the American Institute for Economic Research , criticized the order, saying, \"The premise behind it is philosophically wrong: that a central authority can foresee the risks of an emergent technology better than the distributed knowledge of millions of actors operating within a free market. That premise was wrong when applied to railroads, radio, electricity, telephony, airlines, and nuclear power. It is even more disastrously wrong when applied to artificial intelligence.\" [ 209 ] Regulation of fully autonomous weapons [ edit ] Legal questions related to lethal autonomous weapons systems (LAWS), in particular compliance with the laws of armed conflict , have been under discussion at the United Nations since 2013, within the context of the Convention on Certain Conventional Weapons . [ 210 ] Notably, informal meetings of experts took place in 2014, 2015 and 2016 and a Group of Governmental Experts (GGE) was appointed to further deliberate on the issue in 2016. A set of guiding principles on LAWS affirmed by the GGE on LAWS were adopted in 2018. [ 211 ] In 2016, China published a position paper questioning the adequacy of existing international law to address the eventuality of fully autonomous weapons, becoming the first permanent member of the U.N. Security Council to broach the issue, [ 53 ] and leading to proposals for global regulation. [ 212 ] The possibility of a moratorium or preemptive ban of the development and use of LAWS has also been raised on several occasions by other national delegations to the Convention on Certain Conventional Weapons and is strongly advocated for by the Campaign to Stop Killer Robots – a coalition of non-governmental organizations. [ 213 ] The US government maintains that current international humanitarian law is capable of regulating the development or use of LAWS. [ 214 ] The Congressional Research Service indicated in 2023 that the US does not have LAWS in its inventory, but that its policy does not prohibit the development and employment of it. [ 215 ] ^ Tallberg, Jonas; Erman, Eva; Furendal, Markus; Geith, Johannes; Klamberg, Mark; Lundgren, Magnus (2023). \"Global Governance of Artificial Intelligence: Next Steps for Empirical and Normative Research\" . International Studies Review . 25 (3) viad040. arXiv : 2305.11528 . doi : 10.1093/isr/viad040 . ^ Héder, M (2020). \"A criticism of AI ethics guidelines\" . Információs Társadalom . 20 (4): 57– 73. doi : 10.22503/inftars.XX.2020.4.5 . S2CID 233252939 . ^ Curtis, Caitlin; Gillespie, Nicole; Lockey, Steven (2022-05-24). \"AI-deploying organizations are key to addressing 'perfect storm' of AI risks\" . AI and Ethics . 3 (1): 145– 153. doi : 10.1007/s43681-022-00163-7 . ISSN 2730-5961 . PMC 9127285 . PMID 35634256 . ^ \"Europe sets benchmark for rest of the world with landmark AI laws\" . Reuters . 2024-05-22. ^ a b Vincent, James (3 April 2023). \"AI is entering an era of corporate control\" . The Verge . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . ^ \"Artificial Intelligence Index Report 2025\" . Human-Centered Artificial Intelligence . Stanford University . 2025. Archived from the original on 16 June 2025 . Retrieved 16 June 2025 . {{ cite web }} : CS1 maint: bot: original URL status unknown ( link ) ^ \"2025 State AI Wave Building After 700 Bills in 2024\" . www.bsa.org . Retrieved 2025-08-08 . ^ Varanasi, Lakshmi. \"OpenAI's Sam Altman says an international agency should monitor the 'most powerful' AI to ensure 'reasonable safety' \" . Business Insider . Archived from the original on 2025-04-09 . Retrieved 16 June 2025 . ^ Aloisi, Silva (19 June 2023). \"Elon Musk repeats call for artificial intelligence regulation\" . Reuters . Retrieved 16 June 2025 . ^ Milmo, Dqan (24 October 2023). \"This article is more than 1 year old AI risk must be treated as seriously as climate crisis, says Google DeepMind chief\" . The Guardian . Retrieved 16 June 2025 . ^ Sherry, Ben (5 June 2025). \"Why Anthropic CEO Dario Amodei Is Asking for AI Regulation\" . Inc . Retrieved 16 June 2025 . ^ \"Pause Giant AI Experiments: An Open Letter\" . Future of Life Institute . Retrieved 2025-06-16 . ^ Goldman, Sharon. \"How Mark Zuckerberg has fully rebuilt Meta around Llama\" . Fortune . Retrieved 16 June 2025 . ^ Heath, Ryan (17 October 2023). \"Civilization depends on more AI, Marc Andreessen says\" . Axios . Retrieved 16 June 2025 . ^ Edwards, Benj (17 May 2023). \"Poll: AI poses risk to humanity, according to majority of Americans\" . Ars Technica . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . ^ Kasperowicz, Peter (1 May 2023). \"Regulate AI? GOP much more skeptical than Dems that government can do it right: poll\" . Fox News . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . ^ \"Fox News Poll\" (PDF) . Fox News. 2023. Archived (PDF) from the original on 12 May 2023 . Retrieved 19 June 2023 . ^ Neuillé, Hugo (2025-02-05). \"From Safety To Action: The Upcoming French AI Summit | TechPolicy.Press\" . Tech Policy Press . Retrieved 2025-08-25 . ^ Barfield, Woodrow; Pagallo, Ugo (2018). Research handbook on the law of artificial intelligence . Cheltenham, UK: Edward Elgar Publishing. ISBN 978-1-78643-904-8 . OCLC 1039480085 . ^ a b Artificial intelligence in society . Paris: Organisation for Economic Co-operation and Development. 11 June 2019. ISBN 978-92-64-54519-9 . OCLC 1105926611 . ^ Kamyshansky, Vladimir P.; Rudenko, Evgenia Y.; Kolomiets, Evgeniy A.; Kripakova, Dina R. (2020). \"Revisiting the Place of Artificial Intelligence in Society and the State\". Artificial Intelligence: Anthropogenic Nature vs. Social Origin . Advances in Intelligent Systems and Computing. Vol. 1100. Cham: Springer International Publishing. pp. 359– 364. doi : 10.1007/978-3-030-39319-9_41 . ISBN 978-3-030-39318-2 . S2CID 213070224 . ^ Buiten, Miriam C. (2019). \"Towards Intelligent Regulation of Artificial Intelligence\" . European Journal of Risk Regulation . 10 (1): 41– 59. doi : 10.1017/err.2019.8 . ^ \"Co-Governance and the Future of AI Regulation\" . Harvard Law Review . 10 April 2025 . Retrieved 16 June 2025 . ^ \"Not all AI models should be freely available, argues a legal scholar\" . The Economist . Retrieved 16 June 2025 . ^ \"Keep the code behind AI open, say two entrepreneurs\" . The Economist . Retrieved 16 June 2025 . ^ \"Special Issue on Soft Law Governance of Artificial Intelligence: IEEE Technology and Society Magazine publication information\" . IEEE Technology and Society Magazine . 40 (4): C2. December 2021. doi : 10.1109/MTS.2021.3126194 . ^ a b c d e Marchant, Gary. \" \"Soft Law\" Governance of AI\" (PDF) . AI Pulse . AI PULSE Papers. Archived (PDF) from the original on 21 March 2023 . Retrieved 28 February 2023 . ^ a b c Johnson, Walter G.; Bowman, Diana M. (December 2021). \"A Survey of Instruments and Institutions Available for the Global Governance of Artificial Intelligence\". IEEE Technology and Society Magazine . 40 (4): 68– 76. Bibcode : 2021ITSMg..40d..68J . doi : 10.1109/MTS.2021.3123745 . S2CID 245053179 . ^ Sutcliffe, Hillary R.; Brown, Samantha (December 2021). \"Trust and Soft Law for AI\". IEEE Technology and Society Magazine . 40 (4): 14– 24. Bibcode : 2021ITSMg..40d..14S . doi : 10.1109/MTS.2021.3123741 . S2CID 244955938 . ^ a b Schmit, C. D.; Doerr, M. J.; Wagner, J. K. (17 February 2023). \"Leveraging IP for AI governance\". Science . 379 (6633): 646– 648. Bibcode : 2023Sci...379..646S . doi : 10.1126/science.add2202 . PMID 36795826 . S2CID 256901479 . ^ deVadoss, John. \"Don't Regulate AI Models. Regulate AI Use\" . IEEE Spectrum . IEEE . Retrieved 2026-02-02 . ^ \"EU AI Act: first regulation on artificial intelligence\" . European Parliament . European Parliament. 2023-06-08 . Retrieved 2026-02-02 . ^ Lima-Strong, Cristiano (16 May 2024). \"Youth activists call on world leaders to set AI safeguards by 2030\" . Washington Post . Retrieved 24 June 2024 . ^ Haldane, Matt (21 May 2024). \"Student AI activists at Encode Justice release 22 goals for 2030 ahead of global summit in Seoul\" . Archived from the original on 25 September 2024 . Retrieved 24 June 2024 . ^ Fjeld, Jessica; Achten, Nele; Hilligoss, Hannah; Nagy, Adam; Srikumar, Madhu (2020-01-15). Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-based Approaches to Principles for AI (Report). Berkman Klein Center for Internet & Society. Archived from the original on 2021-07-16 . Retrieved 2021-07-04 . ^ Wirtz, Bernd W.; Weyerer, Jan C.; Geyer, Carolin (2018-07-24). \"Artificial Intelligence and the Public Sector—Applications and Challenges\" . International Journal of Public Administration . 42 (7): 596– 615. doi : 10.1080/01900692.2018.1498103 . ISSN 0190-0692 . S2CID 158829602 . Archived from the original on 2020-08-18 . Retrieved 2020-08-17 . ^ Wirtz, Bernd W.; Weyerer, Jan C.; Sturm, Benjamin J. (2020-04-15). \"The Dark Sides of Artificial Intelligence: An Integrated AI Governance Framework for Public Administration\". International Journal of Public Administration . 43 (9): 818– 829. doi : 10.1080/01900692.2020.1749851 . ISSN 0190-0692 . S2CID 218807452 . ^ a b Bredt, Stephan (2019-10-04). \"Artificial Intelligence (AI) in the Financial Sector—Potential and Public Strategies\" . Frontiers in Artificial Intelligence . 2 16. doi : 10.3389/frai.2019.00016 . ISSN 2624-8212 . PMC 7861258 . PMID 33733105 . ^ a b c White Paper: On Artificial Intelligence – A European approach to excellence and trust (PDF) . Brussels: European Commission. 2020. p. 1. ^ Wirtz, Bernd W.; Müller, Wilhelm M. (2018-12-03). \"An integrated artificial intelligence framework for public management\". Public Management Review . 21 (7): 1076– 1100. doi : 10.1080/14719037.2018.1549268 . ISSN 1471-9037 . S2CID 158267709 . ^ Reisman, Dillon; Schultz, Jason; Crawford, Kate; Whittaker, Meredith (2018). Algorithmic impact assessments: A practical framework for public agency accountability (PDF) . New York: AI Now Institute. Archived from the original (PDF) on 2020-06-14 . Retrieved 2020-04-28 . ^ a b \"Towards Responsible Artificial Intelligence Innovation\" . UNICRI . July 2020. Archived from the original on 2022-07-05 . Retrieved 2022-07-18 . ^ Kohli, Ajay; Mahajan, Vidur; Seals, Kevin; Kohli, Ajit; Jha, Saurabh (2019). \"Concepts in U.S. Food and Drug Administration Regulation of Artificial Intelligence for Medical Imaging\". American Journal of Roentgenology . 213 (4): 886– 888. doi : 10.2214/ajr.18.20410 . ISSN 0361-803X . PMID 31166758 . S2CID 174813195 . ^ Hwang, Thomas J.; Kesselheim, Aaron S.; Vokinger, Kerstin N. (2019-12-17). \"Lifecycle Regulation of Artificial Intelligence– and Machine Learning–Based Software Devices in Medicine\". JAMA . 322 (23): 2285– 2286. doi : 10.1001/jama.2019.16842 . ISSN 0098-7484 . PMID 31755907 . S2CID 208230202 . ^ Sharma, Kavita; Manchikanti, Padmavati (2020-10-01). \"Regulation of Artificial Intelligence in Drug Discovery and Health Care\". Biotechnology Law Report . 39 (5): 371– 380. doi : 10.1089/blr.2020.29183.ks . ISSN 0730-031X . S2CID 225540889 . ^ Petkus, Haroldas; Hoogewerf, Jan; Wyatt, Jeremy C (2020). \"What do senior physicians think about AI and clinical decision support systems: Quantitative and qualitative analysis of data from specialty societies\" . Clinical Medicine . 20 (3): 324– 328. doi : 10.7861/clinmed.2019-0317 . ISSN 1470-2118 . PMC 7354034 . PMID 32414724 . ^ Cheng, Jerome Y.; Abel, Jacob T.; Balis, Ulysses G.J.; McClintock, David S.; Pantanowitz, Liron (2021). \"Challenges in the Development, Deployment, and Regulation of Artificial Intelligence in Anatomic Pathology\" . The American Journal of Pathology . 191 (10): 1684– 1692. doi : 10.1016/j.ajpath.2020.10.018 . ISSN 0002-9440 . PMID 33245914 . S2CID 227191875 . ^ \"AI in Lending: AI Credit Regulations Affecting Lending Business 2025\" . hesfintech . 10 October 2025. Archived from the original on 12 October 2025 . Retrieved 12 October 2025 . ^ a b c Gurkaynak, Gonenc; Yilmaz, Ilay; Haksever, Gunes (2016). \"Stifling artificial intelligence: Human perils\". Computer Law & Security Review . 32 (5): 749– 758. doi : 10.1016/j.clsr.2016.05.003 . ISSN 0267-3649 . ^ Iphofen, Ron; Kritikos, Mihalis (2019-01-03). \"Regulating artificial intelligence and robotics: ethics by design in a digital society\". Contemporary Social Science . 16 (2): 170– 184. doi : 10.1080/21582041.2018.1563803 . ISSN 2158-2041 . S2CID 59298502 . ^ AI principles: Recommendations on the ethical use of artificial intelligence by the Department of Defense (PDF) . Washington, DC: United States Defense Innovation Board. 2019. OCLC 1126650738 . Archived from the original (PDF) on 2020-01-14 . Retrieved 2020-03-28 . ^ a b c Babuta, Alexander; Oswald, Marion; Janjeva, Ardi (2020). Artificial Intelligence and UK National Security: Policy Considerations (PDF) . London: Royal United Services Institute. Archived from the original (PDF) on 2020-05-02 . Retrieved 2020-04-28 . ^ a b \"Robots with Guns: The Rise of Autonomous Weapons Systems\" . Snopes.com . 21 April 2017. Archived from the original on 25 September 2024 . Retrieved 24 December 2017 . ^ Bento, Lucas (2017). \"No Mere Deodands: Human Responsibilities in the Use of Violent Intelligent Systems Under Public International Law\" . Harvard Scholarship Depository . Archived from the original on 2020-03-23 . Retrieved 2019-09-14 . ^ Kissinger, Henry (1 November 2021). \"The Challenge of Being Human in the Age of AI\" . The Wall Street Journal . Archived from the original on 4 November 2021 . Retrieved 4 November 2021 . ^ \"UK and US refuse to sign international AI declaration\" . BBC News . 2025-02-11 . Retrieved 2025-08-25 . ^ a b c d Sotala, Kaj; Yampolskiy, Roman V (2014-12-19). \"Responses to catastrophic AGI risk: a survey\" . Physica Scripta . 90 (1) 018001. Bibcode : 2015PhyS...90a8001S . doi : 10.1088/0031-8949/90/1/018001 . ISSN 0031-8949 . ^ a b Barrett, Anthony M.; Baum, Seth D. (2016-05-23). \"A model of pathways to artificial superintelligence catastrophe for risk and decision analysis\". Journal of Experimental & Theoretical Artificial Intelligence . 29 (2): 397– 414. arXiv : 1607.07730 . doi : 10.1080/0952813x.2016.1186228 . ISSN 0952-813X . S2CID 928824 . ^ \"AI Index Report 2024 - chapter 3: Responsible AI\" (PDF) . aiindex.stanford.edu . April 2024. Archived (PDF) from the original on 2024-05-24 . Retrieved 2024-06-07 . ^ Boyd, Matthew; Wilson, Nick (2017-11-01). \"Rapid developments in Artificial Intelligence: how might the New Zealand government respond?\" . Policy Quarterly . 13 (4). doi : 10.26686/pq.v13i4.4619 . ISSN 2324-1101 . ^ Innovation, Science and Economic Development Canada (2019-05-16). \"Declaration of the International Panel on Artificial Intelligence\" . gcnws . Archived from the original on 2020-03-29 . Retrieved 2020-03-29 . ^ Simonite, Tom (2020-01-08). \"The world has a plan to rein in AI—but the US doesn't like it\" . Wired . Archived from the original on 2020-04-18 . Retrieved 2020-03-29 . ^ a b \"AI Regulation: Has the Time Arrived?\" . InformationWeek . 24 February 2020. Archived from the original on 2020-05-23 . Retrieved 2020-03-29 . ^ a b c d e f g UNESCO Science Report: the Race Against Time for Smarter Development . Paris: UNESCO. 11 June 2021. ISBN 978-92-3-100450-6 . Archived from the original on 18 June 2022 . Retrieved 18 September 2021 . ^ \"Community\" . GPAI . Archived from the original on March 30, 2023. ^ \"AI-Principles Overview\" . OECD.AI . Archived from the original on 2023-10-23 . Retrieved 2023-10-20 . ^ G20 Ministerial Statement on Trade and Digital Economy (PDF) . Tsukuba City, Japan: G20. 2019. ^ \"International AI ethics panel must be independent\" . Nature . 572 (7770): 415. 2019-08-21. Bibcode : 2019Natur.572R.415. . doi : 10.1038/d41586-019-02491-x . PMID 31435065 . ^ Guidelines for AI Procurement (PDF) . Cologny/Geneva: World Economic Forum. 2019. Archived (PDF) from the original on 2020-07-17 . Retrieved 2020-04-28 . ^ \"High-Level Event: Artificial Intelligence and Robotics – Reshaping the Future of Crime, Terrorism and Security\" . UNICRI . Archived from the original on 2022-07-18 . Retrieved 2022-07-18 . ^ a b c d NíFhaoláin, Labhaoise; Hines, Andrew; Nallur, Vivek (2020). Assessing the Appetite for Trustworthiness and the Regulation of Artificial Intelligence in Europe (PDF) . Dublin: Technological University Dublin, School of Computer Science, Dublin. pp. 1– 12. Archived (PDF) from the original on 2021-01-15 . Retrieved 2021-03-27 . This article incorporates text available under the CC BY 4.0 license. (The CC BY 4.0 licence means that everyone have the right to reuse the text that is quoted here, or other parts of the original article itself, if they credit the authors. More info: Creative Commons license ) Changes were made as follows: citations removed and minor grammatical amendments. ^ \"Recommendation on the ethics of artificial intelligence\" . UNESCO . 2020-02-27. Archived from the original on 2022-07-18 . Retrieved 2022-07-18 . ^ Nindler, Reinmar (2019-03-11). \"The United Nation's Capability to Manage Existential Risks with a Focus on Artificial Intelligence\" . International Community Law Review . 21 (1): 5– 34. doi : 10.1163/18719732-12341388 . ISSN 1871-9740 . S2CID 150911357 . Archived from the original on 2022-08-30 . Retrieved 2022-08-30 . ^ Taddeo, Mariarosaria; Floridi, Luciano (April 2018). \"Regulate artificial intelligence to avert cyber arms race\" . Nature . 556 (7701): 296– 298. Bibcode : 2018Natur.556..296T . doi : 10.1038/d41586-018-04602-6 . PMID 29662138 . ^ a b \"Promoting and Advancing Human Rights in Global AI Ecosystems\" . AI Ethics Lab at Rutgers University . 2025. Archived from the original on 17 March 2025 . Retrieved 28 June 2025 . ^ \"The Munich Convention on AI, Data and Human Rights\" . ResearchGate . October 2024. ^ Fourie, Willem (2025-08-20). \"Stellenbosch dialogue advances AI and human rights convention\" . The Policy Innovation Lab . Retrieved 2025-08-25 . ^ \"Hiroshima Process International Guiding Principles for Advanced AI system | Shaping Europe's digital future\" . digital-strategy.ec.europa.eu . 2023-10-30. Archived from the original on 2023-11-01 . Retrieved 2023-11-01 . ^ a b \"G7 AI Principles and Code of Conduct\" . Ernst & Young . January 19, 2024 . Retrieved May 7, 2025 . ^ Schildkraut, Peter J. (January 19, 2024). \"What the G7 Code of Conduct Means for Global AI Compliance Programs\" . Arnold & Porter . Retrieved May 8, 2025 . ^ \"Artificial Intelligence and Robotics\" . UNICRI . Archived from the original on 2020-10-19 . Retrieved 2020-08-08 . ^ Law Library of Congress (U.S.). Global Legal Research Directorate, issuing body. Regulation of artificial intelligence in selected jurisdictions . LCCN 2019668143 . OCLC 1110727808 . ^ Popova, Anna V.; Gorokhova, Svetlana S.; Abramova, Marianna G.; Balashkina, Irina V. (2021), The System of Law and Artificial Intelligence in Modern Russia: Goals and Instruments of Digital Modernization , Studies in Systems, Decision and Control, vol. 314, Cham: Springer International Publishing, pp. 89– 96, doi : 10.1007/978-3-030-56433-9_11 , ISBN 978-3-030-56432-2 , S2CID 234309883 ^ \"OECD Observatory of Public Sector Innovation – Ai Strategies and Public Sector Components\" . 21 November 2019. Archived from the original on 2024-09-25 . Retrieved 2020-05-04 . ^ Berryhill, Jamie; Heang, Kévin Kok; Clogher, Rob; McBride, Keegan (2019). Hello, World: Artificial Intelligence and its Use in the Public Sector (PDF) . Paris: OECD Observatory of Public Sector Innovation. Archived (PDF) from the original on 2019-12-20 . Retrieved 2020-05-05 . ^ Campbell, Thomas A. (2019). Artificial Intelligence: An Overview of State Initiatives (PDF) . Evergreen, CO: FutureGrasp, LLC. Archived from the original (PDF) on March 31, 2020. ^ Bradford, Anu (2023-06-27). \"The Race to Regulate Artificial Intelligence\" . Foreign Affairs . ISSN 0015-7120 . Archived from the original on 2023-08-11 . Retrieved 2023-08-11 . ^ \"Study on human and peoples' rights and artificial intelligence, robotics, and other new and emerging technologies in Africa\" (PDF) . African Commission on Human and Peoples' Rights . 2025-04-08. ^ Odero, Brenda; Nderitu, David; Samuel, Gabrielle (2024). \"The Ubuntu Way: Ensuring Ethical AI Integration in Health Research\" . Wellcome Open Research . 9 : 625. doi : 10.12688/wellcomeopenres.23021.1 . ISSN 2398-502X . PMC 11599802 . PMID 39606617 . ^ Yilma, Kinfe (2025-05-16). \"Ethics of AI in Africa: Interrogating the role of Ubuntu and AI governance initiatives\". Ethics and Information Technology . 27 (2) 24. doi : 10.1007/s10676-025-09834-5 . ISSN 1572-8439 . ^ \"What's in a word: the meaning of Ubuntu\" . The Dandelion Philosophy . Retrieved 2025-09-24 . ^ a b \"Australia needs a national approach to AI strategy\" . Information Age . Retrieved 2023-11-08 . ^ a b \"AI Watch: Global regulatory tracker - Australia\" . whitecase.com . 16 December 2024 . Retrieved May 8, 2025 . ^ \"Câmara aprova marco legal da inteligência artificial no Brasil\" . Revista Globo Rural (in Brazilian Portuguese). 2022-08-24 . Retrieved 2025-06-16 . ^ a b Belli, Luca; Curzi, Yasmin; Gaspar, Walter B. (2023-04-01). \"AI regulation in Brazil: Advancements, flows, and need to learn from the data protection experience\" . Computer Law & Security Review . 48 105767. doi : 10.1016/j.clsr.2022.105767 . ISSN 2212-473X . ^ \"Insufficiency of Ethical Principles for the Regulation of Artificial Intelligence: Antiracism and Antidiscrimination as Vectors for AI Regulation in Brazil\" . Data Privacy Brasil Research . Retrieved 2025-06-16 . ^ \"Brazil: Introduced Bill No. 2338 of 2023 regulating the use of Artificial Intelligence, including algorithm design and technical standards\" . digitalpolicyalert.org . 2023 . Retrieved 16 June 2025 . ^ \"Government of Canada launches second phase of the Pan-Canadian Artificial Intelligence Strategy\" . Innovation, Science and Economic Development Canada . 2022-06-22. Archived from the original on 2023-10-26 . Retrieved 2023-10-24 . ^ \"Bill C-27 summary: Digital Charter Implementation Act, 2022\" . Government of Canada . 2022-08-18. Archived from the original on 2023-12-20 . Retrieved 2023-10-24 . ^ \"Government Bill (House of Commons) C-27 (44–1) – First Reading – Digital Charter Implementation Act, 2022\" . Parliament of Canada . 2022-06-16 . Retrieved 2022-07-12 . ^ \"Intelligence and Data Act\" . Innovation, Science and Economic Development Canada . 2023-09-27 . Retrieved May 4, 2025 . ^ a b \"AI Watch: Global regulatory tracker – Canada\" . Whitecase.com . 2024-12-16 . Retrieved May 8, 2025 . ^ State Council China. \"New Generation of Artificial Intelligence Development Plan\" . www.unodc.org . Archived from the original on June 7, 2023 . Retrieved 2022-07-18 . ^ Department of International Cooperation Ministry of Science and Technology (September 2017). \"Next Generation Artificial Intelligence Development Plan Issued by State Council\" (PDF) . China Science & Technology Newsletter (17): 2– 12. Archived from the original (PDF) on January 21, 2022 – via Ministry of Foreign Affairs of China . ^ Wu, Fei; Lu, Cewu; Zhu, Mingjie; Chen, Hao; Zhu, Jun; Yu, Kai; Li, Lei; Li, Ming; Chen, Qianfeng; Li, Xi; Cao, Xudong (2020). \"Towards a new generation of artificial intelligence in China\" . Nature Machine Intelligence . 2 (6): 312– 316. doi : 10.1038/s42256-020-0183-4 . ISSN 2522-5839 . S2CID 220507829 . Archived from the original on 2022-07-18 . Retrieved 2022-07-18 . ^ \"Ethical Norms for New Generation Artificial Intelligence Released\" . Center for Security and Emerging Technology . Archived from the original on 2023-02-10 . Retrieved 2022-07-18 . ^ \"China just gave the world a blueprint for reigning in generative A.I.\" Fortune . Archived from the original on 2023-07-24 . Retrieved 2023-07-24 . ^ a b c \"Navigating the Complexities of AI Regulation in China\" . Reed Smith . August 2024 . Retrieved 2025-05-08 . ^ Sharma, Animesh Kumar; Sharma, Rahul (2024). \"Comparative Analysis of Data Protection Laws and ai Privacy Risks in brics Nations: A Comprehensive Examination\" . Global Journal of Comparative Law . 13 (1): 56– 85. doi : 10.1163/2211906X-13010003 (inactive 5 July 2025). {{ cite journal }} : CS1 maint: DOI inactive as of July 2025 ( link ) ^ a b Sheehan, Matt (2024-02-27). \"Tracing the Roots of China's AI Regulations\" . Carnegie Endowment for International Peace . Retrieved 2025-05-06 . ^ \"Measures for Labeling of AI-Generated Synthetic Content\" . China Law Translate . Retrieved 12 December 2025 . ^ \"Política nacional de explotación de datos (Big Data) | CONPES 3920\" (PDF) . National Planning Department, Ministry of Information and Communications Technology, and Superintendency of Industry and Commerce (in Spanish). 2018-04-17 . Retrieved 2025-06-16 . ^ a b c \"Colombia adopta de forma temprana recomendaciones de ética en Inteligencia Artificial de la Unesco para la región\" . Ministry of Information and Communications Technology (in Spanish). 2022-03-09 . Retrieved 2025-06-16 . ^ \"Declaración de santiago\" (PDF) . Cumbre Ministerial y de Altas Autoridades de América Latina y el Caribe (in Spanish). October 2023 . Retrieved 2025-06-16 . ^ \"Hoja de Ruta Para el Desarrollo y Aplicación de la Inteligencia Artificial en Colombia\" (PDF) . Ministry of Science, Technology and Innovation (in Spanish). 2024 . Retrieved 2025-06-16 . ^ \"Circular externa No. DE 2024\" (PDF) . Superintendence of Industry and Commerce (in Spanish). 2024-08-21 . Retrieved 2025-06-16 . ^ \"Acuerdo PCSJA24-12243\" (PDF) . Judiciary Council (in Spanish). 2024-12-16 . Retrieved 2025-06-16 . ^ \"Recommendation of the Council on Artificial Intelligence\" . OECD Legal Instruments . Retrieved 2025-06-16 . ^ \"Homepage | Global Digital Compact\" . United Nations . Retrieved 2025-06-16 . ^ \"Seizing the opportunities of safe, secure and trustworthy artificial intelligence systems for sustainable development\" . United Nations General Assembly . 2024-03-11 . Retrieved 2025-06-16 . ^ \"Política nacional de intelligencia artificial | CONPES 4144\" (PDF) . National Planning Department (in Spanish). 2025-02-14 . Retrieved 2025-06-16 . ^ \"Sentencia T-067/25\" . Constitutional Court of Colombia (in Spanish). 2025 . Retrieved 2025-06-16 . ^ \"Council of Europe and Artificial Intelligence\" . Artificial Intelligence . Archived from the original on 2024-01-19 . Retrieved 2021-07-29 . ^ \"The Framework Convention on Artificial Intelligence\" . Council of Europe . Archived from the original on 2024-09-05 . Retrieved 2024-09-05 . ^ \"Council of Europe opens first ever global treaty on AI for signature\" . Council of Europe . 5 September 2024. Archived from the original on 2024-09-17 . Retrieved 2024-09-17 . ^ \"Artificial Intelligence | MPO\" . mpo.gov.cz . Retrieved 2025-06-16 . ^ \"Czechia as a technological leader. Government approved the National Strategy for Artificial Intelligence of the Czech Republic 2030\" . mpo.gov.cz . 2024-07-24 . Retrieved 2025-06-16 . ^ Peukert, Christian; Bechtold, Stefan; Kretschmer, Tobias; Batikas, Michail (2020-09-30). \"Regulatory export and spillovers: How GDPR affects global markets for data\" . CEPR . Archived from the original on 2023-10-26 . Retrieved 2023-10-26 . ^ Coulter, Martin (2023-08-24). \"Big Tech braces for EU Digital Services Act regulations\" . Reuters . Archived from the original on 2023-10-26 . Retrieved 2023-10-26 . ^ \"Europe's new role in digital regulation\" . Le Monde.fr . 2023-08-28. Archived from the original on 2023-10-26 . Retrieved 2023-10-26 . ^ Satariano, Adam (2023-06-14). \"Europeans Take a Major Step Toward Regulating A.I.\" The New York Times . ISSN 0362-4331 . Archived from the original on 2023-10-26 . Retrieved 2023-10-25 . ^ Browne, Ryan (2023-06-14). \"EU lawmakers pass landmark artificial intelligence regulation\" . CNBC . Archived from the original on 2023-10-26 . Retrieved 2023-10-25 . ^ Anonymous (2018-04-25). \"Communication Artificial Intelligence for Europe\" . Shaping Europe's digital future – European Commission . Archived from the original on 2020-05-13 . Retrieved 2020-05-05 . ^ smuhana (2018-06-14). \"High-Level Expert Group on Artificial Intelligence\" . Shaping Europe's digital future – European Commission . Archived from the original on 2019-10-24 . Retrieved 2020-05-05 . ^ a b Andraško, Jozef; Mesarčík, Matúš; Hamuľák, Ondrej (2021-01-02). \"The regulatory intersections between artificial intelligence, data protection and cyber security: challenges and opportunities for the EU legal framework\". AI & Society . 36 (2): 623– 636. doi : 10.1007/s00146-020-01125-5 . ISSN 0951-5666 . S2CID 230109912 . ^ \"Ethics guidelines for trustworthy AI\" . European Commission . 2019. Archived from the original on 2023-03-29 . Retrieved 2022-05-30 . ^ \"Policy and investment recommendations for trustworthy Artificial Intelligence\" . Shaping Europe's digital future – European Commission . 2019-06-26 . Retrieved 2020-05-05 . ^ \"White Paper on Artificial Intelligence – a European approach to excellence and trust\" . European Commission . 19 February 2020. Archived from the original on 2024-01-05 . Retrieved 2021-06-07 . ^ Broadbent, Meredith (17 March 2021). \"What's Ahead for a Cooperative Regulatory Agenda on Artificial Intelligence?\" . www.csis.org . Archived from the original on 7 June 2021 . Retrieved 2021-06-07 . ^ European Commission. (2020). White paper on artificial intelligence: a European approach to excellence and trust . OCLC 1141850140 . ^ Heikkilä, Melissa (2021-04-14). \"POLITICO AI: Decoded: The EU's AI rules — Finland talks to machines — Facebook's fairness project\" (newsletter). POLITICO . Retrieved 2021-05-14. ^ European Commission (2021-04-21). Europe fit for the Digital Age: Commission proposes new rules and actions for excellence and trust in Artificial Intelligence (press release). Archived 2021-05-14 at the Wayback Machine . Retrieved 2021-05-14. ^ Pery, Andrew (2021-10-06). \"Trustworthy Artificial Intelligence and Process Mining: Challenges and Opportunities\" . DeepAI . Archived from the original on 2022-02-18 . Retrieved 2022-02-27 . ^ Browne, Ryan (2023-05-15). \"Europe takes aim at ChatGPT with what might soon be the West's first A.I. law. Here's what it means\" . CNBC . Retrieved 2023-10-25 . ^ Veale, Michael; Borgesius, Frederik Zuiderveen (2021-08-01). \"Demystifying the Draft EU Artificial Intelligence Act — Analysing the good, the bad, and the unclear elements of the proposed approach\" . Computer Law Review International . 22 (4): 97– 112. arXiv : 2107.03721 . doi : 10.9785/cri-2021-220402 . hdl : 2066/245672 . ISSN 2194-4164 . S2CID 235765823 . Archived from the original on 2023-03-26 . Retrieved 2023-01-12 . ^ van Kolfschooten, Hannah (January 2022). \"EU regulation of artificial intelligence: Challenges for patients' rights\" . Common Market Law Review . 59 (1): 81– 112. doi : 10.54648/COLA2022005 . S2CID 248591427 . Archived from the original on 2024-09-25 . Retrieved 2023-12-10 . ^ Coulter, Martin (December 7, 2023). \"What is the EU AI Act and when will regulation come into effect?\" . Reuters . Archived from the original on 2023-12-10 . Retrieved 2024-06-01 . ^ Bertuzzi, Luca (December 7, 2023). \"AI Act: EU policymakers nail down rules on AI models, butt heads on law enforcement\" . euractiv . Archived from the original on January 8, 2024 . Retrieved June 1, 2024 . ^ Browne, Ryan (2024-05-21). \"World's first major law for artificial intelligence gets final EU green light\" . CNBC . Archived from the original on 2024-05-21 . Retrieved 2024-06-01 . ^ \"Artificial Intelligence Act: MEPs adopt landmark law\" . European Parliament . 2024-03-13. Archived from the original on 2024-03-15 . Retrieved 2024-06-01 . ^ \"Experts react: The EU made a deal on AI rules. But can regulators move at the speed of tech?\" . Atlantic Council . 11 December 2023. ^ \"European approach to artificial intelligence | Shaping Europe's digital future\" . digital-strategy.ec.europa.eu . 2024-11-20 . Retrieved 2024-12-09 . ^ Blackman, Reid; Vasiliu-Feltes, Ingrid (2024-02-22). \"The EU's AI Act and How Companies Can Achieve Compliance\" . Harvard Business Review . ISSN 0017-8012 . Retrieved 2025-09-24 . ^ \"Clarifying the costs for the EU's AI Act\" . CEPS . 2021-09-24 . Retrieved 2025-09-24 . ^ \"Understanding the EU AI Act penalties and achieving regulatory compliance\" . 2021.ai . Retrieved 2025-09-24 . ^ Natale, Lara (February 2022). \"EU's digital ambitions beset with strategic dissonance\" . Encompass . Retrieved 25 February 2022 . ^ Bertuzzi, Luca; Killeen, Molly (17 September 2021). \"Digital Brief powered by Google: make it or break it, Chips Act, showing the path\" . Euractiv . Retrieved 25 February 2022 . ^ Propp, Kenneth (7 February 2022). \"France's new mantra: liberty, equality, digital sovereignty\" . Atlantic Council . Archived from the original on 25 February 2022 . Retrieved 25 February 2022 . ^ \"Artificial intelligence: EU must pick up the pace\" . European Court of Auditors . 29 May 2024. Archived from the original on 25 September 2024 . Retrieved 29 May 2024 . ^ \"Long awaited EU AI Act becomes law after publication in the EU's Official Journal | White & Case LLP\" . www.whitecase.com . 2024-07-16 . Retrieved 2025-08-03 . ^ \"National implementation of EU Artificial Intelligence Regulation\" . Ministry of Economic Affairs and Employment of Finland . Retrieved 2025-06-16 . ^ Klimaschutz, BMWK-Bundesministerium für Wirtschaft und. \" \"KI – Made in Germany\" etablieren\" . www.bmwk.de (in German). Archived from the original on 12 June 2023 . Retrieved 12 June 2023 . ^ \"DIN, DKE und BMWi veröffentlichen Normungsroadmap für Künstliche Intelligenz\" . all-electronics (in German) . Retrieved 12 June 2023 . ^ a b Runze, Gerhard; Haimerl, Martin; Hauer, Marc; Holoyad, Taras; Obert, Otto; Pöhls, Henrich; Tagiew, Rustam; Ziehn, Jens (2023). \"Ein Werkzeug für eine gemeinsame KI-Terminologie – Das AI-Glossary als Weg aus Babylon\" . Java Spektrum (in German) (3): 42– 46. Archived from the original on 2024-04-27 . Retrieved 2023-06-12 . ^ \"Normungsroadmap Künstliche Intelligenz\" . www.dke.de (in German) . Retrieved 12 June 2023 . ^ Cahane, Amir (November 13, 2022). \"Israeli AI regulation and policy white paper: a first glance\" . RAILS Blog . ^ Cahane, Amir; Sierra, Michael (2025-12-10). \"Nascent regulatory sandbox frameworks for AI in Israel\" . Cambridge Forum on AI: Law and Governance . 1 : e40. doi : 10.1017/cfl.2025.10032 . ISSN 3033-3733 . ^ Ministry of Innovation, Science and Technology and the Ministry of Justice (December 12, 2023). \"Israel's Policy on Artificial Intelligence Regulation and Ethics\" . ^ \"Artificial Intelligence Regulation and Ethics Policy\" . gov.il . December 17, 2023 . Retrieved 2025-05-07 . ^ Wroble, Sharon (2024-05-03). \"Israel Signs Global Treaty to Address Risks of Artificial Intelligence\" . Times of Israel . Retrieved 2025-05-08 . ^ Marzio Bartoloni (11 October 2023). \"Cures and artificial intelligence: privacy and the risk of the algorithm that discriminates\" . ^ a b \"AI Watch: Global regulatory tracker – Italy\" . whitecase.com . 2024-12-16 . Retrieved 2025-05-09 . ^ Olivi; Bocchi; Cirotti (2024-05-07). \"The road to the AI Act: The Italian approach – Part 3: The Italian national competent AI Authority\" . Dentons . Retrieved 2025-05-09 . ^ \"Morocco Proposes Legislation for National AI Agency\" . The Moroccan Times . 2024-04-24. Archived from the original on 2024-04-25 . Retrieved 2024-04-25 . ^ a b c Buza, Maria; Taha, Sherif (2025-04-09). \"DPA Digital Digest: Morocco [2025 Edition]\" . Digital Policy Alert . Retrieved May 8, 2025 . ^ Rebecca (2023-07-13). \"Why is regulating AI such a challenge?\" . Prime Minister's Chief Science Advisor . Archived from the original on 2024-09-25 . Retrieved 2024-08-20 . ^ \"Reimagining Regulation for the Age of AI: New Zealand Pilot Project\" . World Economic Forum . 2020-06-29. ^ Cann, Geraden (2023-05-25). \"Privacy Commission issues warning to companies and organisations using AI\" . Stuff . Archived from the original on 2024-09-25 . Retrieved 2024-08-20 . ^ \"Artificial Intelligence and the IPPs\" . www.privacy.org.nz . 2023-09-21. Archived from the original on 2024-08-20 . Retrieved 2024-08-20 . ^ \"Survey finds most Kiwis spooked about malicious AI - minister responds\" . The New Zealand Herald . 2024-02-21. Archived from the original on 2024-08-20 . Retrieved 2024-08-20 . ^ Arasa, Dale (13 March 2023). \"Philippine AI Bill Proposes Agency for Artificial Intelligence\" . Philippine Daily Inquirer . Archived from the original on 25 September 2024 . Retrieved 29 May 2024 . ^ Abarca, Charie (29 May 2024). \"Comelec wants AI ban on campaign materials ahead of 2025 polls\" . Philippine Daily Inquirer . Archived from the original on 29 May 2024 . Retrieved 29 May 2024 . ^ Ministry of Science of Spain (2018). \"Spanish RDI Strategy in Artificial Intelligence\" (PDF) . www.knowledge4policy.ec.europa.eu . Archived (PDF) from the original on 18 July 2023 . Retrieved 9 December 2023 . ^ a b \"Chaining the chatbots: Spain closes in on AI Act\" . POLITICO . 2023-06-22 . Retrieved 2023-09-03 . ^ Ministry of Science of Spain (2018). \"Spanish RDI Strategy in Artificial Intelligence\" (PDF) . www.knowledge4policy.ec.europa.eu . Retrieved 9 December 2023 . ^ Castillo, Carlos del (2021-12-28). \"España vigilará la Inteligencia Artificial como a los fármacos o los alimentos\" . elDiario.es (in Spanish) . Retrieved 2023-09-03 . ^ \"España comienza el proceso para elegir la sede de la futura Agencia Española de Supervisión de la IA\" . El Español (in Spanish). 2022-09-13 . Retrieved 2023-09-03 . ^ Marcos, José (2022-09-12). \"El Gobierno inicia con la Agencia de Inteligencia Artificial el traslado de sedes fuera de Madrid\" . El País (in Spanish) . Retrieved 2023-09-03 . ^ \"A Coruña acogerá la Agencia Española de Inteligencia Artificial\" . Europa Press. 2022-12-05 . Retrieved 2023-09-03 . ^ \"El Gobierno aprueba el estatuto de la Agencia Española de Supervisión de la Inteligencia Artificial\" . Europa Press. 2023-08-22 . Retrieved 2023-09-03 . ^ Guerrini, Federico. \"European Countries Race To Set The AI Regulatory Pace\" . Forbes . Retrieved 2023-09-04 . ^ \"Comienza la actividad de la Agencia Española de Supervisión de la Inteligencia Artificial\" . Computerworld.es (in Spanish) . Retrieved 2026-01-03 . ^ \"Spain's AI Detection Requirement: $38 Million Fine for Unlabeled AI\" . www.aiornot.com . Retrieved 2026-01-03 . ^ \"Artificial Intelligence: Overview and Switzerland's regulatory approach\" . Swiss Federal Office of Communications (OFCOM) . 12 February 2025 . Retrieved 31 March 2025 . ^ a b \"Digital economy strategy 2015 to 2018\" . www.ukri.org . 16 February 2015. Archived from the original on 2022-09-01 . Retrieved 2022-07-18 . ^ \"Data ethics and AI guidance landscape\" . GOV.UK . Archived from the original on 2023-10-26 . Retrieved 2023-10-26 . ^ Leslie, David (2019-06-11). \"Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector\" . Zenodo . arXiv : 1906.05684 . doi : 10.5281/zenodo.3240529 . S2CID 189762499 . Archived from the original on 2020-04-16 . Retrieved 2020-04-28 . ^ \"Intelligent security tools\" . www.ncsc.gov.uk . Archived from the original on 2020-04-06 . Retrieved 2020-04-28 . ^ Richardson, Tim. \"UK publishes National Artificial Intelligence Strategy\" . www.theregister.com . Archived from the original on 2023-02-10 . Retrieved 2022-01-01 . ^ The National AI Strategy of the UK Archived 2023-02-10 at the Wayback Machine , 2021 (actions 9 and 10 of the section \"Pillar 3 – Governing AI Effectively\") ^ \"A pro-innovation approach to AI regulation\" . GOV.UK . Archived from the original on 2023-10-27 . Retrieved 2023-10-27 . ^ Gikay, Asress Adimi (2023-06-08). \"How the UK is getting AI regulation right\" . The Conversation . Archived from the original on 2023-10-27 . Retrieved 2023-10-27 . ^ Browne, Ryan (2023-06-12). \"British Prime Minister Rishi Sunak pitches UK as home of A.I. safety regulation as London bids to be next Silicon Valley\" . CNBC . Archived from the original on 2023-07-27 . Retrieved 2023-10-27 . ^ \"AI Safety Summit: introduction (HTML)\" . GOV.UK . Archived from the original on 2023-10-26 . Retrieved 2023-10-27 . ^ \"Introducing the AI Safety Institute\" . GOV.UK . Archived from the original on 2024-07-07 . Retrieved 2024-07-08 . ^ Henshall, Will (2024-04-01). \"U.S., U.K. Will Partner to Safety Test AI\" . TIME . Archived from the original on 2024-07-07 . Retrieved 2024-07-08 . ^ Weaver, John Frank (2018-12-28). \"Regulation of artificial intelligence in the United States\" . Research Handbook on the Law of Artificial Intelligence : 155– 212. doi : 10.4337/9781786439055.00018 . ISBN 978-1-78643-905-5 . Archived from the original on 2020-06-30 . Retrieved 2020-06-29 . ^ Waldenberg, Samantha; Gold, Hadas; Duffy, Clare (2025-12-12). \"Trump signs executive order blocking states from enforcing their own regulations around AI\" . CNN . Retrieved 2025-12-13 . ^ Donway, Walter (2025-12-22). \"The Nationalization of AI Threatens Innovation and the American Mind\" . The Daily Economy . Retrieved 2025-12-24 . ^ \"Background on Lethal Autonomous Weapons Systems in the CCW\" . United Nations Geneva. Archived from the original on 2020-04-27 . Retrieved 2020-05-05 . ^ \"Guiding Principles affirmed by the Group of Governmental Experts on Emerging Technologies in the Area of Lethal Autonomous Weapons System\" (PDF) . United Nations Geneva. Archived from the original (PDF) on 2020-12-01 . Retrieved 2020-05-05 . ^ Baum, Seth (2018-09-30). \"Countering Superintelligence Misinformation\" . Information . 9 (10): 244. doi : 10.3390/info9100244 . ISSN 2078-2489 . ^ \"Country Views on Killer Robots\" (PDF) . The Campaign to Stop Killer Robots. Archived (PDF) from the original on 2019-12-22 . Retrieved 2020-05-05 . ^ Sayler, Kelley (2020). Artificial Intelligence and National Security: Updated November 10, 2020 (PDF) . Washington, DC: Congressional Research Service. Archived (PDF) from the original on May 8, 2020 . Retrieved May 27, 2021 . ^ \"Defense Primer: U.S. Policy on Lethal Autonomous Weapon Systems\" . Congressional Research Service . May 15, 2023. Archived from the original on November 1, 2023 . Retrieved October 18, 2023 .",
      "word_count": 15093,
      "extraction_method": "readability",
      "metadata": {
        "search_position": 1,
        "search_query": "AI regulation",
        "original_title": "AI regulation",
        "snippet": "Regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI). The regulatory and policy landscape for AI is an emerging issue in jurisdictions worldwide, including for international organizations without direct enforcement power like the IEEE or the OECD.Since 2016, numerous AI ethics guidelines have been published in order to maintain social control over the technology. Furthermore, organizations deploying AI have a central role to play in creating and implementing trustworthy AI, adhering to established principles, and taking accountability for mitigating risks. The European Union adopted in 2024 a common legal framework for AI with the AI Act."
      },
      "timestamp": "2026-02-17T01:51:17.041008",
      "error": null
    },
    {
      "url": "https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence",
      "title": "Regulation of artificial intelligence - Wikipedia",
      "content": "Guidelines and laws to regulate AI Regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI). The regulatory and policy landscape for AI is an emerging issue in jurisdictions worldwide, including for international organizations without direct enforcement power like the IEEE or the OECD . [ 1 ] Since 2016, numerous AI ethics guidelines have been published in order to maintain social control over the technology. [ 2 ] Furthermore, organizations deploying AI have a central role to play in creating and implementing trustworthy AI , adhering to established principles, and taking accountability for mitigating risks. [ 3 ] The European Union adopted in 2024 a common legal framework for AI with the AI Act . [ 4 ] According to Stanford University 's 2025 AI Index, legislative mentions of AI rose 21.3% across 75 countries since 2023, marking a ninefold increase since 2016. The U.S. federal agencies introduced 59 AI-related regulations in 2024—more than double the number in 2023. [ 5 ] [ 6 ] In 2024, nearly 700 AI-related bills were introduced across 45 states, up from 191 in 2023. [ 7 ] There is currently no broad consensus on the degree or mechanics of AI regulation. Several prominent figures in the field, including Elon Musk , Sam Altman , Dario Amodei , and Demis Hassabis have publicly called for immediate regulation of AI. [ 8 ] [ 9 ] [ 10 ] [ 11 ] In 2023, following ChatGPT-4 's creation, Elon Musk and others signed an open letter urging a moratorium on the training of more powerful AI systems. [ 12 ] Others, such as Mark Zuckerberg and Marc Andreessen , have warned about the risk of preemptive regulation stifling innovation. [ 13 ] [ 14 ] In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". [ 5 ] Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity. [ 15 ] In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\". [ 16 ] [ 17 ] In 2023 the United Kingdom started a series of international summits on AI with the AI Safety Summit . It was followed by the AI Seoul Summit in 2024, and the AI Action Summit in Paris in 2025. [ 18 ] The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI. [ 19 ] Public administration and policy considerations generally focus on the technical and economic implications and on trustworthy and human-centered AI systems, [ 20 ] regulation of artificial superintelligence , [ 21 ] the risks and biases of machine-learning algorithms, the explainability of model outputs, [ 22 ] and the tension between open source AI and unchecked AI use. [ 23 ] [ 24 ] [ 25 ] There have been both hard law and soft law proposals to regulate AI. [ 26 ] Some legal scholars have noted that hard law approaches to AI regulation have substantial challenges. [ 27 ] [ 28 ] Among the challenges, AI technology is rapidly evolving leading to a \"pacing problem\" where traditional laws and regulations often cannot keep up with emerging applications and their associated risks and benefits. [ 27 ] [ 28 ] Similarly, the diversity of AI applications challenges existing regulatory agencies, which often have limited jurisdictional scope. [ 27 ] As an alternative, some legal scholars argue that soft law approaches to AI regulation are promising, as they offer greater flexibility to adapt to emerging technologies and the evolving nature of AI applications. [ 27 ] [ 28 ] However, soft law approaches often lack substantial enforcement potential. [ 27 ] [ 29 ] Cason Schmit, Megan Doerr, and Jennifer Wagner proposed the creation of a quasi-governmental regulator by leveraging intellectual property rights (i.e., copyleft licensing) in certain AI objects (i.e., AI models and training datasets) and delegating enforcement rights to a designated enforcement entity. [ 30 ] They argue that AI can be licensed under terms that require adherence to specified ethical practices and codes of conduct. (e.g., soft law principles). [ 30 ] Some policy proposals seek to regulate advanced “frontier” AI systems by restricting or licensing the publication of models, while other approaches emphasize regulating how AI is deployed in specific settings. In an article for IEEE Spectrum , technologist John deVadoss argued that model-centric measures—such as licensing training runs or restricting the release of model weights—are difficult to enforce once software artifacts are copied and redistributed, and that restrictions on publishing model code or weights could face constitutional challenges in the United States. He instead advocated a risk-tiered, “use-based” regime in which obligations scale with deployment context (for example, disclosure and acceptable-use policies for general consumer interaction; risk assessment and human oversight for decision support; and rigorous testing, monitoring, and incident reporting for safety-critical uses), with enforcement focused on practical “chokepoints” such as app stores, cloud platforms, and payment systems. [ 31 ] The European Union’s Artificial Intelligence Act similarly follows a risk-based framework that assigns different obligations to providers and users according to an AI system’s risk level, and it includes transparency requirements for generative AI alongside additional oversight for high-impact general-purpose models. [ 32 ] Prominent youth organizations focused on AI, namely Encode AI, have also issued comprehensive agendas calling for more stringent AI regulations and public-private partnerships . [ 33 ] [ 34 ] AI regulation could derive from basic principles. A 2020 Berkman Klein Center for Internet & Society meta-review of existing sets of principles, such as the Asilomar Principles and the Beijing Principles, identified eight such basic principles: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and respect for human values. [ 35 ] AI law and regulations have been divided into three main topics, namely governance of autonomous intelligence systems, responsibility and accountability for the systems, and privacy and safety issues. [ 36 ] A public administration approach sees a relationship between AI law and regulation, the ethics of AI , and 'AI society', defined as workforce substitution and transformation, social acceptance and trust in AI, and the transformation of human to machine interaction. [ 37 ] The development of public sector strategies for management and regulation of AI is deemed necessary at the local, national, [ 38 ] and international levels [ 39 ] and in a variety of fields, from public service management [ 40 ] and accountability [ 41 ] to law enforcement, [ 39 ] [ 42 ] healthcare (especially the concept of a Human Guarantee), [ 43 ] [ 44 ] [ 45 ] [ 46 ] [ 47 ] the financial sector, [ 38 ] [ 48 ] robotics, [ 49 ] [ 50 ] autonomous vehicles, [ 49 ] the military [ 51 ] and national security, [ 52 ] and international law. [ 53 ] [ 54 ] Henry Kissinger , Eric Schmidt , and Daniel Huttenlocher published a joint statement in November 2021 entitled \"Being Human in an Age of AI\", calling for a government commission to regulate AI. [ 55 ] In 2025, the UK and US governments declined to sign an international agreement on AI at the AI Action Summit in Paris. The agreement was described as proposing an open, inclusive and ethical approach to AI development, including environmental protection measures. US Vice President JD Vance argued that the agreement would be detrimental to the growth of the AI industry. The UK government added that the agreement \"didn't provide enough practical clarity on global governance, nor sufficiently address harder questions around national security\". [ 56 ] As a response to the AI control problem [ edit ] Regulation of AI can be seen as positive social means to manage the AI control problem (the need to ensure long-term beneficial AI), with other social responses such as doing nothing or banning being seen as impractical, and approaches such as enhancing human capabilities through transhumanism techniques like brain-computer interfaces being seen as potentially complementary. [ 57 ] [ 58 ] Regulation of research into artificial general intelligence (AGI) focuses on the role of review boards, from university or corporation to international levels, and on encouraging research into AI safety , [ 58 ] together with the possibility of differential intellectual progress (prioritizing protective strategies over risky strategies in AI development) or conducting international mass surveillance to perform AGI arms control. [ 57 ] For instance, the 'AGI Nanny' is a proposed strategy, potentially under the control of humanity, for preventing the creation of a dangerous superintelligence as well as for addressing other major threats to human well-being, such as subversion of the global financial system , until a true superintelligence can be safely created. It entails the creation of a smarter-than-human, but not superintelligent, AGI system connected to a large surveillance network, with the goal of monitoring humanity and protecting it from danger. [ 57 ] Regulation of conscious, ethically aware AGIs focuses on how to integrate them with existing human society and can be divided into considerations of their legal standing and of their moral rights. [ 57 ] Regulation of AI has been seen as restrictive, with a risk of preventing the development of AGI. [ 49 ] Organizations polled largely agree that companies developing foundation models will be responsible for associated risks (rather than those using it), and that global governance is required to address risks from generative AI . [ 59 ] The development of a global governance board to regulate AI development was suggested at least as early as 2017. [ 60 ] In December 2018, Canada and France announced plans for a G7-backed International Panel on Artificial Intelligence, modeled on the International Panel on Climate Change , to study the global effects of AI on people and economies and to steer AI development. [ 61 ] In 2019, the Panel was renamed the Global Partnership on AI. [ 62 ] [ 63 ] The Global Partnership on Artificial Intelligence (GPAI) was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology, as outlined in the OECD Principles on Artificial Intelligence (2019). [ 64 ] The 15 founding members of the Global Partnership on Artificial Intelligence are Australia, Canada, the European Union, France, Germany, India, Italy, Japan, the Republic of Korea, Mexico, New Zealand, Singapore, Slovenia, the United States and the UK. In 2023, the GPAI has 29 members. [ 65 ] The GPAI Secretariat is hosted by the OECD in Paris, France. GPAI's mandate covers four themes, two of which are supported by the International Centre of Expertise in Montréal for the Advancement of Artificial Intelligence, namely, responsible AI and data governance. A corresponding centre of excellence in Paris will support the other two themes on the future of work, and on innovation and commercialization. GPAI also investigated how AI can be leveraged to respond to the COVID-19 pandemic. [ 64 ] The OECD AI Principles [ 66 ] were adopted in May 2019, and the G20 AI Principles in June 2019. [ 63 ] [ 67 ] [ 68 ] In September 2019 the World Economic Forum issued ten 'AI Government Procurement Guidelines'. [ 69 ] In February 2020, the European Union published its draft strategy paper for promoting and regulating AI. [ 39 ] At the United Nations (UN), several entities have begun to promote and discuss aspects of AI regulation and policy, including the UNICRI Centre for AI and Robotics . [ 52 ] In partnership with INTERPOL, UNICRI's Centre issued the report AI and Robotics for Law Enforcement in April 2019 [ 70 ] and the follow-up report Towards Responsible AI Innovation in May 2020. [ 42 ] At UNESCO 's Scientific 40th session in November 2019, the organization commenced a two-year process to achieve a \"global standard-setting instrument on ethics of artificial intelligence\". In pursuit of this goal, UNESCO forums and conferences on AI were held to gather stakeholder views. A draft text of a Recommendation on the Ethics of AI of the UNESCO Ad Hoc Expert Group was issued in September 2020 and included a call for legislative gaps to be filled. [ 71 ] UNESCO tabled the international instrument on the ethics of AI for adoption at its General Conference in November 2021; [ 64 ] this was subsequently adopted. [ 72 ] While the UN is making progress with the global management of AI, its institutional and legal capability to manage the AGI existential risk is more limited. [ 73 ] Recent research has indicated that countries will also begin to use artificial intelligence as a tool for national cyberdefense. AI is a new factor in the cyber arms industry, as it can be used for defense purposes. Therefore, academics urge that nations should establish regulations for the use of AI, similar to how there are regulations for other military industries. [ 74 ] In recent years, academic researchers have made more efforts to promote multilateral dialogue and policy development, advocating for the adoption of international frameworks that govern the deployment of AI in military and cybersecurity contexts, with a strong emphasis on human rights and international humanitarian law. [ 75 ] Initiatives such as the Munich Convention on AI, Data and Human Rights, which brought together scholars from various academic institutions, have called for a binding international agreement to protect human rights in the age of AI. [ 76 ] A key element of such initiatives is identifying common ground between different regional approaches, such as those of the African Union and the Council of Europe. [ 77 ] On 30 October 2023, the Group of Seven ( G7 ) nations adopted a set of eleven guiding principles relating to the design, development and deployment of advanced artificial intelligence systems. These principles form part of the Hiroshima Process, a framework aimed at ensuring that AI technologies are implemented responsibly across global markets. Alongside these principles, a voluntary Code of Conduct for AI developers was introduced to encourage transparency, accountability, and risk-mitigation in emerging AI models and platforms. [ 78 ] The announcement was welcomed internationally, notably by Ursula von der Leyen , who stated that the initiative reflects the direction of the AI Directive, which was in its final stage of negotiation at the time. New guidelines also aim to establish a coordinated global effort towards the responsible development and use of advanced AI systems. While non-binding, the G7 governments encourage organizations to voluntarily adopt the guidelines, which emphasize a risk-based approach across the AI lifecycle—from pre-deployment risk assessment to post-deployment incident reporting and mitigation. [ 79 ] The AIP&CoC also highlight the importance of AI system security, internal adversarial testing ('red teaming'), public transparency about capabilities and limitations, and governance procedures that include privacy safeguards and content authentication tools. The guidelines additionally promote AI innovation directed at solving global challenges such as climate change and public health, and call for advancing international technical standards. [ 79 ] Looking ahead, the G7 intends to further refine their principles and Code of Conduct in collaboration with other organizations like the OECD , GPAI , and broader stakeholders. Areas of broader development include clearer AI terminology (e.g., \"advanced AI systems\"), the setting of risk benchmarks, and mechanisms for cross-border information sharing on potential AI risks. Despite general alignment on AI safety, analysts have noted that differing regulatory philosophies—such as the EU's prescriptive AI Act versus the U.S.'s sector-specific approach—may challenge global regulatory harmonization. [ 80 ] Regional and national regulation [ edit ] Timeline of strategies, action plans and policy papers setting defining national, regional and international approaches to AI [ 81 ] The regulatory and policy landscape for AI is an emerging issue in regional and national jurisdictions globally, for example in the European Union [ 82 ] and Russia. [ 83 ] Since early 2016, many national, regional and international authorities have begun adopting strategies, actions plans and policy papers on AI. [ 84 ] [ 85 ] These documents cover a wide range of topics such as regulation and governance, as well as industrial strategy, research, talent and infrastructure. [ 20 ] [ 86 ] Different countries have approached the problem in different ways. Regarding the three largest economies, it has been said that \"the United States is following a market-driven approach, China is advancing a state-driven approach, and the EU is pursuing a rights-driven approach.\" [ 87 ] The African Union has increasingly been active in the field. Most importantly, the African Commission on Human and Peoples' Rights published a study on AI and human rights and advocated for an African Framework Convention on AI and Human Rights. [ 88 ] This initiative builds on earlier debates within the AU, particularly discussions on autonomous lethal weapons, which African representatives had previously raised in international forums. [ 75 ] A distinctive feature of the proposed African Framework is its strong emphasis on collective rights, as enshrined in the African Charter on Human and Peoples' Rights . This approach is situated within the broader debate on aligning AI governance with African values, including ethical traditions such as Ubuntu (\"humanity to others\"). [ 89 ] [ 90 ] [ 91 ] In October 2023, the Australian Computer Society , Business Council of Australia , Australian Chamber of Commerce and Industry , Ai Group (aka Australian Industry Group) , Council of Small Business Organisations Australia, and Tech Council of Australia jointly published an open letter calling for a national approach to AI strategy. [ 92 ] The letter backs the federal government establishing a whole-of-government AI taskforce. [ 92 ] Additionally, in August 2024, the Australian government set a Voluntary AI Safety Standard, which was followed by a Proposals Paper later in September of that year, outlining potential guardrails for high-risk AI that could become mandatory. These guardrails include areas such as model testing, transparency, human oversight, and record-keeping, all of which may be enforced through new legislation. As noted, however, Australia has not yet passed AI-specific laws, but existing statutes such as the Privacy Act 1988 , Corporations Act 2001 , and Online Safety Act 2021 all have applications which apply to AI use. [ 93 ] In September 2024, a bill also was introduced which granted the Australian Communications and Media Authority powers to regulate AI-generated misinformation. Several agencies, including the ACMA , ACCC , and Office of the Australian Information Commissioner , are all expected to play roles in future AI regulation. [ 93 ] On September 30, 2021, the Brazilian Chamber of Deputies (Câmara dos Deputados) approved the Brazilian Legal Framework for Artificial Intelligence (Marco Legal da Inteligência Artificial). This legislation aimed to regulate AI development and usage while promoting research and innovation in ethical AI solutions that prioritize culture, justice, fairness, and accountability. [ 94 ] The 10-article bill established several key objectives: developing ethical principles for AI, promoting sustained research investment, and removing barriers to innovation. Article 4 specifically emphasized preventing discriminatory AI solutions, ensuring plurality, and protecting human rights. When the bill was first released to the public, it faced substantial criticism, alarming the government for critical provisions. The underlying issue is that this bill failed to thoroughly and carefully address accountability, transparency, and inclusivity principles. Article VI establishes subjective liability, meaning any individual that is damaged by an AI system and is wishing to receive compensation must specify the stakeholder and prove that there was a mistake in the machine's life cycle. Scholars emphasize that it is out of legal order to assign an individual responsible for proving algorithmic errors given the high degree of autonomy, unpredictability, and complexity of AI systems. [ 95 ] This also drew attention to the currently occurring issues with face recognition systems in Brazil leading to unjust arrests by the police, which would then imply that when this bill is adopted, individuals would have to prove and justify these machine errors. The main controversy of this draft bill was directed to three proposed principles. First, the non-discrimination principle, [ 96 ] suggests that AI must be developed and used in a way that merely mitigates the possibility of abusive and discriminatory practices. Secondly, the pursuit of neutrality principle lists recommendations for stakeholders to mitigate biases; however, with no obligation to achieve this goal. Lastly, the transparency principle states that a system's transparency is only necessary when there is a high risk of violating fundamental rights. As easily observed, the Brazilian Legal Framework for Artificial Intelligence lacks binding and obligatory clauses and is rather filled with relaxed guidelines. In fact, experts emphasize that this bill may even make accountability for AI discriminatory biases even harder to achieve. Compared to the EU's proposal of extensive risk-based regulations, the Brazilian Bill has 10 articles proposing vague and generic recommendations. The Brazilian AI Bill lacks the diverse perspectives that characterized earlier Brazilian internet legislation. When Brazil drafted the Marco Civil da Internet (Brazilian Internet Bill of Rights) in the 2000s, it used a multistakeholder approach that brought together various groups—including government, civil society, academia, and industry—to participate in dialogue, decision-making, and implementation. This collaborative process helps capture different viewpoints and trade-offs among stakeholders with varying interests, ultimately improving transparency and effectiveness in AI regulation. [ 95 ] In May 2023, a new bill was passed, superseding the 2021 bill. It calls for risk assessments of AI systems before deployment and distinguishes \"high risk\" and \"excessive risk\" systems. The latter are characterized by their potential to expose or exploit vulnerabilities and will be subject to regulation by the Executive Branch. [ 97 ] The Pan-Canadian Artificial Intelligence Strategy (2017) is supported by federal funding of Can $125 million with the objectives of increasing the number of outstanding AI researchers and skilled graduates in Canada, establishing nodes of scientific excellence at the three major AI centres, developing 'global thought leadership' on the economic, ethical, policy and legal implications of AI advances and supporting a national research community working on AI. [ 64 ] The Canada CIFAR AI Chairs Program is the cornerstone of the strategy. It benefits from funding of Can$86.5 million over five years to attract and retain world-renowned AI researchers. [ 64 ] The federal government appointed an Advisory Council on AI in May 2019 with a focus on examining how to build on Canada's strengths to ensure that AI advancements reflect Canadian values, such as human rights, transparency and openness. The Advisory Council on AI has established a working group on extracting commercial value from Canadian-owned AI and data analytics. [ 64 ] In 2020, the federal government and Government of Quebec announced the opening of the International Centre of Expertise in Montréal for the Advancement of Artificial Intelligence, which will advance the cause of responsible development of AI. [ 64 ] In June 2022, the government of Canada started a second phase of the Pan-Canadian Artificial Intelligence Strategy. [ 98 ] In November 2022, Canada has introduced the Digital Charter Implementation Act (Bill C-27), which proposes three acts that have been described as a holistic package of legislation for trust and privacy: the Consumer Privacy Protection Act, the Personal Information and Data Protection Tribunal Act, and the Artificial Intelligence & Data Act (AIDA). [ 99 ] [ 100 ] In September 2023, the Canadian Government introduced a Voluntary Code of Conduct for the Responsible Development and Management of Advanced Generative AI Systems. The code, based initially on public consultations, seeks to provide interim guidance to Canadian companies on responsible AI practices. Ultimately, its intended to serve as a stopgap until formal legislation, such as the Artificial Intelligence and Data Act (AIDA), is enacted. [ 101 ] [ 102 ] Moreover, in November 2024, the Canadian government additionally announced the creation of the Canadian Artificial Intelligence Safety Institute (CAISI) as part of a 2.4 billion CAD federal AI investment package. This includes 2 billion CAD to support a new AI Sovereign Computing Strategy and the AI Computing Access Fund, which aims to bolster Canada's advanced computing infrastructure. Further funding includes 700 million CAD for domestic AI development, 1 billion CAD for public supercomputing infrastructure, and 300 million CAD to assist companies in accessing new AI resources. [ 102 ] The regulation of AI in China is mainly governed by the State Council of the People's Republic of China 's July 8, 2017 \"A Next Generation Artificial Intelligence Development Plan\" (State Council Document No. 35), in which the Central Committee of the Chinese Communist Party and the State Council of the PRC urged the governing bodies of China to promote the development of AI up to 2030. Regulation of the issues of ethical and legal support for the development of AI is accelerating, and policy ensures state control of Chinese companies and over valuable data, including storage of data on Chinese users within the country and the mandatory use of People's Republic of China's national standards for AI, including over big data, cloud computing, and industrial software. [ 103 ] [ 104 ] [ 105 ] In 2021, China published ethical guidelines for the use of AI in China which state that researchers must ensure that AI abides by shared human values, is always under human control, and is not endangering public safety. [ 106 ] In 2023, China introduced Interim Measures for the Management of Generative AI Services . [ 107 ] On August 15, 2023, China's first generative AI measures officially came into force, becoming one of the first comprehensive national regulatory frameworks for generative AI. The measures apply to all providers offering generative AI services to the Chinese public, including foreign entities, ultimately setting the rules related to data protection, transparency, and algorithmic accountability. [ 108 ] [ 109 ] In parallel, earlier regulations such as the Chinese government's Deep Synthesis Provisions (effective January 2023) and the Algorithm Recommendation Provisions (effective March 2022) continue to shape China's governance of AI-driven systems, including requirements for watermarking and algorithm filing with the Cyberspace Administration of China (CAC). [ 110 ] Additionally, In October 2023, China also implemented a set of Ethics Review Measures for science and technology, mandating certain ethical assessments of AI projects which were deemed socially sensitive or capable of negatively influencing public opinion. [ 108 ] As of mid-2024, over 1,400 AI algorithms had been already registered under the CAC 's algorithm filing regime, which includes disclosure requirements and penalties for noncompliance. [ 108 ] This layered approach reflects a broader policy process shaped by not only central directives but also academic input, civil society concerns, and public discourse. [ 110 ] Later procedures set out detailed mandatory AI content labeling rules. In 2025, Chinese regulators issued the Measures for Labeling of AI-Generated Synthetic Content. These procedures standardize the use of on-screen disclosure labels and embedded provenance metadata for AI-generated text, images, audio, video, and virtual scenes. Additionally, they introduce a mandatory requirement for online service providers to disclose their name or code and content reference number in the embedded metadata, encourage the use of digital watermarking , require online content platforms to detect or infer AI-generated material and add conspicuous consumer disclosures, and mandate that providers describe their labeling methods in online terms of service. [ 111 ] Although Colombia has not issued specific AI laws, this does not mean there is a lack of frameworks or initiatives to govern it. In fact, there are numerous instruments issued for that purpose, including national policies, ethical frameworks, roadmaps, rulings, and guidelines. In addition, there are other existing regulations applicable to AI systems, such as data protection, intellectual property, consumer laws, and civil liability rules. One of the first specific instruments issued was the CONPES 3920 of 2019, the National Policy on Exploitation of Data (Big Data). The main purpose of this policy was to leverage data in Colombia by creating the conditions to handle it as an asset to generate social and economic value. [ 112 ] Another milestone occurred in 2021, when the National Government published the Ethical Framework for AI in Colombia. It was a soft law guide for public entities, offering recommendations to consider in the management of AI-related projects. [ 113 ] An additional framework for AI was adopted by Colombia in 2022: the Recommendation on the Ethics of Artificial Intelligence by UNESCO. [ 113 ] It includes values and principles applicable in the public and private sectors in all stages of the AI system life cycle. [ 113 ] A regional political commitment on AI was made in 2023, involving Latin American and Caribbean countries. It was called the Declaration of Santiago, whose main purpose is to promote ethical AI in the region. [ 114 ] 2024 was a prolific year in governing AI in Colombia. A roadmap for an ethical and sustainable AI adoption was launched by the National Government. [ 115 ] The Superintendence of Industry and Commerce issued a guide on the processing of personal data in AI systems. [ 116 ] The Judiciary Council published a guideline for the use of AI in the judicial sector. [ 117 ] In the global context, the OECD principles were updated, [ 118 ] the Global Digital Compact by the United Nations was published, [ 119 ] and the UN adopted Resolution A/78/L.49 on safe, trustworthy, and reliable AI systems for sustainable development. [ 120 ] In 2025, a new national policy on AI was issued by the National Government, contained in CONPES 4144. [ 121 ] The ruling T-067/25 by the Constitutional Court provided some rules for access to public information and transparency of algorithms. [ 122 ] Until Congress issues AI regulations, these soft-law documents can guide the design, development, and use of AI systems in Colombia. The Council of Europe (CoE) is an international organization that promotes human rights, democracy and the rule of law. It comprises 46 member states, including all 29 Signatories of the European Union's 2018 Declaration of Cooperation on Artificial Intelligence. The CoE has created a common legal space in which the members have a legal obligation to guarantee rights as set out in the European Convention on Human Rights . Specifically in relation to AI, \"The Council of Europe's aim is to identify intersecting areas between AI and our standards on human rights, democracy and rule of law, and to develop relevant standard setting or capacity-building solutions\". The large number of relevant documents identified by the CoE include guidelines, charters, papers, reports and strategies. [ 123 ] The authoring bodies of these AI regulation documents are not confined to one sector of society and include organizations, companies, bodies and nation-states. [ 71 ] In 2019, the Council of Europe initiated a process to assess the need for legally binding regulation of AI, focusing specifically on its implications for human rights and democratic values. Negotiations on a treaty began in September 2022, involving the 46 member states of the Council of Europe, as well as Argentina, Australia, Canada, Costa Rica, the Holy See, Israel, Japan, Mexico, Peru, the United States of America, and Uruguay, as well as the European Union. On 17 May 2024, the \" Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law \" was adopted. It was opened for signature on 5 September 2024. Although developed by a European organisation, the treaty is open for accession by states from other parts of the world. The first ten signatories were: Andorra, Georgia, Iceland, Norway, Moldova, San Marino, the United Kingdom, Israel, the United States, and the European Union. [ 124 ] [ 125 ] The Czech Republic adopted a National AI Strategy in 2019 and updated it in 2024 with the National AI Strategy of the Czech Republic 2030. [ 126 ] The updated strategy includes a provision to ensure effective legislation, to create codes of ethics for developers and users, to establish supervisory bodies and to promote the ethical use of AI. [ 127 ] The EU is one of the largest jurisdictions in the world and plays an active role in the global regulation of digital technology through the GDPR , [ 128 ] Digital Services Act , and the Digital Markets Act . [ 129 ] [ 130 ] For AI in particular, the Artificial intelligence Act is regarded in 2023 as the most far-reaching regulation of AI worldwide. [ 131 ] [ 132 ] Most European Union (EU) countries have their own national strategies towards regulating AI, but these are largely convergent. [ 71 ] The European Union is guided by a European Strategy on Artificial Intelligence, [ 133 ] supported by a High-Level Expert Group on Artificial Intelligence. [ 134 ] [ 135 ] In April 2019, the European Commission published its Ethics Guidelines for Trustworthy Artificial Intelligence (AI) , [ 136 ] following this with its Policy and investment recommendations for trustworthy Artificial Intelligence in June 2019. [ 137 ] The EU Commission's High Level Expert Group on Artificial Intelligence carries out work on Trustworthy AI, and the commission has issued reports on the Safety and Liability Aspects of AI and on the Ethics of Automated Vehicles. In 2020. the EU Commission sought views on a proposal for AI specific legislation, and that process is ongoing. [ 71 ] On February 2, 2020, the European Commission published its White Paper on Artificial Intelligence – A European approach to excellence and trust . [ 138 ] [ 139 ] The White Paper consists of two main building blocks, an 'ecosystem of excellence' and a 'ecosystem of trust'. The 'ecosystem of trust' outlines the EU's approach for a regulatory framework for AI. In its proposed approach, the Commission distinguishes AI applications based on whether they are 'high-risk' or not. Only high-risk AI applications should be in the scope of a future EU regulatory framework. An AI application is considered high-risk if it operates in a risky sector (such as healthcare, transport or energy) and is \"used in such a manner that significant risks are likely to arise\". For high-risk AI applications, the requirements are mainly about the : \"training data\", \"data and record-keeping\", \"information to be provided\", \"robustness and accuracy\", and \"human oversight\". There are also requirements specific to certain usages such as remote biometric identification. AI applications that do not qualify as 'high-risk' could be governed by a voluntary labeling scheme. As regards compliance and enforcement, the Commission considers prior conformity assessments which could include 'procedures for testing, inspection or certification' and/or 'checks of the algorithms and of the data sets used in the development phase'. A European governance structure on AI in the form of a framework for cooperation of national competent authorities could facilitate the implementation of the regulatory framework. [ 140 ] A January 2021 draft was leaked online on April 14, 2021, [ 141 ] before the Commission presented their official \"Proposal for a Regulation laying down harmonised rules on artificial intelligence\" a week later. [ 142 ] Shortly after, the Artificial Intelligence Act (also known as the AI Act) was formally proposed on this basis. [ 143 ] This proposal includes a refinement of the 2020 risk-based approach with, this time, 4 risk categories: \"minimal\", \"limited\", \"high\" and \"unacceptable\". [ 144 ] The proposal has been severely critiqued in the public debate. Academics have expressed concerns about various unclear elements in the proposal – such as the broad definition of what constitutes AI – and feared unintended legal implications, especially for vulnerable groups such as patients and migrants. [ 145 ] [ 146 ] The risk category \"general-purpose AI\" was added to the AI Act to account for versatile models like ChatGPT , which did not fit the application-based regulation framework. [ 147 ] Unlike for other risk categories, general-purpose AI models can be regulated based on their capabilities, not just their uses. Weaker general-purpose AI models are subject transparency requirements, while those considered to pose \"systemic risks\" (notably those trained using computational capabilities exceeding 10 25 FLOPS ) must also undergo a thorough evaluation process. [ 148 ] A subsequent version of the AI Act was finally adopted in May 2024. [ 149 ] The AI Act will be progressively enforced. [ 150 ] Recognition of emotions and real-time remote biometric identification will be prohibited, with some exemptions, such as for law enforcement. [ 151 ] The European Union's AI Act has created a regulatory framework with significant global implications. This legislation introduces a risk-based approach to categorizing AI systems, focusing on high-risk applications like healthcare, education, and public safety. [ 152 ] It requires organizations to ensure transparency, data governance, and human oversight in their AI solutions. While this aims to foster ethical AI use, the stringent requirements could increase overhead and compliance costs, delaying certain AI designs and deployments. [ 153 ] [ 154 ] [ 155 ] Observers have expressed concerns about the multiplication of legislative proposals under the von der Leyen Commission . The speed of the legislative initiatives is partially led by political ambitions of the EU and could put at risk the digital rights of the European citizens, including rights to privacy, [ 156 ] especially in the face of uncertain guarantees of data protection through cyber security. [ 135 ] Among the stated guiding principles in the variety of legislative proposals in the area of AI under the von der Leyen Commission are the objectives of strategic autonomy [ 157 ] and the concept of digital sovereignty. [ 158 ] On May 29, 2024, the European Court of Auditors published a report stating that EU measures were not well coordinated with those of EU countries; that the monitoring of investments was not systematic; and that stronger governance was needed. [ 159 ] The EU's Artificial Intelligence Act (Regulation (EU) 2024/1689) entered into force on 1 August 2024, creating a risk-based legal framework for AI systems, including special provisions for general-purpose AI models enforceable by 2 August 2025. [ 160 ] Finland has appointed a working group to evaluate what national legislation is required by the EU Artificial intelligence Act , and to prepare a legislative proposal on its national implementation. The working group began its evaluation on April 29, 2024, and is expected to conclude by June 30, 2026. [ 161 ] In November 2020, [ 162 ] DIN , DKE and the German Federal Ministry for Economic Affairs and Energy published the first edition of the \"German Standardization Roadmap for Artificial Intelligence\" (NRM KI) and presented it to the public at the Digital Summit of the Federal Government of Germany. [ 163 ] NRM KI describes requirements to future regulations and standards in the context of AI. The implementation of the recommendations for action is intended to help to strengthen the German economy and science in the international competition in the field of artificial intelligence and create innovation-friendly conditions for this emerging technology . The first edition is a 200-page long document written by 300 experts. The second edition of the NRM KI was published to coincide with the German government's Digital Summit on December 9, 2022. [ 164 ] DIN coordinated more than 570 participating experts from a wide range of fields from science, industry, civil society and the public sector. The second edition is a 450-page long document. On the one hand, NRM KI covers the focus topics in terms of applications (e.g. medicine, mobility, energy & environment, financial services, industrial automation) and fundamental issues (e.g. AI classification, security, certifiability, socio-technical systems, ethics). [ 164 ] On the other hand, it provides an overview of the central terms in the field of AI and its environment across a wide range of interest groups and information sources. In total, the document covers 116 standardisation needs and provides six central recommendations for action. [ 165 ] On October 30, 2022, pursuant to government resolution 212 of August 2021, the Israeli Ministry of Innovation, Science and Technology released its \"Principles of Policy, Regulation and Ethics in AI\" white paper for public consultation. [ 166 ] By December 2023, the Ministry of Innovation and the Ministry of Justice published a joint AI regulation and ethics policy paper, outlining several AI ethical principles and a set of recommendations including opting for sector-based regulation, a risk-based approach, preference for \"soft\" regulatory tools such as AI sandboxes [ 167 ] and maintaining consistency with existing global regulatory approaches to AI. [ 168 ] In December 2023, Israel unveiled its first comprehensive national AI policy, which was jointly developed through a collaboration between ministerial and stakeholder consultation. In general, the new policy outlines ethical principles aligned with current OECD guidelines and recommends a sector-based, risk-driven regulatory framework, which focuses on areas like transparency and accountability. [ 169 ] The policy proposes the creation of a national AI Policy Coordination Center to support regulators, and further developing the tools necessary for responsible AI deployment. In addition, alongside 56 other nations, to domestic policy development, Israel signed the world's first binding international treaty on artificial intelligence in March 2024. The specific treaty, led by the Council of Europe , has obliged signatories to ensure current AI systems uphold democratic values, human rights, and the rule of law. [ 170 ] In October 2023, the Italian privacy authority approved a regulation that provides three principles for therapeutic decisions taken by automated systems: transparency of decision-making processes, human supervision of automated decisions and algorithmic non-discrimination. [ 171 ] In March 2024, the President of the Italian Data Protection Authority reaffirmed their agency's readiness to implement the European Union's newly introduced Artificial Intelligence Act , praising the framework of institutional competence and independence. [ 172 ] Italy has continued to develop guidance on AI applications through existing legal frameworks, including recent innovations in areas such as facial recognition for law enforcement, AI in healthcare, deepfakes , and smart assistants . [ 173 ] The Italian government's National AI Strategy (2022–2024) emphasizes responsible innovation and outlines goals for talent development, public and private sector adoption, and regulatory clarity, particularly in coordination with EU-level initiatives. [ 172 ] While Italy has not enacted standalone AI legislation, courts and regulators have begun interpreting existing laws to address transparency, non-discrimination, and human oversight in algorithmic decision-making. In Morocco, a new legislative proposal has been put forward by a coalition of political parties in Parliament to establish the National Agency for Artificial Intelligence (AI). This agency is intended to regulate AI technologies, enhance collaboration with international entities in the field, and increase public awareness of both the possibilities and risks associated with AI. [ 174 ] In recent years, Morocco has made efforts to advance its use of artificial intelligence in the legal sector, particularly through AI tools that assist with judicial prediction and document analysis, helping to streamline case law research and support legal practitioners with more complex tasks. Alongside these efforts to establish a national AI agency, AI is being gradually introduced into legislative and judicial processes in Morocco, with ongoing discussions emphasizing the benefits as well as the potential risks of these technologies. [ 175 ] Generally speaking Morocco's broader digital policy includes robust data governance measures including the 2009 Personal Data Protection Law and the 2020 Cybersecurity Law, which establish requirements in areas such as privacy, breach notification, and data localization. [ 175 ] As of 2024, additional decrees have also expanded cybersecurity standards for cloud infrastructure and data audits within the nation. And while general data localization is not mandated, sensitive government and critical infrastructure data must be stored domestically. Oversight is led by the National Commission for the Protection of Personal Data (CNDP) and the General Directorate of Information Systems Security (DGSSI), though public enforcement actions in the country remain limited. [ 175 ] As of July 2023 [update] , no AI-specific legislation exists, but AI usage is regulated by existing laws, including the Privacy Act , the Human Rights Act , the Fair Trading Act and the Harmful Digital Communications Act . [ 176 ] In 2020, the New Zealand Government sponsored a World Economic Forum pilot project titled \"Reimagining Regulation for the Age of AI\", aimed at creating regulatory frameworks around AI. [ 177 ] The same year, the Privacy Act was updated to regulate the use of New Zealanders' personal information in AI. [ 178 ] In 2023, the Privacy Commissioner released guidance on using AI in accordance with information privacy principles. [ 179 ] In February 2024, the Attorney-General and Technology Minister announced the formation of a Parliamentary cross-party AI caucus , and that framework for the Government's use of AI was being developed. She also announced that no extra regulation was planned at that stage. [ 180 ] In 2023, a bill was filed in the Philippine House of Representatives which proposed the establishment of the Artificial Intelligence Development Authority (AIDA) which would oversee the development and research of artificial intelligence. AIDA was also proposed to be a watchdog against crimes using AI. [ 181 ] The Commission on Elections has also considered in 2024 the ban of using AI and deepfake for campaigning. They look to implement regulations that would apply as early as for the 2025 general elections. [ 182 ] In 2018, the Spanish Ministry of Science, Innovation and Universities approved an R&D Strategy on Artificial Intelligence. [ 183 ] With the formation of the second government of Pedro Sánchez in January 2020, the areas related to new technologies that, since 2018, were in the Ministry of Economy , were strengthened. Thus, in 2020 the Secretariat of State for Digitalization and Artificial Intelligence (SEDIA) was created. [ 184 ] From this higher body, following the recommendations made by the R&D Strategy on Artificial Intelligence of 2018, [ 185 ] the National Artificial Intelligence Strategy (2020) was developed, which already provided for actions concerning the governance of artificial intelligence and the ethical standards that should govern its use. This project was also included within the Recovery, Transformation and Resilience Plan (2021). During 2021, [ 184 ] the Government revealed that these ideas would be developed through a new government agency, and the General State Budget for 2022 authorized its creation and allocated five million euros for its development. [ 186 ] The Council of Ministers , at its meeting on 13 September 2022, began the process for the election of the AESIA headquarters. [ 187 ] [ 188 ] 16 Spanish provinces presented candidatures, with the Government opting for A Coruña , which proposed the La Terraza building. [ 189 ] On 22 August 2023, the Government approved the internal regulations of the Agency. [ 190 ] With this, Spain became the first European country with an agency dedicated to the supervision of AI, anticipating the entry into force of the future European Regulation on Artificial Intelligence, [ 191 ] which establishes the need for Member States to have with a supervisory authority in this matter. The agency officially launched its operations on 19 June 2024. [ 192 ] In April 2025, it became the reinforcing body for Spain's new law against unlabeled AI-generated content. [ 193 ] Switzerland currently has no specific AI legislation, but on 12 February 2025, the Federal Council announced plans to ratify the Council of Europe 's AI Convention and incorporate it into Swiss law. A draft bill and implementation plan are to be prepared by the end of 2026. The approach includes sector-specific regulation, limited cross-sector rules, such as data protection, and non-binding measures such as industry agreements. The goals are to support innovation, protect fundamental rights, and build public trust in AI. [ 194 ] The UK supported the application and development of AI in business via the Digital Economy Strategy 2015–2018 [ 195 ] introduced at the beginning of 2015 by Innovate UK as part of the UK Digital Strategy. [ 195 ] In the public sector, the Department for Digital, Culture, Media and Sport advised on data ethics and the Alan Turing Institute provided guidance on responsible design and implementation of AI systems. [ 196 ] [ 197 ] In terms of cyber security, in 2020 the National Cyber Security Centre has issued guidance on 'Intelligent Security Tools'. [ 52 ] [ 198 ] The following year, the UK published its 10-year National AI Strategy, [ 199 ] which describes actions to assess long-term AI risks, including AGI-related catastrophic risks. [ 200 ] In March 2023, the UK released the white paper A pro-innovation approach to AI regulation . [ 201 ] This white paper presents general AI principles, but leaves significant flexibility to existing regulators in how they adapt these principles to specific areas such as transport or financial markets. [ 202 ] In November 2023, the UK hosted the first AI safety summit , with the prime minister Rishi Sunak aiming to position the UK as a leader in AI safety regulation. [ 203 ] [ 204 ] During the summit, the UK created an AI Safety Institute , as an evolution of the Frontier AI Taskforce led by Ian Hogarth . The institute was notably assigned the responsibility of advancing the safety evaluations of the world's most advanced AI models, also called frontier AI models . [ 205 ] The UK government indicated its reluctance to legislate early, arguing that it may reduce the sector's growth and that laws might be rendered obsolete by further technological progress. [ 206 ] Discussions on regulation of AI in the United States have included topics such as the timeliness of regulating AI, the nature of the federal regulatory framework to govern and promote AI, including what agency should lead, the regulatory and governing powers of that agency, and how to update regulations in the face of rapidly changing technology, as well as the roles of state governments and courts. [ 207 ] On 12 December 2025, President Trump signed an executive order preventing states from creating their own AI restrictions, thereby forcing all states to follow the \"single national framework\". [ 208 ] “This is an executive order that orders aspects of your administration to take decisive action to ensure that AI can operate within a single national framework in this country, as opposed to being subject to state level regulation that could potentially cripple the industry”, White House aide Will Scharf said in the Oval Office, commenting on the executive order. Walter Donway, writing for a publication of the American Institute for Economic Research , criticized the order, saying, \"The premise behind it is philosophically wrong: that a central authority can foresee the risks of an emergent technology better than the distributed knowledge of millions of actors operating within a free market. That premise was wrong when applied to railroads, radio, electricity, telephony, airlines, and nuclear power. It is even more disastrously wrong when applied to artificial intelligence.\" [ 209 ] Regulation of fully autonomous weapons [ edit ] Legal questions related to lethal autonomous weapons systems (LAWS), in particular compliance with the laws of armed conflict , have been under discussion at the United Nations since 2013, within the context of the Convention on Certain Conventional Weapons . [ 210 ] Notably, informal meetings of experts took place in 2014, 2015 and 2016 and a Group of Governmental Experts (GGE) was appointed to further deliberate on the issue in 2016. A set of guiding principles on LAWS affirmed by the GGE on LAWS were adopted in 2018. [ 211 ] In 2016, China published a position paper questioning the adequacy of existing international law to address the eventuality of fully autonomous weapons, becoming the first permanent member of the U.N. Security Council to broach the issue, [ 53 ] and leading to proposals for global regulation. [ 212 ] The possibility of a moratorium or preemptive ban of the development and use of LAWS has also been raised on several occasions by other national delegations to the Convention on Certain Conventional Weapons and is strongly advocated for by the Campaign to Stop Killer Robots – a coalition of non-governmental organizations. [ 213 ] The US government maintains that current international humanitarian law is capable of regulating the development or use of LAWS. [ 214 ] The Congressional Research Service indicated in 2023 that the US does not have LAWS in its inventory, but that its policy does not prohibit the development and employment of it. [ 215 ] ^ Tallberg, Jonas; Erman, Eva; Furendal, Markus; Geith, Johannes; Klamberg, Mark; Lundgren, Magnus (2023). \"Global Governance of Artificial Intelligence: Next Steps for Empirical and Normative Research\" . International Studies Review . 25 (3) viad040. arXiv : 2305.11528 . doi : 10.1093/isr/viad040 . ^ Héder, M (2020). \"A criticism of AI ethics guidelines\" . Információs Társadalom . 20 (4): 57– 73. doi : 10.22503/inftars.XX.2020.4.5 . S2CID 233252939 . ^ Curtis, Caitlin; Gillespie, Nicole; Lockey, Steven (2022-05-24). \"AI-deploying organizations are key to addressing 'perfect storm' of AI risks\" . AI and Ethics . 3 (1): 145– 153. doi : 10.1007/s43681-022-00163-7 . ISSN 2730-5961 . PMC 9127285 . PMID 35634256 . ^ \"Europe sets benchmark for rest of the world with landmark AI laws\" . Reuters . 2024-05-22. ^ a b Vincent, James (3 April 2023). \"AI is entering an era of corporate control\" . The Verge . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . ^ \"Artificial Intelligence Index Report 2025\" . Human-Centered Artificial Intelligence . Stanford University . 2025. Archived from the original on 16 June 2025 . Retrieved 16 June 2025 . {{ cite web }} : CS1 maint: bot: original URL status unknown ( link ) ^ \"2025 State AI Wave Building After 700 Bills in 2024\" . www.bsa.org . Retrieved 2025-08-08 . ^ Varanasi, Lakshmi. \"OpenAI's Sam Altman says an international agency should monitor the 'most powerful' AI to ensure 'reasonable safety' \" . Business Insider . Archived from the original on 2025-04-09 . Retrieved 16 June 2025 . ^ Aloisi, Silva (19 June 2023). \"Elon Musk repeats call for artificial intelligence regulation\" . Reuters . Retrieved 16 June 2025 . ^ Milmo, Dqan (24 October 2023). \"This article is more than 1 year old AI risk must be treated as seriously as climate crisis, says Google DeepMind chief\" . The Guardian . Retrieved 16 June 2025 . ^ Sherry, Ben (5 June 2025). \"Why Anthropic CEO Dario Amodei Is Asking for AI Regulation\" . Inc . Retrieved 16 June 2025 . ^ \"Pause Giant AI Experiments: An Open Letter\" . Future of Life Institute . Retrieved 2025-06-16 . ^ Goldman, Sharon. \"How Mark Zuckerberg has fully rebuilt Meta around Llama\" . Fortune . Retrieved 16 June 2025 . ^ Heath, Ryan (17 October 2023). \"Civilization depends on more AI, Marc Andreessen says\" . Axios . Retrieved 16 June 2025 . ^ Edwards, Benj (17 May 2023). \"Poll: AI poses risk to humanity, according to majority of Americans\" . Ars Technica . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . ^ Kasperowicz, Peter (1 May 2023). \"Regulate AI? GOP much more skeptical than Dems that government can do it right: poll\" . Fox News . Archived from the original on 19 June 2023 . Retrieved 19 June 2023 . ^ \"Fox News Poll\" (PDF) . Fox News. 2023. Archived (PDF) from the original on 12 May 2023 . Retrieved 19 June 2023 . ^ Neuillé, Hugo (2025-02-05). \"From Safety To Action: The Upcoming French AI Summit | TechPolicy.Press\" . Tech Policy Press . Retrieved 2025-08-25 . ^ Barfield, Woodrow; Pagallo, Ugo (2018). Research handbook on the law of artificial intelligence . Cheltenham, UK: Edward Elgar Publishing. ISBN 978-1-78643-904-8 . OCLC 1039480085 . ^ a b Artificial intelligence in society . Paris: Organisation for Economic Co-operation and Development. 11 June 2019. ISBN 978-92-64-54519-9 . OCLC 1105926611 . ^ Kamyshansky, Vladimir P.; Rudenko, Evgenia Y.; Kolomiets, Evgeniy A.; Kripakova, Dina R. (2020). \"Revisiting the Place of Artificial Intelligence in Society and the State\". Artificial Intelligence: Anthropogenic Nature vs. Social Origin . Advances in Intelligent Systems and Computing. Vol. 1100. Cham: Springer International Publishing. pp. 359– 364. doi : 10.1007/978-3-030-39319-9_41 . ISBN 978-3-030-39318-2 . S2CID 213070224 . ^ Buiten, Miriam C. (2019). \"Towards Intelligent Regulation of Artificial Intelligence\" . European Journal of Risk Regulation . 10 (1): 41– 59. doi : 10.1017/err.2019.8 . ^ \"Co-Governance and the Future of AI Regulation\" . Harvard Law Review . 10 April 2025 . Retrieved 16 June 2025 . ^ \"Not all AI models should be freely available, argues a legal scholar\" . The Economist . Retrieved 16 June 2025 . ^ \"Keep the code behind AI open, say two entrepreneurs\" . The Economist . Retrieved 16 June 2025 . ^ \"Special Issue on Soft Law Governance of Artificial Intelligence: IEEE Technology and Society Magazine publication information\" . IEEE Technology and Society Magazine . 40 (4): C2. December 2021. doi : 10.1109/MTS.2021.3126194 . ^ a b c d e Marchant, Gary. \" \"Soft Law\" Governance of AI\" (PDF) . AI Pulse . AI PULSE Papers. Archived (PDF) from the original on 21 March 2023 . Retrieved 28 February 2023 . ^ a b c Johnson, Walter G.; Bowman, Diana M. (December 2021). \"A Survey of Instruments and Institutions Available for the Global Governance of Artificial Intelligence\". IEEE Technology and Society Magazine . 40 (4): 68– 76. Bibcode : 2021ITSMg..40d..68J . doi : 10.1109/MTS.2021.3123745 . S2CID 245053179 . ^ Sutcliffe, Hillary R.; Brown, Samantha (December 2021). \"Trust and Soft Law for AI\". IEEE Technology and Society Magazine . 40 (4): 14– 24. Bibcode : 2021ITSMg..40d..14S . doi : 10.1109/MTS.2021.3123741 . S2CID 244955938 . ^ a b Schmit, C. D.; Doerr, M. J.; Wagner, J. K. (17 February 2023). \"Leveraging IP for AI governance\". Science . 379 (6633): 646– 648. Bibcode : 2023Sci...379..646S . doi : 10.1126/science.add2202 . PMID 36795826 . S2CID 256901479 . ^ deVadoss, John. \"Don't Regulate AI Models. Regulate AI Use\" . IEEE Spectrum . IEEE . Retrieved 2026-02-02 . ^ \"EU AI Act: first regulation on artificial intelligence\" . European Parliament . European Parliament. 2023-06-08 . Retrieved 2026-02-02 . ^ Lima-Strong, Cristiano (16 May 2024). \"Youth activists call on world leaders to set AI safeguards by 2030\" . Washington Post . Retrieved 24 June 2024 . ^ Haldane, Matt (21 May 2024). \"Student AI activists at Encode Justice release 22 goals for 2030 ahead of global summit in Seoul\" . Archived from the original on 25 September 2024 . Retrieved 24 June 2024 . ^ Fjeld, Jessica; Achten, Nele; Hilligoss, Hannah; Nagy, Adam; Srikumar, Madhu (2020-01-15). Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-based Approaches to Principles for AI (Report). Berkman Klein Center for Internet & Society. Archived from the original on 2021-07-16 . Retrieved 2021-07-04 . ^ Wirtz, Bernd W.; Weyerer, Jan C.; Geyer, Carolin (2018-07-24). \"Artificial Intelligence and the Public Sector—Applications and Challenges\" . International Journal of Public Administration . 42 (7): 596– 615. doi : 10.1080/01900692.2018.1498103 . ISSN 0190-0692 . S2CID 158829602 . Archived from the original on 2020-08-18 . Retrieved 2020-08-17 . ^ Wirtz, Bernd W.; Weyerer, Jan C.; Sturm, Benjamin J. (2020-04-15). \"The Dark Sides of Artificial Intelligence: An Integrated AI Governance Framework for Public Administration\". International Journal of Public Administration . 43 (9): 818– 829. doi : 10.1080/01900692.2020.1749851 . ISSN 0190-0692 . S2CID 218807452 . ^ a b Bredt, Stephan (2019-10-04). \"Artificial Intelligence (AI) in the Financial Sector—Potential and Public Strategies\" . Frontiers in Artificial Intelligence . 2 16. doi : 10.3389/frai.2019.00016 . ISSN 2624-8212 . PMC 7861258 . PMID 33733105 . ^ a b c White Paper: On Artificial Intelligence – A European approach to excellence and trust (PDF) . Brussels: European Commission. 2020. p. 1. ^ Wirtz, Bernd W.; Müller, Wilhelm M. (2018-12-03). \"An integrated artificial intelligence framework for public management\". Public Management Review . 21 (7): 1076– 1100. doi : 10.1080/14719037.2018.1549268 . ISSN 1471-9037 . S2CID 158267709 . ^ Reisman, Dillon; Schultz, Jason; Crawford, Kate; Whittaker, Meredith (2018). Algorithmic impact assessments: A practical framework for public agency accountability (PDF) . New York: AI Now Institute. Archived from the original (PDF) on 2020-06-14 . Retrieved 2020-04-28 . ^ a b \"Towards Responsible Artificial Intelligence Innovation\" . UNICRI . July 2020. Archived from the original on 2022-07-05 . Retrieved 2022-07-18 . ^ Kohli, Ajay; Mahajan, Vidur; Seals, Kevin; Kohli, Ajit; Jha, Saurabh (2019). \"Concepts in U.S. Food and Drug Administration Regulation of Artificial Intelligence for Medical Imaging\". American Journal of Roentgenology . 213 (4): 886– 888. doi : 10.2214/ajr.18.20410 . ISSN 0361-803X . PMID 31166758 . S2CID 174813195 . ^ Hwang, Thomas J.; Kesselheim, Aaron S.; Vokinger, Kerstin N. (2019-12-17). \"Lifecycle Regulation of Artificial Intelligence– and Machine Learning–Based Software Devices in Medicine\". JAMA . 322 (23): 2285– 2286. doi : 10.1001/jama.2019.16842 . ISSN 0098-7484 . PMID 31755907 . S2CID 208230202 . ^ Sharma, Kavita; Manchikanti, Padmavati (2020-10-01). \"Regulation of Artificial Intelligence in Drug Discovery and Health Care\". Biotechnology Law Report . 39 (5): 371– 380. doi : 10.1089/blr.2020.29183.ks . ISSN 0730-031X . S2CID 225540889 . ^ Petkus, Haroldas; Hoogewerf, Jan; Wyatt, Jeremy C (2020). \"What do senior physicians think about AI and clinical decision support systems: Quantitative and qualitative analysis of data from specialty societies\" . Clinical Medicine . 20 (3): 324– 328. doi : 10.7861/clinmed.2019-0317 . ISSN 1470-2118 . PMC 7354034 . PMID 32414724 . ^ Cheng, Jerome Y.; Abel, Jacob T.; Balis, Ulysses G.J.; McClintock, David S.; Pantanowitz, Liron (2021). \"Challenges in the Development, Deployment, and Regulation of Artificial Intelligence in Anatomic Pathology\" . The American Journal of Pathology . 191 (10): 1684– 1692. doi : 10.1016/j.ajpath.2020.10.018 . ISSN 0002-9440 . PMID 33245914 . S2CID 227191875 . ^ \"AI in Lending: AI Credit Regulations Affecting Lending Business 2025\" . hesfintech . 10 October 2025. Archived from the original on 12 October 2025 . Retrieved 12 October 2025 . ^ a b c Gurkaynak, Gonenc; Yilmaz, Ilay; Haksever, Gunes (2016). \"Stifling artificial intelligence: Human perils\". Computer Law & Security Review . 32 (5): 749– 758. doi : 10.1016/j.clsr.2016.05.003 . ISSN 0267-3649 . ^ Iphofen, Ron; Kritikos, Mihalis (2019-01-03). \"Regulating artificial intelligence and robotics: ethics by design in a digital society\". Contemporary Social Science . 16 (2): 170– 184. doi : 10.1080/21582041.2018.1563803 . ISSN 2158-2041 . S2CID 59298502 . ^ AI principles: Recommendations on the ethical use of artificial intelligence by the Department of Defense (PDF) . Washington, DC: United States Defense Innovation Board. 2019. OCLC 1126650738 . Archived from the original (PDF) on 2020-01-14 . Retrieved 2020-03-28 . ^ a b c Babuta, Alexander; Oswald, Marion; Janjeva, Ardi (2020). Artificial Intelligence and UK National Security: Policy Considerations (PDF) . London: Royal United Services Institute. Archived from the original (PDF) on 2020-05-02 . Retrieved 2020-04-28 . ^ a b \"Robots with Guns: The Rise of Autonomous Weapons Systems\" . Snopes.com . 21 April 2017. Archived from the original on 25 September 2024 . Retrieved 24 December 2017 . ^ Bento, Lucas (2017). \"No Mere Deodands: Human Responsibilities in the Use of Violent Intelligent Systems Under Public International Law\" . Harvard Scholarship Depository . Archived from the original on 2020-03-23 . Retrieved 2019-09-14 . ^ Kissinger, Henry (1 November 2021). \"The Challenge of Being Human in the Age of AI\" . The Wall Street Journal . Archived from the original on 4 November 2021 . Retrieved 4 November 2021 . ^ \"UK and US refuse to sign international AI declaration\" . BBC News . 2025-02-11 . Retrieved 2025-08-25 . ^ a b c d Sotala, Kaj; Yampolskiy, Roman V (2014-12-19). \"Responses to catastrophic AGI risk: a survey\" . Physica Scripta . 90 (1) 018001. Bibcode : 2015PhyS...90a8001S . doi : 10.1088/0031-8949/90/1/018001 . ISSN 0031-8949 . ^ a b Barrett, Anthony M.; Baum, Seth D. (2016-05-23). \"A model of pathways to artificial superintelligence catastrophe for risk and decision analysis\". Journal of Experimental & Theoretical Artificial Intelligence . 29 (2): 397– 414. arXiv : 1607.07730 . doi : 10.1080/0952813x.2016.1186228 . ISSN 0952-813X . S2CID 928824 . ^ \"AI Index Report 2024 - chapter 3: Responsible AI\" (PDF) . aiindex.stanford.edu . April 2024. Archived (PDF) from the original on 2024-05-24 . Retrieved 2024-06-07 . ^ Boyd, Matthew; Wilson, Nick (2017-11-01). \"Rapid developments in Artificial Intelligence: how might the New Zealand government respond?\" . Policy Quarterly . 13 (4). doi : 10.26686/pq.v13i4.4619 . ISSN 2324-1101 . ^ Innovation, Science and Economic Development Canada (2019-05-16). \"Declaration of the International Panel on Artificial Intelligence\" . gcnws . Archived from the original on 2020-03-29 . Retrieved 2020-03-29 . ^ Simonite, Tom (2020-01-08). \"The world has a plan to rein in AI—but the US doesn't like it\" . Wired . Archived from the original on 2020-04-18 . Retrieved 2020-03-29 . ^ a b \"AI Regulation: Has the Time Arrived?\" . InformationWeek . 24 February 2020. Archived from the original on 2020-05-23 . Retrieved 2020-03-29 . ^ a b c d e f g UNESCO Science Report: the Race Against Time for Smarter Development . Paris: UNESCO. 11 June 2021. ISBN 978-92-3-100450-6 . Archived from the original on 18 June 2022 . Retrieved 18 September 2021 . ^ \"Community\" . GPAI . Archived from the original on March 30, 2023. ^ \"AI-Principles Overview\" . OECD.AI . Archived from the original on 2023-10-23 . Retrieved 2023-10-20 . ^ G20 Ministerial Statement on Trade and Digital Economy (PDF) . Tsukuba City, Japan: G20. 2019. ^ \"International AI ethics panel must be independent\" . Nature . 572 (7770): 415. 2019-08-21. Bibcode : 2019Natur.572R.415. . doi : 10.1038/d41586-019-02491-x . PMID 31435065 . ^ Guidelines for AI Procurement (PDF) . Cologny/Geneva: World Economic Forum. 2019. Archived (PDF) from the original on 2020-07-17 . Retrieved 2020-04-28 . ^ \"High-Level Event: Artificial Intelligence and Robotics – Reshaping the Future of Crime, Terrorism and Security\" . UNICRI . Archived from the original on 2022-07-18 . Retrieved 2022-07-18 . ^ a b c d NíFhaoláin, Labhaoise; Hines, Andrew; Nallur, Vivek (2020). Assessing the Appetite for Trustworthiness and the Regulation of Artificial Intelligence in Europe (PDF) . Dublin: Technological University Dublin, School of Computer Science, Dublin. pp. 1– 12. Archived (PDF) from the original on 2021-01-15 . Retrieved 2021-03-27 . This article incorporates text available under the CC BY 4.0 license. (The CC BY 4.0 licence means that everyone have the right to reuse the text that is quoted here, or other parts of the original article itself, if they credit the authors. More info: Creative Commons license ) Changes were made as follows: citations removed and minor grammatical amendments. ^ \"Recommendation on the ethics of artificial intelligence\" . UNESCO . 2020-02-27. Archived from the original on 2022-07-18 . Retrieved 2022-07-18 . ^ Nindler, Reinmar (2019-03-11). \"The United Nation's Capability to Manage Existential Risks with a Focus on Artificial Intelligence\" . International Community Law Review . 21 (1): 5– 34. doi : 10.1163/18719732-12341388 . ISSN 1871-9740 . S2CID 150911357 . Archived from the original on 2022-08-30 . Retrieved 2022-08-30 . ^ Taddeo, Mariarosaria; Floridi, Luciano (April 2018). \"Regulate artificial intelligence to avert cyber arms race\" . Nature . 556 (7701): 296– 298. Bibcode : 2018Natur.556..296T . doi : 10.1038/d41586-018-04602-6 . PMID 29662138 . ^ a b \"Promoting and Advancing Human Rights in Global AI Ecosystems\" . AI Ethics Lab at Rutgers University . 2025. Archived from the original on 17 March 2025 . Retrieved 28 June 2025 . ^ \"The Munich Convention on AI, Data and Human Rights\" . ResearchGate . October 2024. ^ Fourie, Willem (2025-08-20). \"Stellenbosch dialogue advances AI and human rights convention\" . The Policy Innovation Lab . Retrieved 2025-08-25 . ^ \"Hiroshima Process International Guiding Principles for Advanced AI system | Shaping Europe's digital future\" . digital-strategy.ec.europa.eu . 2023-10-30. Archived from the original on 2023-11-01 . Retrieved 2023-11-01 . ^ a b \"G7 AI Principles and Code of Conduct\" . Ernst & Young . January 19, 2024 . Retrieved May 7, 2025 . ^ Schildkraut, Peter J. (January 19, 2024). \"What the G7 Code of Conduct Means for Global AI Compliance Programs\" . Arnold & Porter . Retrieved May 8, 2025 . ^ \"Artificial Intelligence and Robotics\" . UNICRI . Archived from the original on 2020-10-19 . Retrieved 2020-08-08 . ^ Law Library of Congress (U.S.). Global Legal Research Directorate, issuing body. Regulation of artificial intelligence in selected jurisdictions . LCCN 2019668143 . OCLC 1110727808 . ^ Popova, Anna V.; Gorokhova, Svetlana S.; Abramova, Marianna G.; Balashkina, Irina V. (2021), The System of Law and Artificial Intelligence in Modern Russia: Goals and Instruments of Digital Modernization , Studies in Systems, Decision and Control, vol. 314, Cham: Springer International Publishing, pp. 89– 96, doi : 10.1007/978-3-030-56433-9_11 , ISBN 978-3-030-56432-2 , S2CID 234309883 ^ \"OECD Observatory of Public Sector Innovation – Ai Strategies and Public Sector Components\" . 21 November 2019. Archived from the original on 2024-09-25 . Retrieved 2020-05-04 . ^ Berryhill, Jamie; Heang, Kévin Kok; Clogher, Rob; McBride, Keegan (2019). Hello, World: Artificial Intelligence and its Use in the Public Sector (PDF) . Paris: OECD Observatory of Public Sector Innovation. Archived (PDF) from the original on 2019-12-20 . Retrieved 2020-05-05 . ^ Campbell, Thomas A. (2019). Artificial Intelligence: An Overview of State Initiatives (PDF) . Evergreen, CO: FutureGrasp, LLC. Archived from the original (PDF) on March 31, 2020. ^ Bradford, Anu (2023-06-27). \"The Race to Regulate Artificial Intelligence\" . Foreign Affairs . ISSN 0015-7120 . Archived from the original on 2023-08-11 . Retrieved 2023-08-11 . ^ \"Study on human and peoples' rights and artificial intelligence, robotics, and other new and emerging technologies in Africa\" (PDF) . African Commission on Human and Peoples' Rights . 2025-04-08. ^ Odero, Brenda; Nderitu, David; Samuel, Gabrielle (2024). \"The Ubuntu Way: Ensuring Ethical AI Integration in Health Research\" . Wellcome Open Research . 9 : 625. doi : 10.12688/wellcomeopenres.23021.1 . ISSN 2398-502X . PMC 11599802 . PMID 39606617 . ^ Yilma, Kinfe (2025-05-16). \"Ethics of AI in Africa: Interrogating the role of Ubuntu and AI governance initiatives\". Ethics and Information Technology . 27 (2) 24. doi : 10.1007/s10676-025-09834-5 . ISSN 1572-8439 . ^ \"What's in a word: the meaning of Ubuntu\" . The Dandelion Philosophy . Retrieved 2025-09-24 . ^ a b \"Australia needs a national approach to AI strategy\" . Information Age . Retrieved 2023-11-08 . ^ a b \"AI Watch: Global regulatory tracker - Australia\" . whitecase.com . 16 December 2024 . Retrieved May 8, 2025 . ^ \"Câmara aprova marco legal da inteligência artificial no Brasil\" . Revista Globo Rural (in Brazilian Portuguese). 2022-08-24 . Retrieved 2025-06-16 . ^ a b Belli, Luca; Curzi, Yasmin; Gaspar, Walter B. (2023-04-01). \"AI regulation in Brazil: Advancements, flows, and need to learn from the data protection experience\" . Computer Law & Security Review . 48 105767. doi : 10.1016/j.clsr.2022.105767 . ISSN 2212-473X . ^ \"Insufficiency of Ethical Principles for the Regulation of Artificial Intelligence: Antiracism and Antidiscrimination as Vectors for AI Regulation in Brazil\" . Data Privacy Brasil Research . Retrieved 2025-06-16 . ^ \"Brazil: Introduced Bill No. 2338 of 2023 regulating the use of Artificial Intelligence, including algorithm design and technical standards\" . digitalpolicyalert.org . 2023 . Retrieved 16 June 2025 . ^ \"Government of Canada launches second phase of the Pan-Canadian Artificial Intelligence Strategy\" . Innovation, Science and Economic Development Canada . 2022-06-22. Archived from the original on 2023-10-26 . Retrieved 2023-10-24 . ^ \"Bill C-27 summary: Digital Charter Implementation Act, 2022\" . Government of Canada . 2022-08-18. Archived from the original on 2023-12-20 . Retrieved 2023-10-24 . ^ \"Government Bill (House of Commons) C-27 (44–1) – First Reading – Digital Charter Implementation Act, 2022\" . Parliament of Canada . 2022-06-16 . Retrieved 2022-07-12 . ^ \"Intelligence and Data Act\" . Innovation, Science and Economic Development Canada . 2023-09-27 . Retrieved May 4, 2025 . ^ a b \"AI Watch: Global regulatory tracker – Canada\" . Whitecase.com . 2024-12-16 . Retrieved May 8, 2025 . ^ State Council China. \"New Generation of Artificial Intelligence Development Plan\" . www.unodc.org . Archived from the original on June 7, 2023 . Retrieved 2022-07-18 . ^ Department of International Cooperation Ministry of Science and Technology (September 2017). \"Next Generation Artificial Intelligence Development Plan Issued by State Council\" (PDF) . China Science & Technology Newsletter (17): 2– 12. Archived from the original (PDF) on January 21, 2022 – via Ministry of Foreign Affairs of China . ^ Wu, Fei; Lu, Cewu; Zhu, Mingjie; Chen, Hao; Zhu, Jun; Yu, Kai; Li, Lei; Li, Ming; Chen, Qianfeng; Li, Xi; Cao, Xudong (2020). \"Towards a new generation of artificial intelligence in China\" . Nature Machine Intelligence . 2 (6): 312– 316. doi : 10.1038/s42256-020-0183-4 . ISSN 2522-5839 . S2CID 220507829 . Archived from the original on 2022-07-18 . Retrieved 2022-07-18 . ^ \"Ethical Norms for New Generation Artificial Intelligence Released\" . Center for Security and Emerging Technology . Archived from the original on 2023-02-10 . Retrieved 2022-07-18 . ^ \"China just gave the world a blueprint for reigning in generative A.I.\" Fortune . Archived from the original on 2023-07-24 . Retrieved 2023-07-24 . ^ a b c \"Navigating the Complexities of AI Regulation in China\" . Reed Smith . August 2024 . Retrieved 2025-05-08 . ^ Sharma, Animesh Kumar; Sharma, Rahul (2024). \"Comparative Analysis of Data Protection Laws and ai Privacy Risks in brics Nations: A Comprehensive Examination\" . Global Journal of Comparative Law . 13 (1): 56– 85. doi : 10.1163/2211906X-13010003 (inactive 5 July 2025). {{ cite journal }} : CS1 maint: DOI inactive as of July 2025 ( link ) ^ a b Sheehan, Matt (2024-02-27). \"Tracing the Roots of China's AI Regulations\" . Carnegie Endowment for International Peace . Retrieved 2025-05-06 . ^ \"Measures for Labeling of AI-Generated Synthetic Content\" . China Law Translate . Retrieved 12 December 2025 . ^ \"Política nacional de explotación de datos (Big Data) | CONPES 3920\" (PDF) . National Planning Department, Ministry of Information and Communications Technology, and Superintendency of Industry and Commerce (in Spanish). 2018-04-17 . Retrieved 2025-06-16 . ^ a b c \"Colombia adopta de forma temprana recomendaciones de ética en Inteligencia Artificial de la Unesco para la región\" . Ministry of Information and Communications Technology (in Spanish). 2022-03-09 . Retrieved 2025-06-16 . ^ \"Declaración de santiago\" (PDF) . Cumbre Ministerial y de Altas Autoridades de América Latina y el Caribe (in Spanish). October 2023 . Retrieved 2025-06-16 . ^ \"Hoja de Ruta Para el Desarrollo y Aplicación de la Inteligencia Artificial en Colombia\" (PDF) . Ministry of Science, Technology and Innovation (in Spanish). 2024 . Retrieved 2025-06-16 . ^ \"Circular externa No. DE 2024\" (PDF) . Superintendence of Industry and Commerce (in Spanish). 2024-08-21 . Retrieved 2025-06-16 . ^ \"Acuerdo PCSJA24-12243\" (PDF) . Judiciary Council (in Spanish). 2024-12-16 . Retrieved 2025-06-16 . ^ \"Recommendation of the Council on Artificial Intelligence\" . OECD Legal Instruments . Retrieved 2025-06-16 . ^ \"Homepage | Global Digital Compact\" . United Nations . Retrieved 2025-06-16 . ^ \"Seizing the opportunities of safe, secure and trustworthy artificial intelligence systems for sustainable development\" . United Nations General Assembly . 2024-03-11 . Retrieved 2025-06-16 . ^ \"Política nacional de intelligencia artificial | CONPES 4144\" (PDF) . National Planning Department (in Spanish). 2025-02-14 . Retrieved 2025-06-16 . ^ \"Sentencia T-067/25\" . Constitutional Court of Colombia (in Spanish). 2025 . Retrieved 2025-06-16 . ^ \"Council of Europe and Artificial Intelligence\" . Artificial Intelligence . Archived from the original on 2024-01-19 . Retrieved 2021-07-29 . ^ \"The Framework Convention on Artificial Intelligence\" . Council of Europe . Archived from the original on 2024-09-05 . Retrieved 2024-09-05 . ^ \"Council of Europe opens first ever global treaty on AI for signature\" . Council of Europe . 5 September 2024. Archived from the original on 2024-09-17 . Retrieved 2024-09-17 . ^ \"Artificial Intelligence | MPO\" . mpo.gov.cz . Retrieved 2025-06-16 . ^ \"Czechia as a technological leader. Government approved the National Strategy for Artificial Intelligence of the Czech Republic 2030\" . mpo.gov.cz . 2024-07-24 . Retrieved 2025-06-16 . ^ Peukert, Christian; Bechtold, Stefan; Kretschmer, Tobias; Batikas, Michail (2020-09-30). \"Regulatory export and spillovers: How GDPR affects global markets for data\" . CEPR . Archived from the original on 2023-10-26 . Retrieved 2023-10-26 . ^ Coulter, Martin (2023-08-24). \"Big Tech braces for EU Digital Services Act regulations\" . Reuters . Archived from the original on 2023-10-26 . Retrieved 2023-10-26 . ^ \"Europe's new role in digital regulation\" . Le Monde.fr . 2023-08-28. Archived from the original on 2023-10-26 . Retrieved 2023-10-26 . ^ Satariano, Adam (2023-06-14). \"Europeans Take a Major Step Toward Regulating A.I.\" The New York Times . ISSN 0362-4331 . Archived from the original on 2023-10-26 . Retrieved 2023-10-25 . ^ Browne, Ryan (2023-06-14). \"EU lawmakers pass landmark artificial intelligence regulation\" . CNBC . Archived from the original on 2023-10-26 . Retrieved 2023-10-25 . ^ Anonymous (2018-04-25). \"Communication Artificial Intelligence for Europe\" . Shaping Europe's digital future – European Commission . Archived from the original on 2020-05-13 . Retrieved 2020-05-05 . ^ smuhana (2018-06-14). \"High-Level Expert Group on Artificial Intelligence\" . Shaping Europe's digital future – European Commission . Archived from the original on 2019-10-24 . Retrieved 2020-05-05 . ^ a b Andraško, Jozef; Mesarčík, Matúš; Hamuľák, Ondrej (2021-01-02). \"The regulatory intersections between artificial intelligence, data protection and cyber security: challenges and opportunities for the EU legal framework\". AI & Society . 36 (2): 623– 636. doi : 10.1007/s00146-020-01125-5 . ISSN 0951-5666 . S2CID 230109912 . ^ \"Ethics guidelines for trustworthy AI\" . European Commission . 2019. Archived from the original on 2023-03-29 . Retrieved 2022-05-30 . ^ \"Policy and investment recommendations for trustworthy Artificial Intelligence\" . Shaping Europe's digital future – European Commission . 2019-06-26 . Retrieved 2020-05-05 . ^ \"White Paper on Artificial Intelligence – a European approach to excellence and trust\" . European Commission . 19 February 2020. Archived from the original on 2024-01-05 . Retrieved 2021-06-07 . ^ Broadbent, Meredith (17 March 2021). \"What's Ahead for a Cooperative Regulatory Agenda on Artificial Intelligence?\" . www.csis.org . Archived from the original on 7 June 2021 . Retrieved 2021-06-07 . ^ European Commission. (2020). White paper on artificial intelligence: a European approach to excellence and trust . OCLC 1141850140 . ^ Heikkilä, Melissa (2021-04-14). \"POLITICO AI: Decoded: The EU's AI rules — Finland talks to machines — Facebook's fairness project\" (newsletter). POLITICO . Retrieved 2021-05-14. ^ European Commission (2021-04-21). Europe fit for the Digital Age: Commission proposes new rules and actions for excellence and trust in Artificial Intelligence (press release). Archived 2021-05-14 at the Wayback Machine . Retrieved 2021-05-14. ^ Pery, Andrew (2021-10-06). \"Trustworthy Artificial Intelligence and Process Mining: Challenges and Opportunities\" . DeepAI . Archived from the original on 2022-02-18 . Retrieved 2022-02-27 . ^ Browne, Ryan (2023-05-15). \"Europe takes aim at ChatGPT with what might soon be the West's first A.I. law. Here's what it means\" . CNBC . Retrieved 2023-10-25 . ^ Veale, Michael; Borgesius, Frederik Zuiderveen (2021-08-01). \"Demystifying the Draft EU Artificial Intelligence Act — Analysing the good, the bad, and the unclear elements of the proposed approach\" . Computer Law Review International . 22 (4): 97– 112. arXiv : 2107.03721 . doi : 10.9785/cri-2021-220402 . hdl : 2066/245672 . ISSN 2194-4164 . S2CID 235765823 . Archived from the original on 2023-03-26 . Retrieved 2023-01-12 . ^ van Kolfschooten, Hannah (January 2022). \"EU regulation of artificial intelligence: Challenges for patients' rights\" . Common Market Law Review . 59 (1): 81– 112. doi : 10.54648/COLA2022005 . S2CID 248591427 . Archived from the original on 2024-09-25 . Retrieved 2023-12-10 . ^ Coulter, Martin (December 7, 2023). \"What is the EU AI Act and when will regulation come into effect?\" . Reuters . Archived from the original on 2023-12-10 . Retrieved 2024-06-01 . ^ Bertuzzi, Luca (December 7, 2023). \"AI Act: EU policymakers nail down rules on AI models, butt heads on law enforcement\" . euractiv . Archived from the original on January 8, 2024 . Retrieved June 1, 2024 . ^ Browne, Ryan (2024-05-21). \"World's first major law for artificial intelligence gets final EU green light\" . CNBC . Archived from the original on 2024-05-21 . Retrieved 2024-06-01 . ^ \"Artificial Intelligence Act: MEPs adopt landmark law\" . European Parliament . 2024-03-13. Archived from the original on 2024-03-15 . Retrieved 2024-06-01 . ^ \"Experts react: The EU made a deal on AI rules. But can regulators move at the speed of tech?\" . Atlantic Council . 11 December 2023. ^ \"European approach to artificial intelligence | Shaping Europe's digital future\" . digital-strategy.ec.europa.eu . 2024-11-20 . Retrieved 2024-12-09 . ^ Blackman, Reid; Vasiliu-Feltes, Ingrid (2024-02-22). \"The EU's AI Act and How Companies Can Achieve Compliance\" . Harvard Business Review . ISSN 0017-8012 . Retrieved 2025-09-24 . ^ \"Clarifying the costs for the EU's AI Act\" . CEPS . 2021-09-24 . Retrieved 2025-09-24 . ^ \"Understanding the EU AI Act penalties and achieving regulatory compliance\" . 2021.ai . Retrieved 2025-09-24 . ^ Natale, Lara (February 2022). \"EU's digital ambitions beset with strategic dissonance\" . Encompass . Retrieved 25 February 2022 . ^ Bertuzzi, Luca; Killeen, Molly (17 September 2021). \"Digital Brief powered by Google: make it or break it, Chips Act, showing the path\" . Euractiv . Retrieved 25 February 2022 . ^ Propp, Kenneth (7 February 2022). \"France's new mantra: liberty, equality, digital sovereignty\" . Atlantic Council . Archived from the original on 25 February 2022 . Retrieved 25 February 2022 . ^ \"Artificial intelligence: EU must pick up the pace\" . European Court of Auditors . 29 May 2024. Archived from the original on 25 September 2024 . Retrieved 29 May 2024 . ^ \"Long awaited EU AI Act becomes law after publication in the EU's Official Journal | White & Case LLP\" . www.whitecase.com . 2024-07-16 . Retrieved 2025-08-03 . ^ \"National implementation of EU Artificial Intelligence Regulation\" . Ministry of Economic Affairs and Employment of Finland . Retrieved 2025-06-16 . ^ Klimaschutz, BMWK-Bundesministerium für Wirtschaft und. \" \"KI – Made in Germany\" etablieren\" . www.bmwk.de (in German). Archived from the original on 12 June 2023 . Retrieved 12 June 2023 . ^ \"DIN, DKE und BMWi veröffentlichen Normungsroadmap für Künstliche Intelligenz\" . all-electronics (in German) . Retrieved 12 June 2023 . ^ a b Runze, Gerhard; Haimerl, Martin; Hauer, Marc; Holoyad, Taras; Obert, Otto; Pöhls, Henrich; Tagiew, Rustam; Ziehn, Jens (2023). \"Ein Werkzeug für eine gemeinsame KI-Terminologie – Das AI-Glossary als Weg aus Babylon\" . Java Spektrum (in German) (3): 42– 46. Archived from the original on 2024-04-27 . Retrieved 2023-06-12 . ^ \"Normungsroadmap Künstliche Intelligenz\" . www.dke.de (in German) . Retrieved 12 June 2023 . ^ Cahane, Amir (November 13, 2022). \"Israeli AI regulation and policy white paper: a first glance\" . RAILS Blog . ^ Cahane, Amir; Sierra, Michael (2025-12-10). \"Nascent regulatory sandbox frameworks for AI in Israel\" . Cambridge Forum on AI: Law and Governance . 1 : e40. doi : 10.1017/cfl.2025.10032 . ISSN 3033-3733 . ^ Ministry of Innovation, Science and Technology and the Ministry of Justice (December 12, 2023). \"Israel's Policy on Artificial Intelligence Regulation and Ethics\" . ^ \"Artificial Intelligence Regulation and Ethics Policy\" . gov.il . December 17, 2023 . Retrieved 2025-05-07 . ^ Wroble, Sharon (2024-05-03). \"Israel Signs Global Treaty to Address Risks of Artificial Intelligence\" . Times of Israel . Retrieved 2025-05-08 . ^ Marzio Bartoloni (11 October 2023). \"Cures and artificial intelligence: privacy and the risk of the algorithm that discriminates\" . ^ a b \"AI Watch: Global regulatory tracker – Italy\" . whitecase.com . 2024-12-16 . Retrieved 2025-05-09 . ^ Olivi; Bocchi; Cirotti (2024-05-07). \"The road to the AI Act: The Italian approach – Part 3: The Italian national competent AI Authority\" . Dentons . Retrieved 2025-05-09 . ^ \"Morocco Proposes Legislation for National AI Agency\" . The Moroccan Times . 2024-04-24. Archived from the original on 2024-04-25 . Retrieved 2024-04-25 . ^ a b c Buza, Maria; Taha, Sherif (2025-04-09). \"DPA Digital Digest: Morocco [2025 Edition]\" . Digital Policy Alert . Retrieved May 8, 2025 . ^ Rebecca (2023-07-13). \"Why is regulating AI such a challenge?\" . Prime Minister's Chief Science Advisor . Archived from the original on 2024-09-25 . Retrieved 2024-08-20 . ^ \"Reimagining Regulation for the Age of AI: New Zealand Pilot Project\" . World Economic Forum . 2020-06-29. ^ Cann, Geraden (2023-05-25). \"Privacy Commission issues warning to companies and organisations using AI\" . Stuff . Archived from the original on 2024-09-25 . Retrieved 2024-08-20 . ^ \"Artificial Intelligence and the IPPs\" . www.privacy.org.nz . 2023-09-21. Archived from the original on 2024-08-20 . Retrieved 2024-08-20 . ^ \"Survey finds most Kiwis spooked about malicious AI - minister responds\" . The New Zealand Herald . 2024-02-21. Archived from the original on 2024-08-20 . Retrieved 2024-08-20 . ^ Arasa, Dale (13 March 2023). \"Philippine AI Bill Proposes Agency for Artificial Intelligence\" . Philippine Daily Inquirer . Archived from the original on 25 September 2024 . Retrieved 29 May 2024 . ^ Abarca, Charie (29 May 2024). \"Comelec wants AI ban on campaign materials ahead of 2025 polls\" . Philippine Daily Inquirer . Archived from the original on 29 May 2024 . Retrieved 29 May 2024 . ^ Ministry of Science of Spain (2018). \"Spanish RDI Strategy in Artificial Intelligence\" (PDF) . www.knowledge4policy.ec.europa.eu . Archived (PDF) from the original on 18 July 2023 . Retrieved 9 December 2023 . ^ a b \"Chaining the chatbots: Spain closes in on AI Act\" . POLITICO . 2023-06-22 . Retrieved 2023-09-03 . ^ Ministry of Science of Spain (2018). \"Spanish RDI Strategy in Artificial Intelligence\" (PDF) . www.knowledge4policy.ec.europa.eu . Retrieved 9 December 2023 . ^ Castillo, Carlos del (2021-12-28). \"España vigilará la Inteligencia Artificial como a los fármacos o los alimentos\" . elDiario.es (in Spanish) . Retrieved 2023-09-03 . ^ \"España comienza el proceso para elegir la sede de la futura Agencia Española de Supervisión de la IA\" . El Español (in Spanish). 2022-09-13 . Retrieved 2023-09-03 . ^ Marcos, José (2022-09-12). \"El Gobierno inicia con la Agencia de Inteligencia Artificial el traslado de sedes fuera de Madrid\" . El País (in Spanish) . Retrieved 2023-09-03 . ^ \"A Coruña acogerá la Agencia Española de Inteligencia Artificial\" . Europa Press. 2022-12-05 . Retrieved 2023-09-03 . ^ \"El Gobierno aprueba el estatuto de la Agencia Española de Supervisión de la Inteligencia Artificial\" . Europa Press. 2023-08-22 . Retrieved 2023-09-03 . ^ Guerrini, Federico. \"European Countries Race To Set The AI Regulatory Pace\" . Forbes . Retrieved 2023-09-04 . ^ \"Comienza la actividad de la Agencia Española de Supervisión de la Inteligencia Artificial\" . Computerworld.es (in Spanish) . Retrieved 2026-01-03 . ^ \"Spain's AI Detection Requirement: $38 Million Fine for Unlabeled AI\" . www.aiornot.com . Retrieved 2026-01-03 . ^ \"Artificial Intelligence: Overview and Switzerland's regulatory approach\" . Swiss Federal Office of Communications (OFCOM) . 12 February 2025 . Retrieved 31 March 2025 . ^ a b \"Digital economy strategy 2015 to 2018\" . www.ukri.org . 16 February 2015. Archived from the original on 2022-09-01 . Retrieved 2022-07-18 . ^ \"Data ethics and AI guidance landscape\" . GOV.UK . Archived from the original on 2023-10-26 . Retrieved 2023-10-26 . ^ Leslie, David (2019-06-11). \"Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector\" . Zenodo . arXiv : 1906.05684 . doi : 10.5281/zenodo.3240529 . S2CID 189762499 . Archived from the original on 2020-04-16 . Retrieved 2020-04-28 . ^ \"Intelligent security tools\" . www.ncsc.gov.uk . Archived from the original on 2020-04-06 . Retrieved 2020-04-28 . ^ Richardson, Tim. \"UK publishes National Artificial Intelligence Strategy\" . www.theregister.com . Archived from the original on 2023-02-10 . Retrieved 2022-01-01 . ^ The National AI Strategy of the UK Archived 2023-02-10 at the Wayback Machine , 2021 (actions 9 and 10 of the section \"Pillar 3 – Governing AI Effectively\") ^ \"A pro-innovation approach to AI regulation\" . GOV.UK . Archived from the original on 2023-10-27 . Retrieved 2023-10-27 . ^ Gikay, Asress Adimi (2023-06-08). \"How the UK is getting AI regulation right\" . The Conversation . Archived from the original on 2023-10-27 . Retrieved 2023-10-27 . ^ Browne, Ryan (2023-06-12). \"British Prime Minister Rishi Sunak pitches UK as home of A.I. safety regulation as London bids to be next Silicon Valley\" . CNBC . Archived from the original on 2023-07-27 . Retrieved 2023-10-27 . ^ \"AI Safety Summit: introduction (HTML)\" . GOV.UK . Archived from the original on 2023-10-26 . Retrieved 2023-10-27 . ^ \"Introducing the AI Safety Institute\" . GOV.UK . Archived from the original on 2024-07-07 . Retrieved 2024-07-08 . ^ Henshall, Will (2024-04-01). \"U.S., U.K. Will Partner to Safety Test AI\" . TIME . Archived from the original on 2024-07-07 . Retrieved 2024-07-08 . ^ Weaver, John Frank (2018-12-28). \"Regulation of artificial intelligence in the United States\" . Research Handbook on the Law of Artificial Intelligence : 155– 212. doi : 10.4337/9781786439055.00018 . ISBN 978-1-78643-905-5 . Archived from the original on 2020-06-30 . Retrieved 2020-06-29 . ^ Waldenberg, Samantha; Gold, Hadas; Duffy, Clare (2025-12-12). \"Trump signs executive order blocking states from enforcing their own regulations around AI\" . CNN . Retrieved 2025-12-13 . ^ Donway, Walter (2025-12-22). \"The Nationalization of AI Threatens Innovation and the American Mind\" . The Daily Economy . Retrieved 2025-12-24 . ^ \"Background on Lethal Autonomous Weapons Systems in the CCW\" . United Nations Geneva. Archived from the original on 2020-04-27 . Retrieved 2020-05-05 . ^ \"Guiding Principles affirmed by the Group of Governmental Experts on Emerging Technologies in the Area of Lethal Autonomous Weapons System\" (PDF) . United Nations Geneva. Archived from the original (PDF) on 2020-12-01 . Retrieved 2020-05-05 . ^ Baum, Seth (2018-09-30). \"Countering Superintelligence Misinformation\" . Information . 9 (10): 244. doi : 10.3390/info9100244 . ISSN 2078-2489 . ^ \"Country Views on Killer Robots\" (PDF) . The Campaign to Stop Killer Robots. Archived (PDF) from the original on 2019-12-22 . Retrieved 2020-05-05 . ^ Sayler, Kelley (2020). Artificial Intelligence and National Security: Updated November 10, 2020 (PDF) . Washington, DC: Congressional Research Service. Archived (PDF) from the original on May 8, 2020 . Retrieved May 27, 2021 . ^ \"Defense Primer: U.S. Policy on Lethal Autonomous Weapon Systems\" . Congressional Research Service . May 15, 2023. Archived from the original on November 1, 2023 . Retrieved October 18, 2023 .",
      "word_count": 15093,
      "extraction_method": "readability",
      "metadata": {
        "search_position": 2,
        "search_query": "AI regulation",
        "original_title": "Regulation of artificial intelligence - Wikipedia",
        "snippet": "Regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI)."
      },
      "timestamp": "2026-02-17T01:51:18.464004",
      "error": null
    },
    {
      "url": "https://www.anecdotes.ai/learn/ai-regulations-in-2025-us-eu-uk-japan-china-and-more",
      "title": "AI Regulations in 2025: US, EU, UK, Japan, China & More",
      "content": "What Are AI Regulations? AI regulations refer to the legal frameworks and guidelines established to oversee the development and deployment of artificial intelligence technologies. These regulations aim to address safety and societal concerns associated with AI systems and ensure they are used responsibly. AI regulations cover a range of issues, including data protection, safety of AI systems, algorithmic transparency, and accountability of AI systems and their creators. A few recent examples of AI regulations are the European Union’s AI Act, the USA’s Executive Order on Removing Barriers to AI Leadership and AI Bill of Rights, and the UK’s AI Regulation White Paper. In this article: The Importance of Regulating AI Technologies Key Components of AI Regulations AI Regulations Around the World AI International Initiatives 5 Best Practices to Adhere AI Regulations The Importance of Regulating AI Technologies Artificial intelligence poses a range of real-world concerns that make regulation both necessary and challenging. These issues span from immediate technical risks to broader societal and existential implications: Privacy: AI systems are often integrated with personal data and digital behavior. Governments like those in the EU are responding with legislation that prohibits high-risk AI applications such as real-time biometric surveillance and social scoring, reflecting public anxiety over surveillance and data misuse. China mandates pre-approval of algorithms and enforces alignment with state ideologies, highlighting the geopolitical dimension of AI governance. Safety and accountability: High-risk systems, such as those used in autonomous vehicles, healthcare, and public infrastructure, require pre-market testing, documentation, and human oversight under the EU’s AI Act. These measures aim to ensure that AI behaves reliably and transparently in critical areas. In the U.S., although there is no national law yet, agencies are stepping in to address AI risks in domains like finance, healthcare, and child safety. Existential risk: Leading AI scientists such as Geoffrey Hinton and Yoshua Bengio have warned about the potential for AI to become uncontrollable, posing risks on par with nuclear war or pandemics. Their concerns have led to global calls for prioritizing the mitigation of such risks. Economic concerns: AI’s impact on jobs and workforce dynamics has also become a central issue. While proponents argue that AI can drive productivity and innovation, critics worry about widespread job displacement and unequal benefits. Policymakers must balance the need to foster innovation with protecting workers. Geopolitical and trade tensions: The EU’s laws will apply to non-EU providers, exporting its regulatory standards. Meanwhile, the U.S. is likely to continue a fragmented approach, which could lead to inconsistencies but also allow more flexibility for innovation. These diverging strategies may lead to trade friction, particularly between democratic nations and authoritarian regimes like China. {{ banner-image }} Key Components of AI Regulations Various regulations affecting the development of and use of AI focus on the same set of objectives. Privacy and Data Protection Privacy and data protection are central to AI regulations, mandating that AI applications comply with legal standards regarding personal data use. Regulations require systems to respect user privacy, ensuring secure handling, storage, and processing of personal information. Effective privacy measures build public trust in AI technologies by protecting individuals' rights to data protection. Compliance with privacy regulations requires AI systems to integrate robust data security protocols and transparent data management practices. These measures ensure that data is only used for intended purposes and protects against unauthorized access. Safety and Security Safety and security components of AI regulations address potential threats posed by AI technologies to individuals and society. Regulations set standards to ensure AI applications operate safely, mitigating risks such as unintended harm or malicious misuse. Security measures protect AI systems against vulnerabilities and cyber threats that could compromise their integrity and functionality. Implementing safety standards involves adhering to best practices in system design, testing, and monitoring. Regular assessments and updates to security protocols are imperative to maintain safe AI operations. By emphasizing safety and security, AI regulations aim to protect public health, safety, and welfare. Transparency and Explainability Transparency and explainability in AI help stakeholders understand how AI systems make decisions. These components ensure that AI processes are not opaque, increasing trust among users and stakeholders. Regulators aim to implement measures requiring AI systems to disclose their functionality, enabling users to understand the system's decision pathways and the data influencing these decisions. Explainability also involves simplifying complex AI algorithms to make them comprehensible. By demystifying AI operations, stakeholders, including non-experts, can gain insights into system behavior. Accountability and Responsibility AI regulations emphasize accountability, ensuring those who develop and deploy AI systems are responsible for their impacts. Organizations must take ownership of the AI systems they produce, establish clear guidelines for accountability, and set mechanisms to assess performance and rectify issues. This ensures developers and companies remain answerable for the actions and decisions of AI systems. Responsibility extends to the appropriate use of AI applications, requiring stakeholders to align AI deployment with safety standards. By enforcing accountability measures, AI regulations prevent negligence and promote responsible use of AI technologies. AI Regulations Around the World 1. European Union (EU): AI Act In brief: What this regulation mandates Security : The Act mandates that high-risk AI systems meet standards for robustness, accuracy, and cybersecurity. Providers must conduct risk assessments and implement human oversight to ensure system integrity. Privacy : The AI Act complements the GDPR by enforcing transparency obligations, such as informing users when interacting with AI systems like chatbots or encountering AI-generated content. ‍ Regulation in-depth The AI Act is the European Union's legal framework for regulating artificial intelligence. Adopted in 2024, it aims to promote the development of trustworthy AI while protecting fundamental rights and public safety. It introduces a risk-based approach that categorizes AI systems into four risk levels: Unacceptable-risk AI systems are banned entirely. These include AI applications that manipulate users, exploit vulnerabilities, or enable mass biometric surveillance. The legislation prohibits practices like real-time remote biometric identification in public spaces and emotion recognition in schools and workplaces. High-risk AI systems—such as those used in critical infrastructure, education, employment, and law enforcement—are subject to strict compliance requirements. Providers must conduct risk assessments, ensure high-quality datasets, maintain detailed documentation, and implement human oversight. These systems must also meet standards for robustness, accuracy, and cybersecurity. Limited-risk AI systems face transparency obligations. For example, users must be informed when interacting with AI systems like chatbots or when encountering AI-generated content, especially deepfakes or media intended to inform the public. Minimal or no-risk AI —which includes most consumer applications like spam filters or video games—is not subject to regulation under the Act. The Act also introduces rules for general-purpose AI models, particularly those that could pose systemic risks. Providers of such models must implement risk mitigation measures and comply with transparency and copyright standards. These rules will come into effect in August 2025 and will be supported by a forthcoming Code of Practice. Official source: AI Act 2. USA: Executive Order 14179 In brief: What this regulation mandates Security : The order prioritizes national security by directing agencies to enhance U.S. dominance in AI technologies. While it doesn’t establish new cybersecurity requirements, it mandates that the federal government identify and remove existing policies that could obstruct the secure development of AI systems critical to national interests. Privacy : The order does not create new privacy standards but implicitly affects data governance by revoking previous directives, including those that emphasized data transparency and protection. This rollback may influence how federal agencies and private sector actors interpret and implement privacy safeguards in AI deployments. Regulation in-depth Executive Order 14179, issued in January 2025, reorients U.S. AI policy by revoking the 2023 Executive Order 14110 on “Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.” Its core objective is to eliminate federal policies perceived as impediments to innovation and U.S. dominance in AI. The order tasks the Assistant to the President for Science and Technology, the Special Advisor for AI and Crypto, and the National Security Advisor with developing a new AI action plan. This plan is intended to align federal policy with a pro-innovation, pro-competitiveness agenda and is due within 180 days of the order’s issuance. Key directives include: Reviewing all regulations and policies enacted under the prior AI executive order to identify and suspend or revise those conflicting with the new national strategy. Revising Office of Management and Budget memoranda (M-24-10 and M-24-18) to align with the current policy focus. Empowering agencies to grant exemptions to prior policy requirements while formal revocations or revisions are finalized. Notably, the order does not introduce direct regulatory obligations for private-sector AI developers. Instead, it focuses on creating a more permissive environment for innovation, particularly in sectors like defense, economics, and national security. While not a traditional regulation in the sense of imposing technical requirements, Executive Order 14179 significantly reshapes the federal landscape for AI governance by removing constraints and prioritizing U.S. global leadership. Official source: Executive Order 14179 3. USA: AI Bill of Rights In brief: What this regulation mandates Security : The blueprint advocates for AI systems to be safe and effective, requiring pre-deployment testing, risk identification, and ongoing monitoring to ensure they operate as intended and do not cause harm. Privacy : It emphasizes that users should have control over how their data is collected and used, with built-in protections against intrusive surveillance and misuse. Regulation in-depth The Blueprint for an AI Bill of Rights , released by the White House Office of Science and Technology Policy in October 2022, outlines a set of five principles intended to guide the design, use, and deployment of AI systems in the United States. While non-binding, the blueprint provides a foundational framework for federal agencies, private companies, and developers to promote accountable AI practices. The five principles are: Safe and effective systems : AI systems should be subject to pre-deployment testing, risk identification, and ongoing monitoring to ensure they operate as intended and do not cause harm. Data privacy : Users should have control over how their data is collected and used, with built-in protections against intrusive surveillance and misuse. Notice and explanation : People should be informed when an AI system is being used and provided with clear explanations about how it functions and affects them. Human alternatives, consideration, and fallback : Individuals should be able to opt out of AI-driven processes and access human decision-making when needed, especially in high-stakes contexts. Though not enforceable by law, the blueprint has influenced federal procurement guidelines, agency risk assessments, and sector-specific AI governance initiatives. It reflects the U.S. government's broader strategy of promoting trustworthy AI through voluntary standards, secure design, and public engagement. Official source: AI Bill of Rights 4. UK: AI Regulation White Paper In brief: What this regulation mandates Security : The UK's approach emphasizes safety, security, and robustness, requiring regulators to consider technical standards and practices for the security of machine learning. Privacy : While the framework builds on existing roles of sectoral regulators, it does not introduce sweeping AI-specific legislation, relying instead on context-based oversight to address privacy concerns. Regulation in-depth The UK’s approach to AI regulation, outlined in the 2023 white paper A Pro-Innovation Approach to AI Regulation , emphasizes flexibility, sector-specific oversight, and a commitment to responsible innovation. Rather than introducing sweeping AI-specific legislation or a central AI regulator, the UK has opted for a context-based framework that builds on the existing roles and expertise of sectoral regulators. This strategy aims to avoid stifling innovation. The framework includes five cross-sectoral principles: Safety, security and robustness Appropriate transparency and explainability Accountability and governance Contestability and redress These principles serve as guidelines for regulators to interpret and apply within their respective domains. Initially non-statutory, the government is considering whether to formalize a statutory duty for regulators to “have due regard” to these principles after an implementation period​. The framework includes new central functions within government to coordinate regulatory activity and support implementation. This includes publishing guidance, enabling regulator capability-building, and conducting cross-sector risk assessments. The UK also established a steering committee and launched an AI and Digital Hub to provide innovators with regulatory advice​. Official source: AI Regulation White Paper 5. Canada: Artificial Intelligence and Data Act (AIDA) In brief: What this regulation mandates Security : AIDA focuses on high-impact AI systems, requiring risk assessments, transparency, human oversight, and robustness to ensure safety and accountability. Privacy : The act aims to protect individuals by aligning with existing Canadian legal frameworks like privacy, consumer protection, and human rights legislation, ensuring responsible development and use of AI technologies. Regulation in-depth The Artificial Intelligence and Data Act (AIDA), introduced as part of Bill C-27 in 2022, is Canada’s proposed regulatory framework to ensure responsible development and use of AI technologies. It aims to protect individuals and uphold Canadian values while supporting innovation and international interoperability. AIDA uses a risk-based approach to regulate high-impact AI systems and is designed to work in tandem with existing Canadian legal frameworks like privacy, consumer protection, and human rights legislation. The act would authorize the Minister of Innovation, Science, and Industry to oversee enforcement, supported by a newly created AI and Data Commissioner. This office will initially focus on education and support, eventually expanding to compliance and enforcement. Regulations under AIDA will be developed through a multi-phase consultation process, with the law not expected to come into effect before 2025. AIDA focuses on high-impact AI systems—defined by factors such as potential harm to health, safety, or rights; severity and scale of use; and lack of existing regulatory coverage. Obligations for these systems include risk assessment, transparency, human oversight, safety, accountability, and robustness. These requirements are aligned with international AI governance norms and aim to ensure AI systems are safe and trustworthy. Official source: Artificial Intelligence and Data Act 6. China: Generative AI Regulation In brief: What this regulation mandates Security : Providers must maintain the security and reliability of their systems. In addition, providers are required to prevent the generation of illegal or harmful content. Privacy : The measures mandate lawful data use, requiring providers to obtain user consent, respect intellectual property, and ensure the legal sourcing of training data. Regulation in-depth China’s regulatory framework for generative artificial intelligence is anchored in the Interim Measures for the Management of Generative Artificial Intelligence Services (\"AI Measures\"), which took effect on August 15, 2023. These measures mark China's first administrative regulation directly targeting generative AI and are enforced by a coalition of state agencies led by the Cyberspace Administration of China. The AI Measures apply to all organizations providing generative AI services to the public within China, regardless of their country of incorporation. While sector-agnostic in scope, the rules interact with other AI-relevant laws such as the Cybersecurity Law, Personal Information Protection Law (PIPL), and various sector-specific guidelines in finance, healthcare, and automotive industries. The regulation outlines comprehensive compliance obligations for generative AI service providers. These include: Lawful data use : Providers must obtain user consent, respect intellectual property, and ensure the legal sourcing of training data. Transparency and labeling : AI-generated content must be clearly labeled—either explicitly (e.g., visible watermarks) or implicitly (e.g., metadata tags). Content moderation : Providers must prevent the generation of illegal or harmful content and establish mechanisms for public complaints and regulatory reporting. National security and social stability : AI services must align with \"socialist core values\" and avoid generating content that undermines state authority or promotes extremism. Additionally, service providers must maintain the security and reliability of their systems, provide technical assistance during regulatory inspections, and report security risks. Providers with influence over public opinion or mobilization must complete pre-launch security assessments and obtain regulatory filings. Translation of regulation: Generative AI Regulation AI International Initiatives There are also some regulations that aim to unify AI standards across borders. OECD AI Principles The OECD’s Recommendation on Artificial Intelligence —adopted in 2019 and updated in 2023 and 2024—is the first intergovernmental standard promoting trustworthy AI. It establishes five principles for responsible AI development and five recommendations for national and international action. These principles aim to ensure AI systems are human-centric, trustworthy, and aligned with democratic values and human rights. Principles for Trustworthy AI Inclusive growth, sustainable development, and well-being : AI should benefit people and the planet by improving human capabilities, promoting inclusion, reducing inequality, and supporting environmental sustainability. Respect for the rule of law, human rights, and democratic values : AI actors must uphold freedoms, dignity, equality, and rights throughout the AI lifecycle. Mechanisms should protect against misuse and ensure human oversight. Transparency and explainability : Stakeholders should understand how AI systems operate. Providers must disclose information about data sources, logic, and decision-making processes in a clear and context-appropriate way, enabling users to challenge outputs where needed. Robustness, security, and safety : AI systems should function reliably in various conditions and be designed to prevent and mitigate harm. Systems must be overrideable or decommissioned when needed and support information integrity. Accountability : AI actors are responsible for ensuring systems function correctly and in line with these principles. They must enable traceability of data and decisions, apply risk management at all lifecycle stages, and collaborate with other stakeholders to address issues like bias and rights violations. National and International Recommendations Invest in research and development : Governments should fund long-term AI R&D, promote open science, and support tools and datasets that are representative and privacy-compliant. Foster an inclusive AI ecosystem : Promote access to digital infrastructure, AI technologies, and shared knowledge through legal and secure data-sharing mechanisms such as data trusts. Create an interoperable governance environment : Support agile, outcome-based policies, regulatory sandboxes, and cross-border cooperation to align governance frameworks and stimulate responsible innovation. Build human capacity and prepare for labour market changes : Equip citizens with AI-related skills, ensure smooth transitions for displaced workers, and promote quality employment through dialogue and training. Advance international cooperation : Collaborate globally to develop shared AI standards, foster knowledge exchange, and create indicators to measure AI development and policy effectiveness. The OECD AI Principles have become a global benchmark, informing AI policies in the G20 and many member and non-member countries. Their focus on flexibility and adaptability ensures continued relevance as AI technologies evolve, especially with the emergence of generative AI. Official source: OECD AI Principles GPAI (Global Partnership on AI) The Global Partnership on Artificial Intelligence (GPAI) is an international, multi-stakeholder initiative designed to guide the responsible development and use of AI in alignment with human rights, democratic values, and the OECD AI Principles. Launched in 2020, GPAI brings together countries committed to fostering trustworthy, human-centric AI through international collaboration. In 2024, GPAI deepened its collaboration with the OECD by forming an integrated partnership that includes 44 member countries across six continents. This joint structure ensures equitable participation between GPAI and OECD members, reduces duplication, and improves the efficiency of AI policy coordination and research. Key Objectives and Structure GPAI aims to bridge the gap between AI theory and practice. It enables cooperation among policymakers, academic experts, industry leaders, and civil society to translate shared values into actionable frameworks. Membership requires adherence to the OECD AI Principles and evidence of a proactive commitment to responsible AI at national and international levels. Expert Community and Support Centres GPAI is supported by a strong expert community formed from the merger of the GPAI Multistakeholder Experts Group and the OECD ONE AI network. This community provides diverse, global perspectives on AI governance and contributes to the partnership’s policy and technical outputs. In addition, GPAI operates Expert Support Centres—nationally funded organizations in Canada (CEIMIA), France (Inria), and Japan (NICT)—which support implementation through practical projects and research aligned with the partnership’s work plan. By integrating technical expertise with multilateral policy collaboration, GPAI aids in shaping global norms and frameworks for AI governance. Official source: Global Partnership on AI Council of Europe Framework Convention on AI The Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law is the world’s first legally binding international treaty on AI. Opened for signature on September 5, 2024, the convention sets out legal obligations to ensure that the lifecycle of AI systems respects fundamental rights while promoting innovation. Scope and Purpose The treaty applies to both public and private actors using AI systems, including private entities acting on behalf of public authorities. It aims to close regulatory gaps in existing human rights frameworks as AI technologies evolve, without regulating specific technologies, maintaining a technology-neutral stance. Core Requirements States that ratify the convention must embed several fundamental principles into the design, development, and deployment of AI systems: Human autonomy Privacy and data protection Transparency and oversight Accountability and responsibility Reliability Safe innovation The convention also guarantees remedies and procedural safeguards . Affected individuals must have access to sufficient information about AI system usage to understand and challenge decisions. They must also be informed when interacting with an AI system and be able to file complaints with competent authorities. Risk and Impact Management Parties are required to conduct iterative risk and impact assessments on AI’s implications for human rights, democracy, and the rule of law. These assessments must lead to appropriate mitigation measures, and in some cases, governments may impose bans or moratoria on harmful AI applications. Compliance Options for the Private Sector Countries can choose one of two compliance approaches for private sector activities: Apply the convention’s provisions directly, or Implement alternative but equivalent measures in line with international human rights obligations. Monitoring and Enforcement Implementation is overseen by the Conference of the Parties , a body composed of state representatives. This group reviews compliance, issues recommendations, and coordinates with stakeholders through activities such as public hearings. By focusing on binding commitments and inclusive oversight, the Framework Convention seeks to ensure that AI systems operate within the bounds of democratic values and fundamental rights across all member states and signatories. Official source: Framework Convention on AI 5 Best Practices to Adhere AI Regulations The following best practices can help organizations ensure their AI systems and usage policies align with AI regulations around the world. 1. Establish Clear AI Governance Policies Organizations should begin by building a formal governance structure that oversees the development, deployment, and maintenance of AI systems. This includes defining accountability across teams, appointing responsible officers, and setting up cross-functional collaboration among legal, technical, and operational departments. Governance policies must outline roles and responsibilities, review and approval workflows, and escalation paths for security concerns or compliance issues. Additionally, organizations should create frameworks for documenting AI system purposes, intended use cases, risk classification, and lifecycle activities. These policies ensure that all AI initiatives are guided by consistent principles aligned with regulatory expectations and organizational values. 2. Implement Continuous Compliance Solutions AI systems evolve over time due to updates in models, data, or operating environments. Compliance solutions must be designed to detect changes and flag regulatory risks as they arise. This requires embedding compliance checks into the AI development pipeline—from data ingestion to model deployment and post-production monitoring. Tools like automated documentation generators, model validation platforms, and compliance dashboards help track whether systems meet transparency and data protection standards. These systems should be able to trigger alerts or policy enforcement actions when deviations occur. ‍ Learn more in our detailed guide to continuous compliance (coming soon) 3. Implement Thorough Data Management Practices Data quality and governance are foundational to regulatory compliance. Organizations must establish policies for sourcing data legally, ensuring consent where applicable, and documenting data provenance. This includes verifying the accuracy, completeness, and diversity of AI training data to prevent biased outcomes. Strong AI data management involves versioning training datasets, labeling data with appropriate metadata, and maintaining logs of data access and transformations in AI workflows. Privacy-by-design approaches should be integrated into AI models and their data pipelines, including pseudonymization, minimization, and differential privacy when necessary. These controls help demonstrate compliance with data protection laws such as GDPR, PIPL, or CCPA and support reliable model performance. 4. Monitor and Audit AI Systems Continuously Ongoing monitoring ensures AI systems behave as intended and stay within compliance thresholds. This includes tracking metrics like accuracy, false positive/negative rates, and system availability. Monitoring should also cover input data shifts and unexpected outputs that may indicate model drift or failures. Auditing processes should be periodic and event-driven, covering both technical performance and regulatory criteria. Maintaining logs of predictions, decision rationale, and model updates is critical for traceability. Organizations should establish procedures for incident response and corrective action based on audit findings. These practices provide evidence of due diligence and help identify issues before they escalate into compliance violations. 5. Provide Ongoing Training and Awareness AI regulation is complex and constantly evolving. Organizations must equip employees with the knowledge and skills to navigate this landscape effectively. Regular training sessions should cover the latest legal frameworks, safety principles, and organizational compliance protocols. Programs should be tailored to different roles—for example, engineers might need deep dives on model transparency and accuracy , while product managers may focus on consent and data governance. Interactive workshops, simulation exercises, and role-specific guidance help reinforce understanding. ‍",
      "word_count": 4168,
      "extraction_method": "readability",
      "metadata": {
        "search_position": 3,
        "search_query": "AI regulation",
        "original_title": "AI Regulations in 2025: US, EU, UK, Japan, China & More - Anecdotes AI",
        "snippet": "28-Jan-2026 · AI regulations refer to the legal frameworks and guidelines established to oversee the development and deployment of artificial intelligence ..."
      },
      "timestamp": "2026-02-17T01:51:21.585456",
      "error": null
    }
  ],
  "metadata": {
    "total_queries": 3,
    "total_search_results": 9,
    "total_pages_fetched": 8,
    "successful_extractions": 4,
    "total_words_extracted": 34710,
    "elapsed_time_seconds": 143.33,
    "min_content_words": 100
  },
  "timestamp": "2026-02-17T01:51:21.589399"
}