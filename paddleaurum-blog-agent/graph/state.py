# # graph/state.py
# # ──────────────────────────────────────────────────────────────────────────────
# # All state definitions for the PaddleAurum autonomous blog pipeline.
# # A single AgentState TypedDict flows through every node in the LangGraph graph.
# # Sub-types are defined first so AgentState can reference them directly.
# # ──────────────────────────────────────────────────────────────────────────────

# from __future__ import annotations

# from enum import Enum
# from typing import Any, Dict, List, Optional, TypedDict


# # ── Enumerations ──────────────────────────────────────────────────────────────


# class IntentType(str, Enum):
#     """Classifies the dominant user intent behind a search query."""

#     INFORMATIONAL = "informational"   # "what are pickleball kitchen rules"
#     COMMERCIAL    = "commercial"      # "best pickleball paddles 2025"
#     NAVIGATIONAL  = "navigational"    # "paddleaurum.com tournament schedule"


# class Severity(str, Enum):
#     """Severity levels used by the SEO Auditor to categorise issues."""

#     CRITICAL = "critical"   # blocks publish (e.g. missing title tag)
#     WARNING  = "warning"    # degrades ranking (e.g. thin meta description)
#     INFO     = "info"       # nice-to-have improvement


# class Tone(str, Enum):
#     """Authorial tone options passed to the Coach Writer agent."""

#     COACH             = "coach"              # default — experienced pickleball coach
#     EXPERT            = "expert"             # technical / advanced players
#     BEGINNER_FRIENDLY = "beginner-friendly"  # simple language, step-by-step


# # ── Sub-types (used as nested structures inside AgentState) ──────────────────


# class ResearchSnippet(TypedDict):
#     """One search result captured by a Research Worker node."""

#     query:        str   # the sub-query that produced this result
#     url:          str   # source URL
#     title:        str   # page/article title
#     snippet:      str   # extracted text snippet
#     retrieved_at: str   # ISO 8601 timestamp


# class KeywordMap(TypedDict):
#     """Structured keyword plan produced by the SEO Strategist (Keyword Mapper node)."""

#     primary:     str            # single primary keyword (e.g. "pickleball kitchen rules")
#     secondary:   List[str]      # closely related keywords (e.g. ["NVZ rules", "volley fault"])
#     lsi:         List[str]      # latent semantic indexing terms (e.g. ["dink", "erne"])
#     entities:    List[str]      # NLP entities — players, equipment, venues, organisations
#     intent_type: IntentType     # confirmed search intent classification


# class ContentOutline(TypedDict):
#     """Article skeleton produced by the Outline Agent node."""

#     headings:                  List[Dict[str, Any]]  # [{level: "H1|H2|H3", text: str}]
#     faq_candidates:            List[str]              # questions suitable for FAQ schema
#     internal_link_placeholders: List[str]             # anchor text suggestions for internal links


# class SEOIssue(TypedDict):
#     """A single violation or suggestion returned by the SEO Auditor node."""

#     field:      str        # e.g. "title_tag", "meta_description", "heading_hierarchy"
#     severity:   Severity   # CRITICAL | WARNING | INFO
#     message:    str        # human-readable description of the problem
#     suggestion: str        # specific corrective action


# class ImageSlot(TypedDict):
#     """One image placement identified by the Image Selector node."""

#     slot_id:     str            # unique identifier (e.g. "img_001")
#     description: str            # context extracted from surrounding article text
#     alt_text:    str            # descriptive alt text (SEO + accessibility)
#     url:         Optional[str]  # filled by Unsplash / Pexels query; None = placeholder
#     credit:      Optional[str]  # photographer / source credit line


# class SchemaMarkup(TypedDict):
#     """JSON-LD structured data blocks generated by the Schema Generator node."""

#     article: str           # Article schema JSON-LD string
#     faq:     Optional[str] # FAQPage schema JSON-LD; None if no FAQ candidates
#     how_to:  Optional[str] # HowTo schema JSON-LD; None if article is not instructional


# class FinalOutput(TypedDict):
#     """The complete, publish-ready article package assembled by the Final Assembler node."""

#     markdown:         str            # full article body in Markdown
#     title_tag:        str            # <title> tag content (50–60 chars)
#     meta_description: str            # meta description (150–160 chars)
#     url_slug:         str            # clean, keyword-rich URL slug
#     schema_markup:    SchemaMarkup   # all JSON-LD blocks
#     image_manifest:   List[ImageSlot]
#     citations:        List[str]      # formatted reference list
#     word_count:       int
#     seo_score:        int            # final score that cleared the 85 threshold


# # ── Primary state container ───────────────────────────────────────────────────


# class AgentState(TypedDict):
#     """
#     The single shared state object that flows through every node in the graph.

#     LangGraph passes this TypedDict between nodes; each node reads what it needs
#     and returns a partial dict of only the keys it has updated.  All coordination
#     between agents happens through this object — no direct agent-to-agent calls.

#     Sections
#     --------
#     Input           — provided by the user or scheduler at pipeline start
#     Planner         — task plan and sub-query decisions from the Planner node
#     Research        — snippets and sources from parallel Research Workers
#     Keyword/Outline — keyword map and article skeleton
#     Draft/Revision  — current draft and self-correction loop counters
#     SEO Audit       — score, issues, and suggestions from the Auditor node
#     Final Output    — fully assembled publish-ready package
#     Control Flow    — flags that drive conditional routing decisions
#     """

#     # ── Input ─────────────────────────────────────────────────────────────────
#     topic:           str            # raw topic string, e.g. "pickleball kitchen rules for beginners"
#     target_keyword:  Optional[str]  # optional override; Keyword Mapper derives one if absent
#     tone:            Tone           # authorial tone — defaults to Tone.COACH
#     word_count_goal: int            # target article length — defaults to 1 500
#     session_id:      str            # UUID; used as LangSmith trace ID and checkpoint thread ID

#     # ── Planner outputs ───────────────────────────────────────────────────────
#     task_plan:       Optional[Dict[str, Any]]  # structured JSON plan emitted by Planner node
#     sub_queries:     List[str]                 # parallel research sub-queries
#     needs_research:  bool                      # True → fan out to Research Workers
#     intent_type:     Optional[IntentType]      # classified search intent

#     # ── Research outputs ──────────────────────────────────────────────────────
#     research_snippets: List[ResearchSnippet]  # raw snippets from all Research Workers
#     research_sources:  List[str]              # deduplicated source URLs (for citations)

#     # ── Keyword & outline ─────────────────────────────────────────────────────
#     keyword_map:                Optional[KeywordMap]
#     content_outline:            Optional[ContentOutline]
#     faq_candidates:             List[str]   # mirror of content_outline.faq_candidates for easy access
#     internal_link_placeholders: List[str]   # mirror of content_outline.internal_link_placeholders

#     # ── Draft & revision ──────────────────────────────────────────────────────
#     draft_article:      Optional[str]  # current Markdown draft; overwritten on each revision
#     revision_iteration: int            # counts Writer → Auditor → Reflection cycles (starts at 0)
#     max_iterations:     int            # maximum reflection loops before human escalation (default 3)

#     # ── SEO audit ─────────────────────────────────────────────────────────────
#     seo_score:       Optional[int]    # 0–100; pipeline advances when score ≥ SEO_PASS_THRESHOLD
#     seo_issues:      List[SEOIssue]   # all violations from the last audit pass
#     seo_suggestions: List[str]        # plain-text improvement hints for the Reflection node

#     # ── Final output ──────────────────────────────────────────────────────────
#     image_manifest:    List[ImageSlot]
#     formatted_article: Optional[str]           # article body with inline citation markers inserted
#     schema_markup:     Optional[SchemaMarkup]
#     title_tag:         Optional[str]
#     meta_description:  Optional[str]
#     url_slug:          Optional[str]
#     final_output:      Optional[FinalOutput]   # complete publish package

#     # ── Control flow ──────────────────────────────────────────────────────────
#     approved:               bool           # True after human approves in the review gate
#     outline_approved:       bool           # True after optional human outline review
#     human_review_requested: bool           # True when SEO loop exhausted without passing
#     error:                  Optional[str]  # error message set by any failing node
#     error_node:             Optional[str]  # name of the node that raised the error
#     retry_count:            int            # global retry counter used by ErrorRecoveryNode


# # ── Default factory ───────────────────────────────────────────────────────────


# def make_initial_state(
#     topic: str,
#     session_id: str,
#     target_keyword: Optional[str] = None,
#     tone: Tone = Tone.COACH,
#     word_count_goal: int = 1_500,
#     max_iterations: int = 3,
# ) -> AgentState:
#     """
#     Build a fully-initialised AgentState with safe default values.

#     Call this before invoking the compiled LangGraph app so that every key
#     expected by downstream nodes is present — even those not yet populated.

#     Parameters
#     ----------
#     topic           : Raw blog topic string.
#     session_id      : UUID used for LangSmith tracing and SQLite checkpointing.
#     target_keyword  : Optional keyword override; Keyword Mapper will derive one if None.
#     tone            : Authorial tone passed to the Coach Writer agent.
#     word_count_goal : Target article length in words.
#     max_iterations  : Hard limit on Writer → Auditor → Reflection cycles.
#     """
#     return AgentState(
#         # Input
#         topic=topic,
#         target_keyword=target_keyword,
#         tone=tone,
#         word_count_goal=word_count_goal,
#         session_id=session_id,

#         # Planner
#         task_plan=None,
#         sub_queries=[],
#         needs_research=True,
#         intent_type=None,

#         # Research
#         research_snippets=[],
#         research_sources=[],

#         # Keyword & outline
#         keyword_map=None,
#         content_outline=None,
#         faq_candidates=[],
#         internal_link_placeholders=[],

#         # Draft & revision
#         draft_article=None,
#         revision_iteration=0,
#         max_iterations=max_iterations,

#         # SEO audit
#         seo_score=None,
#         seo_issues=[],
#         seo_suggestions=[],

#         # Final output
#         image_manifest=[],
#         formatted_article=None,
#         schema_markup=None,
#         title_tag=None,
#         meta_description=None,
#         url_slug=None,
#         final_output=None,

#         # Control flow
#         approved=False,
#         outline_approved=False,
#         human_review_requested=False,
#         error=None,
#         error_node=None,
#         retry_count=0,
#     )



























# @##############################################################################

















# graph/state.py
# ──────────────────────────────────────────────────────────────────────────────
# All state definitions for the PaddleAurum autonomous blog pipeline.
# A single AgentState TypedDict flows through every node in the LangGraph graph.
# Sub-types are defined first so AgentState can reference them directly.
# ──────────────────────────────────────────────────────────────────────────────

from __future__ import annotations

import operator
from enum import Enum
from typing import Annotated, Any, Dict, List, Optional, TypedDict


# ── Enumerations ──────────────────────────────────────────────────────────────


class IntentType(str, Enum):
    """Classifies the dominant user intent behind a search query."""

    INFORMATIONAL = "informational"   # "what are pickleball kitchen rules"
    COMMERCIAL    = "commercial"      # "best pickleball paddles 2025"
    NAVIGATIONAL  = "navigational"    # "paddleaurum.com tournament schedule"


class Severity(str, Enum):
    """Severity levels used by the SEO Auditor to categorise issues."""

    CRITICAL = "critical"   # blocks publish (e.g. missing title tag)
    WARNING  = "warning"    # degrades ranking (e.g. thin meta description)
    INFO     = "info"       # nice-to-have improvement


class Tone(str, Enum):
    """Authorial tone options passed to the Coach Writer agent."""

    COACH             = "coach"              # default — experienced pickleball coach
    EXPERT            = "expert"             # technical / advanced players
    BEGINNER_FRIENDLY = "beginner-friendly"  # simple language, step-by-step


# ── Sub-types (used as nested structures inside AgentState) ──────────────────


class ResearchSnippet(TypedDict):
    """One search result captured by a Research Worker node."""

    query:        str   # the sub-query that produced this result
    url:          str   # source URL
    title:        str   # page/article title
    snippet:      str   # extracted text snippet
    retrieved_at: str   # ISO 8601 timestamp


class KeywordMap(TypedDict):
    """Structured keyword plan produced by the SEO Strategist (Keyword Mapper node)."""

    primary:     str            # single primary keyword (e.g. "pickleball kitchen rules")
    secondary:   List[str]      # closely related keywords (e.g. ["NVZ rules", "volley fault"])
    lsi:         List[str]      # latent semantic indexing terms (e.g. ["dink", "erne"])
    entities:    List[str]      # NLP entities — players, equipment, venues, organisations
    intent_type: IntentType     # confirmed search intent classification


class ContentOutline(TypedDict):
    """Article skeleton produced by the Outline Agent node."""

    headings:                  List[Dict[str, Any]]  # [{level: "H1|H2|H3", text: str}]
    faq_candidates:            List[str]              # questions suitable for FAQ schema
    internal_link_placeholders: List[str]             # anchor text suggestions for internal links


class SEOIssue(TypedDict):
    """A single violation or suggestion returned by the SEO Auditor node."""

    field:      str        # e.g. "title_tag", "meta_description", "heading_hierarchy"
    severity:   Severity   # CRITICAL | WARNING | INFO
    message:    str        # human-readable description of the problem
    suggestion: str        # specific corrective action


class ImageSlot(TypedDict):
    """One image placement identified by the Image Selector node."""

    slot_id:     str            # unique identifier (e.g. "img_001")
    description: str            # context extracted from surrounding article text
    alt_text:    str            # descriptive alt text (SEO + accessibility)
    url:         Optional[str]  # filled by Unsplash / Pexels query; None = placeholder
    credit:      Optional[str]  # photographer / source credit line


class SchemaMarkup(TypedDict):
    """JSON-LD structured data blocks generated by the Schema Generator node."""

    article: str           # Article schema JSON-LD string
    faq:     Optional[str] # FAQPage schema JSON-LD; None if no FAQ candidates
    how_to:  Optional[str] # HowTo schema JSON-LD; None if article is not instructional


class FinalOutput(TypedDict):
    """The complete, publish-ready article package assembled by the Final Assembler node."""

    markdown:         str            # full article body in Markdown
    title_tag:        str            # <title> tag content (50–60 chars)
    meta_description: str            # meta description (150–160 chars)
    url_slug:         str            # clean, keyword-rich URL slug
    schema_markup:    SchemaMarkup   # all JSON-LD blocks
    image_manifest:   List[ImageSlot]
    citations:        List[str]      # formatted reference list
    word_count:       int
    seo_score:        int            # final score that cleared the 85 threshold


# ── Primary state container ───────────────────────────────────────────────────


class AgentState(TypedDict):
    """
    The single shared state object that flows through every node in the graph.

    LangGraph passes this TypedDict between nodes; each node reads what it needs
    and returns a partial dict of only the keys it has updated.  All coordination
    between agents happens through this object — no direct agent-to-agent calls.

    Sections
    --------
    Input           — provided by the user or scheduler at pipeline start
    Planner         — task plan and sub-query decisions from the Planner node
    Research        — snippets and sources from parallel Research Workers
    Keyword/Outline — keyword map and article skeleton
    Draft/Revision  — current draft and self-correction loop counters
    SEO Audit       — score, issues, and suggestions from the Auditor node
    Final Output    — fully assembled publish-ready package
    Control Flow    — flags that drive conditional routing decisions
    """

    # ── Input ─────────────────────────────────────────────────────────────────
    topic:           str            # raw topic string, e.g. "pickleball kitchen rules for beginners"
    target_keyword:  Optional[str]  # optional override; Keyword Mapper derives one if absent
    tone:            Tone           # authorial tone — defaults to Tone.COACH
    word_count_goal: int            # target article length — defaults to 1 500
    session_id:      str            # UUID; used as LangSmith trace ID and checkpoint thread ID

    # ── Planner outputs ───────────────────────────────────────────────────────
    task_plan:       Optional[Dict[str, Any]]  # structured JSON plan emitted by Planner node
    sub_queries:     List[str]                 # parallel research sub-queries
    needs_research:  bool                      # True → fan out to Research Workers
    intent_type:     Optional[IntentType]      # classified search intent

    # ── Research outputs ──────────────────────────────────────────────────────
    # UPDATED: Annotated with operator.add for correct accumulation from parallel workers
    research_snippets: Annotated[List[ResearchSnippet], operator.add]  # raw snippets from all Research Workers
    research_sources:  List[str]              # deduplicated source URLs (for citations)

    # ── Keyword & outline ─────────────────────────────────────────────────────
    keyword_map:                Optional[KeywordMap]
    content_outline:            Optional[ContentOutline]
    faq_candidates:             List[str]   # mirror of content_outline.faq_candidates for easy access
    internal_link_placeholders: List[str]   # mirror of content_outline.internal_link_placeholders

    # ── Draft & revision ──────────────────────────────────────────────────────
    draft_article:      Optional[str]  # current Markdown draft; overwritten on each revision
    revision_iteration: int            # counts Writer → Auditor → Reflection cycles (starts at 0)
    max_iterations:     int            # maximum reflection loops before human escalation (default 3)

    # ── SEO audit ─────────────────────────────────────────────────────────────
    seo_score:       Optional[int]    # 0–100; pipeline advances when score ≥ SEO_PASS_THRESHOLD
    seo_issues:      List[SEOIssue]   # all violations from the last audit pass
    seo_suggestions: List[str]        # plain-text improvement hints for the Reflection node

    # ── Final output ──────────────────────────────────────────────────────────
    image_manifest:    List[ImageSlot]
    formatted_article: Optional[str]           # article body with inline citation markers inserted
    schema_markup:     Optional[SchemaMarkup]
    title_tag:         Optional[str]
    meta_description:  Optional[str]
    url_slug:          Optional[str]
    final_output:      Optional[FinalOutput]   # complete publish package

    # ── Control flow ──────────────────────────────────────────────────────────
    approved:               bool           # True after human approves in the review gate
    outline_approved:       bool           # True after optional human outline review
    human_review_requested: bool           # True when SEO loop exhausted without passing
    error:                  Optional[str]  # error message set by any failing node
    error_node:             Optional[str]  # name of the node that raised the error
    retry_count:            int            # global retry counter used by ErrorRecoveryNode


# ── Default factory ───────────────────────────────────────────────────────────


def make_initial_state(
    topic: str,
    session_id: str,
    target_keyword: Optional[str] = None,
    tone: Tone = Tone.COACH,
    word_count_goal: int = 1_500,
    max_iterations: int = 3,
) -> AgentState:
    """
    Build a fully-initialised AgentState with safe default values.

    Call this before invoking the compiled LangGraph app so that every key
    expected by downstream nodes is present — even those not yet populated.

    Parameters
    ----------
    topic           : Raw blog topic string.
    session_id      : UUID used for LangSmith tracing and SQLite checkpointing.
    target_keyword  : Optional keyword override; Keyword Mapper will derive one if None.
    tone            : Authorial tone passed to the Coach Writer agent.
    word_count_goal : Target article length in words.
    max_iterations  : Hard limit on Writer → Auditor → Reflection cycles.
    """
    return AgentState(
        # Input
        topic=topic,
        target_keyword=target_keyword,
        tone=tone,
        word_count_goal=word_count_goal,
        session_id=session_id,

        # Planner
        task_plan=None,
        sub_queries=[],
        needs_research=True,
        intent_type=None,

        # Research
        research_snippets=[],
        research_sources=[],

        # Keyword & outline
        keyword_map=None,
        content_outline=None,
        faq_candidates=[],
        internal_link_placeholders=[],

        # Draft & revision
        draft_article=None,
        revision_iteration=0,
        max_iterations=max_iterations,

        # SEO audit
        seo_score=None,
        seo_issues=[],
        seo_suggestions=[],

        # Final output
        image_manifest=[],
        formatted_article=None,
        schema_markup=None,
        title_tag=None,
        meta_description=None,
        url_slug=None,
        final_output=None,

        # Control flow
        approved=False,
        outline_approved=False,
        human_review_requested=False,
        error=None,
        error_node=None,
        retry_count=0,
    )